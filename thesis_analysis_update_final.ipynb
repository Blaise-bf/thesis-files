{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Blaise-bf/thesis-files/blob/main/thesis_analysis_update_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GEHSCGQeGfJM",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "!pip install segmentation_models_pytorch --quiet\n",
        "!pip install torchsummary --quiet\n",
        "!pip install torchmetrics --quiet\n",
        "!pip install -U albumentations --quiet\n",
        "!pip install timm --quiet\n",
        "# !pip install nnviz --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ul8EbfiOGc29"
      },
      "outputs": [],
      "source": [
        "from torchvision import transforms\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import segmentation_models_pytorch as smp\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from torchmetrics.segmentation import DiceScore\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GW1tr38RYNUs"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DDVnUoWdYG-i"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "def resize_to_square(\n",
        "    img: np.ndarray,\n",
        "    target_size: int,\n",
        "    pad_color: int = 0,\n",
        "    interpolation: int = cv2.INTER_CUBIC\n",
        ") -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Resizes an image to a square while maintaining aspect ratio.\n",
        "    Pads the remaining space with `pad_color` (default: 0/black).\n",
        "\n",
        "    Args:\n",
        "        img (np.ndarray): Input image (grayscale or color).\n",
        "        target_size (int): Desired width & height of the square output.\n",
        "        pad_color (int): Padding color (default 0 for black).\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: Square image of size (target_size, target_size).\n",
        "    \"\"\"\n",
        "    h, w = img.shape[:2]\n",
        "\n",
        "    # Scale the image to fit inside the target square\n",
        "    scale = min(target_size / w, target_size / h)\n",
        "    new_w = int(w * scale)\n",
        "    new_h = int(h * scale)\n",
        "    resized_img = cv2.resize(img, (new_w, new_h), interpolation=interpolation )\n",
        "\n",
        "    # Calculate padding to center the image\n",
        "    delta_w = target_size - new_w\n",
        "    delta_h = target_size - new_h\n",
        "    top = delta_h // 2\n",
        "    bottom = delta_h - top\n",
        "    left = delta_w // 2\n",
        "    right = delta_w - left\n",
        "\n",
        "    # Apply padding\n",
        "    square_img = cv2.copyMakeBorder(\n",
        "        resized_img,\n",
        "        top, bottom, left, right,\n",
        "        cv2.BORDER_CONSTANT,\n",
        "        value=pad_color\n",
        "    )\n",
        "\n",
        "    return square_img\n",
        "\n",
        "\n",
        "def read_image_frompath(\n",
        "    mask_paths: list[str],\n",
        "    size: int | None = None,\n",
        "    pad_color: int = 0,\n",
        "    interpolation: int = cv2.INTER_CUBIC\n",
        ") -> list[np.ndarray]:\n",
        "    \"\"\"\n",
        "    Reads images from paths and optionally resizes them to squares.\n",
        "\n",
        "    Args:\n",
        "        mask_paths (list[str]): List of image file paths.\n",
        "        size (int | None): If provided, resize images to (size x size).\n",
        "        pad_color (int): Padding color (default 0 for black).\n",
        "\n",
        "    Returns:\n",
        "        list[np.ndarray]: List of images (resized if `size` is given).\n",
        "    \"\"\"\n",
        "    images = []\n",
        "    for path in mask_paths:\n",
        "        img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
        "        if img is None:\n",
        "            print(f\"Warning: Could not read image at {path}\")\n",
        "            continue\n",
        "\n",
        "        if size is not None:\n",
        "            img = resize_to_square(img, size, pad_color, interpolation)\n",
        "        images.append(img)\n",
        "\n",
        "    return images\n",
        "\n",
        "\n",
        "def load_base_unetmodel(encoder_name=\"efficientnet-b7\"):\n",
        "    model = smp.UnetPlusPlus(\n",
        "    encoder_name=encoder_name,  # EfficientNet-b4 encoder\n",
        "    encoder_weights=\"imagenet\",      # Pretrained weights\n",
        "    in_channels=1,                   # RGB channels\n",
        "    classes=1                       # Single binary mask class\n",
        ")\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i59lApL4GOMG"
      },
      "outputs": [],
      "source": [
        "service = 'colab'\n",
        "# Read in meta data\n",
        "met_df = pd.read_excel('/content/drive/MyDrive/msc_uhasselt/cath_ai_rev_anon.xlsx')\n",
        "met_df.rename(columns={'arch (1-ok, 0-no)': 'arch',\n",
        "                                 'tip (1-ok, 0-no)' : 'tip' }, inplace=True)\n",
        "\n",
        "\n",
        "if service == 'kaggle':\n",
        "# Paths to images\n",
        "    train_ctheter_mask_dir = '/kaggle/input/thesis-files/train_catheter_masks/train_catheter_masks'\n",
        "    test_ctheter_mask_dir = '/kaggle/input/thesis-files/test_catheter_masks'\n",
        "    train_atrium_mask_dir = '/kaggle/input/thesis-files/train_atrium_masks/train_atrium_masks'\n",
        "    test_atrium_mask_dir = '/kaggle/input/thesis-files/test_atrium_masks'\n",
        "    original_images_dir = '/kaggle/input/thesis-files/train_images/train_images'\n",
        "    original_test_images_dir = '/kaggle/input/thesis-files/test_images'\n",
        "else:\n",
        "    train_ctheter_mask_dir = '/content/drive/MyDrive/msc_uhasselt/train_catheter_masks'\n",
        "    test_ctheter_mask_dir = '/content/drive/MyDrive/msc_uhasselt/test_catheter_masks'\n",
        "    train_atrium_mask_dir = '/content/drive/MyDrive/msc_uhasselt/train_atrium_masks'\n",
        "    test_atrium_mask_dir = '/content/drive/MyDrive/msc_uhasselt/test_atrium_masks'\n",
        "    original_images_dir = '/content/drive/MyDrive/msc_uhasselt/train_images'\n",
        "    original_test_images_dir = '/content/drive/MyDrive/msc_uhasselt/test_images'\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def get_filenames(dir_path):\n",
        "    filenames = [f for f in os.listdir(dir_path) if f.endswith('.tif')]\n",
        "    return filenames\n",
        "\n",
        "def get_ids(filenames):\n",
        "    ids = {f.split('.')[0] for f in filenames}\n",
        "    return ids\n",
        "\n",
        "def get_full_paths(dir_path, filenames):\n",
        "    full_paths = [os.path.join(dir_path, f\"{img_id}.tif\") for img_id in filenames]\n",
        "    return full_paths\n",
        "\n",
        "\n",
        "# Get filenames (not full paths yet)\n",
        "catheter_labels = get_filenames(train_ctheter_mask_dir)\n",
        "atrial_labels = get_filenames(train_atrium_mask_dir)\n",
        "test_catheter_labels = get_filenames(test_ctheter_mask_dir)\n",
        "test_atrial_labels = get_filenames(test_atrium_mask_dir)\n",
        "\n",
        "# Extract IDs\n",
        "# The files typically have this form 'IMG-0025-00001.tif'\n",
        "# A set data structure is used to ensure set concepts like intersection or union can be used\n",
        "ids_cath = {f.split('.')[0] for f in catheter_labels} # this should return ids like IMG-0025-00001\n",
        "ids_atria = {f.split('.')[0] for f in atrial_labels}\n",
        "test_cath_ids = {f.split('.')[0] for f in test_catheter_labels}\n",
        "test_atria_ids = {f.split('.')[0] for f in test_atrial_labels}\n",
        "\n",
        "# Find common IDs\n",
        "common_ids = sorted(list(ids_cath.intersection(ids_atria)))  # sorted is optional, but keeps things in order\n",
        "common_ids_test = sorted(list(test_cath_ids.intersection(test_atria_ids)))\n",
        "\n",
        "common_ids_test.remove('IMG-0273-00001') # This image returns blank predictions for both masks, very poor image quality\n",
        "common_ids_test = sorted(common_ids_test)\n",
        "\n",
        "# Now build matched paths\n",
        "valid_cathetr_paths = get_full_paths(train_ctheter_mask_dir, common_ids)\n",
        "valid_atrial_paths = get_full_paths(train_atrium_mask_dir, common_ids)\n",
        "valid_test_cathetr_paths = get_full_paths(test_ctheter_mask_dir, common_ids_test)\n",
        "valid_test_atrial_paths = get_full_paths(test_atrium_mask_dir, common_ids_test)\n",
        "valid_images_paths = get_full_paths(original_images_dir, common_ids)\n",
        "valid_test_paths = get_full_paths(original_test_images_dir, common_ids_test)\n",
        "\n",
        "print(f\"Number of images: {len(valid_images_paths)}\")\n",
        "print(f\"Number of catheter masks: {len(valid_cathetr_paths)}\")\n",
        "print(f\"Number of atrial masks: {len(valid_atrial_paths)}\")\n",
        "print(f\"Number of test images: {len(valid_test_paths)}\")\n",
        "print(f\"Number of test catheter masks: {len(valid_test_cathetr_paths)}\")\n",
        "print(f\"Number of test atrial masks: {len(valid_test_atrial_paths)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j58Kg1Y_Fb68"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import requests\n",
        "\n",
        "def download_file(url, local_filename):\n",
        "    \"\"\"Download a file from a URL to a local file.\"\"\"\n",
        "    with requests.get(url, stream=True) as r:\n",
        "        r.raise_for_status()\n",
        "        with open(local_filename, 'wb') as f:\n",
        "            for chunk in r.iter_content(chunk_size=8192):\n",
        "                f.write(chunk)\n",
        "    return local_filename\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def save_file_locally(url, local_file_name):\n",
        "    if not os.path.exists(local_file_name):\n",
        "        print(f\"File {local_file_name} not found. Downloading from GitHub...\")\n",
        "        try:\n",
        "            download_file(url, local_file_name)\n",
        "            print(f\"Successfully downloaded {local_file_name}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Failed to download file: {e}\")\n",
        "    else:\n",
        "        print(f\"File {local_file_name} already exists\")\n",
        "\n",
        "\n",
        "\n",
        "file_info = {\n",
        "    'layers' : (\"https://raw.githubusercontent.com/Blaise-bf/unet/refs/heads/master/models/layers.py\", 'layers.py'),\n",
        "    'model'  : ('https://raw.githubusercontent.com/Blaise-bf/unet/refs/heads/master/models/UNet_3Plus.py', 'unet_3plus.py'),\n",
        "    'weights' : ('https://raw.githubusercontent.com/Blaise-bf/unet/refs/heads/master/models/init_weights.py', 'init_weights.py'),\n",
        "    'atention_unet' : ('https://raw.githubusercontent.com/Blaise-bf/thesis-files/refs/heads/main/attention_unet.py', 'attention_unet.py'),\n",
        "    'unet_2plus' : ('https://raw.githubusercontent.com/Blaise-bf/unet/refs/heads/master/models/UNet_2Plus.py', 'unet_2plus.py'),\n",
        "    'models':      ('https://raw.githubusercontent.com/Blaise-bf/thesis-files/refs/heads/main/models.py', 'models.py'),\n",
        "}\n",
        "\n",
        "for key in file_info.keys():\n",
        "    info = file_info[key]\n",
        "    save_file_locally(info[0], info[1])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "waDf6IzSFb69"
      },
      "outputs": [],
      "source": [
        "from unet_3plus import UNet_3Plus, UNet_3Plus_DeepSup\n",
        "# from unet_2plus import UNet_2Plus\n",
        "from attention_unet import Attention_UNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O0mjimryFb6-"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-yF_I7E2BNID"
      },
      "outputs": [],
      "source": [
        "# python version\n",
        "!python --version\n",
        "\n",
        "# pytorch version\n",
        "print(torch.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_H5kKiDUFb6-"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import cv2\n",
        "from typing import List, Optional, Tuple\n",
        "\n",
        "# from segmentation_models_pytorch.losses import DiceLoss|\n",
        "# from segmentation_models_pytorch.metrics import DiceScore\n",
        "\n",
        "\n",
        "class SegmentationDataset(Dataset):\n",
        "    def __init__(\n",
        "        self,\n",
        "        image_paths: List[str],\n",
        "        mask_paths: List[str],\n",
        "        image_size: int = 720,\n",
        "        transform: Optional[transforms.Compose] = None,\n",
        "        apply_clahe: bool = True,\n",
        "        clahe_limit: float = 2.0,\n",
        "        clahe_tile_grid_size: Tuple[int, int] = (8, 8)\n",
        "    ):\n",
        "        self.image_paths = image_paths\n",
        "        self.mask_paths = mask_paths\n",
        "        self.image_size = image_size\n",
        "        self.transform = transform\n",
        "        self.apply_clahe = apply_clahe\n",
        "        self.clahe_limit = clahe_limit\n",
        "        self.clahe_tile_grid_size = clahe_tile_grid_size\n",
        "\n",
        "        # Validate inputs\n",
        "        if len(image_paths) != len(mask_paths):\n",
        "            raise ValueError(\"Number of images and masks must be equal\")\n",
        "\n",
        "        # Image normalization transform\n",
        "        self.normalize = transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.5], std=[0.5])  # Normalize to [-1, 1] range\n",
        "        ])\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "        # Load image and mask\n",
        "        # image = Image.open(self.image_paths[idx]).convert('L')  # Convert to grayscale\n",
        "        # mask = Image.open(self.mask_paths[idx]).convert('L')\n",
        "        # Use Open cv to read in gray scale image and mask\n",
        "        image = cv2.imread(self.image_paths[idx], cv2.IMREAD_GRAYSCALE)\n",
        "        mask = cv2.imread(self.mask_paths[idx], cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "        # Apply CLAHE for contrast enhancement if enabled\n",
        "        if self.apply_clahe:\n",
        "            # image_np = np.array(image)\n",
        "            clahe = cv2.createCLAHE(clipLimit=self.clahe_limit, tileGridSize=self.clahe_tile_grid_size)\n",
        "            image = Image.fromarray(clahe.apply(image))\n",
        "\n",
        "        # Resize both image and mask\n",
        "        image = self._resize_to_square(np.array(image), self.image_size)\n",
        "        mask = self._resize_to_square(np.array(mask), self.image_size)\n",
        "\n",
        "        # Convert mask to binary (0 or 1)\n",
        "        mask = (mask > 0).astype(np.float32)  # float32 for PyTorch compatibility\n",
        "\n",
        "        # Convert to PIL for potential transforms\n",
        "        # image_pil = Image.fromarray(image)\n",
        "        # mask_pil = Image.fromarray(mask)\n",
        "\n",
        "        # Apply additional transforms if specified\n",
        "\n",
        "        augmented = self.transform(image=image, mask=mask)\n",
        "            # image_pil = self.transform(image_pil)\n",
        "            # mask_pil = self.transform(mask_pil)\n",
        "\n",
        "        # Apply normalization to image only\n",
        "        image_tensor = augmented['image']\n",
        "        mask_tensor = augmented['mask'] # Add channel dimension\n",
        "\n",
        "        if mask_tensor.ndim == 2:\n",
        "            mask_tensor = mask_tensor.unsqueeze(0)\n",
        "\n",
        "        return image_tensor, mask_tensor\n",
        "\n",
        "    @staticmethod\n",
        "    def _resize_to_square(image: np.ndarray, size: int) -> np.ndarray:\n",
        "        \"\"\"Resize image to square while maintaining aspect ratio with padding\"\"\"\n",
        "        h, w = image.shape\n",
        "        scale = size / max(h, w)\n",
        "        new_h, new_w = int(h * scale), int(w * scale)\n",
        "\n",
        "        resized = cv2.resize(image, (new_w, new_h))\n",
        "\n",
        "        # Pad to make square\n",
        "        delta_w = size - new_w\n",
        "        delta_h = size - new_h\n",
        "        top = delta_h // 2\n",
        "        bottom = delta_h - top\n",
        "        left = delta_w // 2\n",
        "        right = delta_w - left\n",
        "\n",
        "        return cv2.copyMakeBorder(\n",
        "            resized,\n",
        "            top, bottom, left, right,\n",
        "            cv2.BORDER_CONSTANT,\n",
        "            value=0\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "exKFnsZRb24k"
      },
      "outputs": [],
      "source": [
        "from math import pi\n",
        "from torch.utils.data import DataLoader\n",
        "import albumentations as A\n",
        "# Example transforms for data augmentation\n",
        "\n",
        "import albumentations as A\n",
        "SZIE = 960\n",
        "train_transform = A.Compose([\n",
        "    # --- Spatial Augmentations ---\n",
        "    A.HorizontalFlip(p=0.3),  # Safe for atrial anatomy\n",
        "    A.Rotate(limit=15, p=0.2, border_mode=cv2.BORDER_CONSTANT),\n",
        "\n",
        "    # Finer GridDistortion (controlled warping)\n",
        "\n",
        "\n",
        "    # Optional: Combined with ElasticTransform\n",
        "    A.OneOf([\n",
        "        A.ElasticTransform(\n",
        "                alpha=300,\n",
        "                sigma=10,\n",
        "                interpolation=cv2.INTER_LINEAR,\n",
        "                approximate=False,\n",
        "                same_dxdy=True,\n",
        "                mask_interpolation=cv2.INTER_NEAREST,\n",
        "                noise_distribution=\"gaussian\",\n",
        "                keypoint_remapping_method=\"mask\",\n",
        "                border_mode=cv2.BORDER_CONSTANT,\n",
        "                fill=0,\n",
        "                fill_mask=0,\n",
        "                p=0.3\n",
        "),\n",
        "        A.GridDistortion(distort_limit=0.1, p=0.3)  # Even subtler variant\n",
        "    ], p=0.4),\n",
        "\n",
        "    # --- Intensity Augmentations ---\n",
        "    # A.CLAHE(clip_limit=2.0, p=0.3),\n",
        "    A.RandomBrightnessContrast(\n",
        "        brightness_limit=(-0.1, 0.1),\n",
        "        contrast_limit=(-0.1, 0.1),\n",
        "        p=0.4\n",
        "    ),\n",
        "    A.GaussNoise(std_range=(0.01, 0.05), p=0.2),\n",
        "    # --- Normalization ---\n",
        "    A.Normalize(mean=(0.485), std=(0.229)),\n",
        "    A.ToTensorV2(),\n",
        "])\n",
        "\n",
        "val_transform = A.Compose([\n",
        "    A.Normalize(mean=(0.485), std=(0.229)),\n",
        "    A.ToTensorV2(),\n",
        "])\n",
        "\n",
        "\n",
        "\n",
        "train_dataset = SegmentationDataset(\n",
        "    image_paths=valid_images_paths,\n",
        "    mask_paths=valid_cathetr_paths,\n",
        "    image_size=SZIE,\n",
        "    transform=train_transform,\n",
        "    apply_clahe=True\n",
        ")\n",
        "\n",
        "val_dataset = SegmentationDataset(\n",
        "    image_paths=valid_test_paths,\n",
        "    mask_paths=valid_test_cathetr_paths,\n",
        "    image_size=SZIE,\n",
        "    transform=val_transform,\n",
        "    apply_clahe=True\n",
        ")\n",
        "\n",
        "train_data_loader = DataLoader(train_dataset, batch_size=5, shuffle=True, pin_memory=True)\n",
        "val_data_loader = DataLoader(val_dataset, batch_size=4, shuffle=False,  pin_memory=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-GU9hkL6RLW8"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "img, mask = val_dataset[0]\n",
        "print(img.shape, mask.shape)\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "# Access the image tensor at index 0, remove channel dim, convert to numpy\n",
        "plt.imshow(img.squeeze().numpy(), cmap='gray')\n",
        "plt.title('Image')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "# Access the mask tensor at index 1, remove channel dim, convert to numpy\n",
        "plt.imshow(mask.squeeze().numpy(), cmap='gray')\n",
        "plt.title('Mask')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IdIWQRY9Om3k"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch import Tensor\n",
        "\n",
        "class HybridSegmentationLoss(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        focal_alpha: float = 0.25,\n",
        "        focal_gamma: float = 2.0,\n",
        "        window_size: int = 11,\n",
        "        msssim_weights: Tensor = None,\n",
        "        eps: float = 1e-8\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.focal_alpha = focal_alpha\n",
        "        self.focal_gamma = focal_gamma\n",
        "        self.window_size = window_size\n",
        "        self.eps = eps\n",
        "\n",
        "        # Default weights for MS-SSIM (5 scales)\n",
        "        if msssim_weights is None:\n",
        "            msssim_weights = torch.tensor([0.0448, 0.2856, 0.3001, 0.2363, 0.1333])\n",
        "        self.register_buffer('msssim_weights', msssim_weights)\n",
        "\n",
        "    def forward(self, pred: Tensor, target: Tensor) -> Tensor:\n",
        "        # Ensure float32 for mixed precision\n",
        "        pred = pred.float()\n",
        "        target = target.float()\n",
        "\n",
        "        # Focal Loss (pixel-level)\n",
        "        focal_loss = self.focal_loss_with_logits(pred, target)\n",
        "\n",
        "        # Convert logits to probabilities\n",
        "        pred_prob = torch.sigmoid(pred)\n",
        "\n",
        "        # MS-SSIM Loss (patch-level)\n",
        "        ms_ssim_loss = self.ms_ssim_loss(pred_prob, target)\n",
        "\n",
        "        # IoU Loss (map-level)\n",
        "        iou_loss = self.iou_loss(pred_prob, target)\n",
        "\n",
        "        # Combine losses (Eq. 6 in paper)\n",
        "        return focal_loss + ms_ssim_loss + iou_loss\n",
        "\n",
        "    def focal_loss_with_logits(self, pred: Tensor, target: Tensor) -> Tensor:\n",
        "        bce = F.binary_cross_entropy_with_logits(pred, target, reduction='none')\n",
        "        pt = torch.exp(-bce)  # p if target=1, 1-p otherwise\n",
        "\n",
        "        # Alpha-balanced focal loss (Eq. in paper references [10])\n",
        "        alpha_t = torch.where(target == 1,\n",
        "                             self.focal_alpha,\n",
        "                             1 - self.focal_alpha)\n",
        "        focal_loss = alpha_t * (1 - pt) ** self.focal_gamma * bce\n",
        "        return focal_loss.mean()\n",
        "\n",
        "    def ms_ssim_loss(self, pred: Tensor, target: Tensor) -> Tensor:\n",
        "        # MS-SSIM returns a similarity score [0,1] → convert to loss\n",
        "        ms_ssim_val = self.calc_ms_ssim(pred, target)\n",
        "        return 1.0 - ms_ssim_val\n",
        "\n",
        "    def iou_loss(self, pred: Tensor, target: Tensor) -> Tensor:\n",
        "        intersection = (pred * target).sum(dim=(1, 2, 3))\n",
        "        union = pred.sum(dim=(1, 2, 3)) + target.sum(dim=(1, 2, 3)) - intersection\n",
        "        iou = (intersection + self.eps) / (union + self.eps)\n",
        "        return (1.0 - iou).mean()\n",
        "\n",
        "    def calc_ms_ssim(self, pred: Tensor, target: Tensor) -> Tensor:\n",
        "        device = pred.device\n",
        "        weights = self.msssim_weights.to(device)\n",
        "        levels = weights.size(0)\n",
        "\n",
        "        # Initialize SSIM values\n",
        "        ssim_per_level = []\n",
        "        cs_per_level = []\n",
        "\n",
        "        for i in range(levels):\n",
        "            # Calculate SSIM at current scale\n",
        "            ssim_val, cs_val = self.calc_ssim(pred, target, full=True)\n",
        "            ssim_per_level.append(ssim_val)\n",
        "            cs_per_level.append(cs_val)\n",
        "\n",
        "            # Downsample for next level\n",
        "            if i < levels - 1:\n",
        "                pred = F.avg_pool2d(pred, kernel_size=2)\n",
        "                target = F.avg_pool2d(target, kernel_size=2)\n",
        "\n",
        "        # Combine results (Eq. 5 in paper)\n",
        "        ms_ssim = torch.ones_like(ssim_per_level[0])\n",
        "        for i in range(levels):\n",
        "            if i < levels - 1:\n",
        "                ms_ssim *= cs_per_level[i] ** weights[i]\n",
        "            else:\n",
        "                ms_ssim *= ssim_per_level[i] ** weights[i]\n",
        "\n",
        "        return ms_ssim.mean()\n",
        "\n",
        "    def calc_ssim(\n",
        "        self,\n",
        "        pred: Tensor,\n",
        "        target: Tensor,\n",
        "        window: Tensor = None,\n",
        "        full: bool = False,\n",
        "        val_range: float = None\n",
        "    ) -> Tensor:\n",
        "        # Determine value range\n",
        "        if val_range is None:\n",
        "            max_val = torch.max(pred).item()\n",
        "            val_range = max_val if max_val > 1 else 1.0\n",
        "\n",
        "        # Create window if needed\n",
        "        c = pred.size(1)\n",
        "        if window is None:\n",
        "            real_size = min(self.window_size, pred.shape[2], pred.shape[3])\n",
        "            window = self.create_window(real_size, c).to(pred.device)\n",
        "\n",
        "        # Calculate means\n",
        "        mu_pred = F.conv2d(pred, window, groups=c)\n",
        "        mu_target = F.conv2d(target, window, groups=c)\n",
        "\n",
        "        # Calculate variances and covariances\n",
        "        mu_pred_sq = mu_pred.pow(2)\n",
        "        mu_target_sq = mu_target.pow(2)\n",
        "        mu_pred_target = mu_pred * mu_target\n",
        "\n",
        "        sigma_pred_sq = F.conv2d(pred * pred, window, groups=c) - mu_pred_sq\n",
        "        sigma_target_sq = F.conv2d(target * target, window, groups=c) - mu_target_sq\n",
        "        sigma_pred_target = F.conv2d(pred * target, window, groups=c) - mu_pred_target\n",
        "\n",
        "        # SSIM constants\n",
        "        c1 = (0.01 * val_range) ** 2\n",
        "        c2 = (0.03 * val_range) ** 2\n",
        "\n",
        "        # Contrast sensitivity (CS)\n",
        "        cs_map = (2 * sigma_pred_target + c2) / (sigma_pred_sq + sigma_target_sq + c2)\n",
        "\n",
        "        # SSIM map\n",
        "        ssim_map = ((2 * mu_pred_target + c1) / (mu_pred_sq + mu_target_sq + c1)) * cs_map\n",
        "\n",
        "        if full:\n",
        "            return ssim_map.mean(), cs_map.mean()\n",
        "        return ssim_map.mean()\n",
        "\n",
        "    def create_window(self, size: int, channel: int = 1) -> Tensor:\n",
        "        # Create 1D Gaussian kernel\n",
        "        sigma = 1.5\n",
        "        coords = torch.arange(size).float()\n",
        "        coords -= size // 2\n",
        "        g = torch.exp(-(coords ** 2) / (2 * sigma ** 2))\n",
        "        g /= g.sum()\n",
        "\n",
        "        # Create 2D window\n",
        "        g_2d = g.unsqueeze(1) @ g.unsqueeze(0)\n",
        "        g_2d = g_2d.unsqueeze(0).unsqueeze(0)\n",
        "        return g_2d.expand(channel, 1, size, size).contiguous()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R347N8yvK8Or"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR, LinearLR, SequentialLR\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "from tqdm.auto import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from datetime import datetime\n",
        "from torch.cuda.amp import GradScaler, autocast\n",
        "import segmentation_models_pytorch as smp # Ensure smp is imported\n",
        "\n",
        "from segmentation_models_pytorch.metrics.functional import iou_score\n",
        "\n",
        "# from torchmetrics import DiceScore\n",
        "\n",
        "# All previous imports remain the same\n",
        "\n",
        "class SegmentationLoss(nn.Module):\n",
        "    def __init__(self, alpha=0.5, beta=0.5, gamma=2.0, smooth=1e-6):\n",
        "        super().__init__()\n",
        "        self.alpha = alpha\n",
        "        self.beta = beta\n",
        "        self.gamma = gamma\n",
        "        self.smooth = smooth\n",
        "\n",
        "    def forward(self, pred, target):\n",
        "        # Ensure float32 for mixed precision\n",
        "        pred = pred.float()\n",
        "        target = target.float()\n",
        "\n",
        "        # BCEWithLogitsLoss (handles logits)\n",
        "        bce_loss = F.binary_cross_entropy_with_logits(pred, target)\n",
        "\n",
        "        # Dice Loss with prob conversion\n",
        "        pred_prob = torch.sigmoid(pred)\n",
        "        intersection = (pred_prob * target).sum()\n",
        "        dice_loss = 1 - (2. * intersection + self.smooth) / (pred_prob.sum() + target.sum() + self.smooth)\n",
        "\n",
        "        # Stabilized Focal Loss\n",
        "        focal_loss = self._focal_loss(pred, target)\n",
        "\n",
        "        return (1 - self.alpha - self.beta) * bce_loss + self.alpha * dice_loss + self.beta * focal_loss\n",
        "\n",
        "    def _focal_loss(self, pred, target):\n",
        "        bce = F.binary_cross_entropy_with_logits(pred, target, reduction='none')\n",
        "        pt = torch.exp(-bce.clamp(min=-100, max=50))  # Critical stabilization\n",
        "        return ((1 - pt) ** self.gamma * bce).mean()\n",
        "\n",
        "\n",
        "def free_gpu_memory():\n",
        "    torch.cuda.empty_cache()\n",
        "    import gc\n",
        "    gc.collect()\n",
        "\n",
        "class Trainer:\n",
        "    def __init__(self, model, train_loader, val_loader,\n",
        "                 device, num_epochs=100, experiment_name=\"\",\n",
        "                 lr=0.0001, weight_decay=0.001, loss_type='hybrid'): # Renamed 'loss' to 'loss_type' to avoid conflict\n",
        "        self.model = model.to(device)\n",
        "        self.train_loader = train_loader\n",
        "        self.val_loader = val_loader\n",
        "        self.device = device\n",
        "        self.num_epochs = num_epochs\n",
        "\n",
        "        # Setup experiment directory\n",
        "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "        self.experiment_dir = f\"experiments/{experiment_name}_{timestamp}\" if experiment_name else f\"experiments/exp_{timestamp}\"\n",
        "        os.makedirs(f\"{self.experiment_dir}/plots\", exist_ok=True)\n",
        "        os.makedirs(f\"{self.experiment_dir}/models\", exist_ok=True)\n",
        "\n",
        "        # Optimizer with filtered parameters\n",
        "        self.optimizer = optim.AdamW(\n",
        "            filter(lambda p: p.requires_grad, model.parameters()),\n",
        "            lr=lr,\n",
        "            weight_decay=weight_decay\n",
        "        )\n",
        "\n",
        "        # Mixed precision training\n",
        "        self.scaler = GradScaler()\n",
        "\n",
        "        # LR scheduling with warmup\n",
        "        warmup_epochs = 5\n",
        "        self.scheduler = SequentialLR(\n",
        "            self.optimizer,\n",
        "            schedulers=[\n",
        "                LinearLR(self.optimizer, start_factor=0.01, end_factor=1.0, total_iters=warmup_epochs),\n",
        "                CosineAnnealingLR(self.optimizer, T_max=num_epochs-warmup_epochs, eta_min=1e-6)\n",
        "            ],\n",
        "            milestones=[warmup_epochs]\n",
        "        )\n",
        "\n",
        "        # Define loss functions based on loss_type\n",
        "        self.loss_type = loss_type\n",
        "        if self.loss_type == 'hybrid':\n",
        "            # Define individual loss components for hybrid loss\n",
        "            self.dice_loss = smp.losses.DiceLoss(mode='binary')\n",
        "            self.focal_loss = smp.losses.FocalLoss(mode='binary')\n",
        "            # Note: The actual combination happens in the forward pass methods\n",
        "            self.criterion_name = \"Dice + Focal\"\n",
        "        elif self.loss_type == 'focal':\n",
        "            self.criterion = smp.losses.FocalLoss(mode='binary')\n",
        "            self.criterion_name = \"Focal Loss\"\n",
        "        elif self.loss_type == 'custom':\n",
        "            self.criterion = SegmentationLoss()\n",
        "            self.criterion_name = \"Custom Loss\"\n",
        "\n",
        "        elif self.loss_type == 'dice':\n",
        "            self.criterion = smp.losses.DiceLoss(mode='binary')\n",
        "            self.criterion_name = \"Dice Loss\"\n",
        "\n",
        "        elif self.loss_type == 'bced':\n",
        "            self.dice_loss = smp.losses.DiceLoss(mode='binary')\n",
        "            self.bce_loss = smp.losses.SoftBCEWithLogitsLoss()\n",
        "            self.criterion_name = \"Dice + BCE\"\n",
        "\n",
        "\n",
        "        else: # Default or soft_bce\n",
        "            self.criterion = smp.losses.SoftBCEWithLogitsLoss()\n",
        "            self.criterion_name = \"SoftBCEWithLogitsLoss\"\n",
        "\n",
        "\n",
        "        # Track metrics\n",
        "        self.train_loss = []\n",
        "        self.val_loss = []\n",
        "        self.val_dice = []\n",
        "        self.val_iou = []\n",
        "        self.lr_history = []\n",
        "        self.best_dice = 0.0\n",
        "        self.best_iou = 0.0\n",
        "\n",
        "    def train_epoch(self, epoch):\n",
        "        self.model.train()\n",
        "        epoch_loss = 0.0\n",
        "\n",
        "        with tqdm(self.train_loader, unit=\"batch\", desc=f\"Epoch {epoch+1}/{self.num_epochs} [Train]\") as pbar:\n",
        "            for images, masks in pbar:\n",
        "                images = images.to(self.device, non_blocking=True)\n",
        "                masks = masks.to(self.device, non_blocking=True)\n",
        "\n",
        "                # Mixed precision forward\n",
        "                with autocast():\n",
        "                    outputs = self.model(images)\n",
        "                    # Calculate loss based on loss_type\n",
        "                    if self.loss_type == 'hybrid':\n",
        "                        loss = self.dice_loss(outputs, masks) + self.focal_loss(outputs, masks)\n",
        "                    elif self.loss_type == 'bced':\n",
        "                        loss = self.dice_loss(outputs, masks) + self.bce_loss(outputs, masks)\n",
        "                    else:\n",
        "                        loss = self.criterion(outputs, masks)\n",
        "\n",
        "\n",
        "                # Backward pass\n",
        "                self.optimizer.zero_grad()\n",
        "                self.scaler.scale(loss).backward()\n",
        "                self.scaler.step(self.optimizer)\n",
        "                self.scaler.update()\n",
        "\n",
        "                epoch_loss += loss.item()\n",
        "                pbar.set_postfix({\"loss\": f\"{loss.item():.4f}\", \"lr\": f\"{self.optimizer.param_groups[0]['lr']:.2e}\"})\n",
        "\n",
        "        return epoch_loss / len(self.train_loader)\n",
        "\n",
        "\n",
        "    def validate_epoch(self, epoch):\n",
        "        self.model.eval()\n",
        "        val_loss = 0.0\n",
        "        dice_scores = []\n",
        "        iou_scores = []\n",
        "\n",
        "        with tqdm(self.val_loader, unit=\"batch\", desc=f\"Epoch {epoch+1}/{self.num_epochs} [Val]\") as pbar:\n",
        "            with torch.no_grad():\n",
        "                for images, masks in pbar:\n",
        "                    images = images.to(self.device, non_blocking=True)\n",
        "                    masks = masks.to(self.device, non_blocking=True)\n",
        "\n",
        "                    with autocast():\n",
        "                        outputs = self.model(images)\n",
        "                        # Calculate loss based on loss_type\n",
        "                        if self.loss_type == 'hybrid':\n",
        "                             loss = self.dice_loss(outputs, masks) + self.focal_loss(outputs, masks)\n",
        "\n",
        "                        elif self.loss_type == 'bced':\n",
        "                             loss = self.dice_loss(outputs, masks) + self.bce_loss(outputs, masks)\n",
        "                        else:\n",
        "                             loss = self.criterion(outputs, masks)\n",
        "\n",
        "                    val_loss += loss.item()\n",
        "\n",
        "                    # Calculate Dice score\n",
        "                    preds = torch.sigmoid(outputs)\n",
        "                    # Move tensors to CPU before calculating dice\n",
        "                    dice = self._calculate_dice(preds.cpu(), masks.cpu())\n",
        "                    iou = self._calculate_iou(preds.cpu(), masks.cpu())\n",
        "                    dice_scores.append(dice)\n",
        "                    iou_scores.append(iou)\n",
        "\n",
        "                    pbar.set_postfix({\"val_loss\": f\"{loss.item():.4f}\", \"dice\": f\"{dice:.4f}\", \"iou\": f\"{iou:.4f}\"})\n",
        "\n",
        "        mean_dice = np.mean(dice_scores)\n",
        "        mean_iou = np.mean(iou_scores)\n",
        "        return val_loss / len(self.val_loader), mean_dice, mean_iou\n",
        "\n",
        "    def _calculate_dice(self, pred, target, smooth=1e-6):\n",
        "        # Ensure tensors are on CPU if they weren't already\n",
        "        pred = pred.cpu()\n",
        "        target = target.cpu()\n",
        "\n",
        "        pred = (pred > 0.5).float()\n",
        "        intersection = (pred * target).sum()\n",
        "        return (2. * intersection + smooth) / (pred.sum() + target.sum() + smooth)\n",
        "\n",
        "    def _calculate_iou(self, pred, target):\n",
        "        # Ensure tensors are on CPU if they weren't already\n",
        "        pred = pred.cpu()\n",
        "        target = target.cpu()\n",
        "\n",
        "        pred = (pred > 0.5).float()\n",
        "        intersection = (pred * target).sum()\n",
        "        union = pred.sum() + target.sum() - intersection\n",
        "        return intersection / union\n",
        "\n",
        "    def _update_plots(self, epoch):\n",
        "        \"\"\"Update training metrics visualization\"\"\"\n",
        "        plt.figure(figsize=(18, 6))\n",
        "\n",
        "        # Loss plot\n",
        "        plt.subplot(1, 3, 1)\n",
        "        plt.plot(self.train_loss, label='Train', color='blue')\n",
        "        plt.plot(self.val_loss, label='Val', color='red')\n",
        "        plt.title('Training & Validation Loss')\n",
        "        plt.xlabel('Epochs')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "\n",
        "        # Dice plot\n",
        "        plt.subplot(1, 3, 2)\n",
        "        plt.plot(self.val_dice, label='Val Dice', color='green')\n",
        "        plt.title('Validation Dice Score')\n",
        "        plt.xlabel('Epochs')\n",
        "        plt.ylabel('Dice')\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "\n",
        "        # LR plot\n",
        "        plt.subplot(1, 3, 3)\n",
        "        plt.plot(self.lr_history, label='Learning Rate', color='purple')\n",
        "        plt.title('Learning Rate Schedule')\n",
        "        plt.xlabel('Epochs')\n",
        "        plt.ylabel('LR')\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "        plt.yscale('log')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(f\"{self.experiment_dir}/plots/metrics_epoch_{epoch+1}.png\", dpi=120)\n",
        "        plt.close()\n",
        "\n",
        "    def train(self):\n",
        "        print(f\"\\n🚀 Starting training for {self.num_epochs} epochs...\")\n",
        "        print(f\"📂 Experiment directory: {self.experiment_dir}\")\n",
        "        print(f\"⚡ Using device: {self.device}\")\n",
        "        print(f\"🔧 Loss function: {self.criterion_name}\\n\") # Use criterion_name for printing\n",
        "\n",
        "        for epoch in tqdm(range(self.num_epochs), desc=\"Training Progress\"):\n",
        "            train_loss = self.train_epoch(epoch)\n",
        "            val_loss, val_dice, val_iou = self.validate_epoch(epoch)\n",
        "\n",
        "            self.scheduler.step()\n",
        "            self.train_loss.append(train_loss)\n",
        "            self.val_loss.append(val_loss)\n",
        "            self.val_dice.append(val_dice)\n",
        "            self.lr_history.append(self.optimizer.param_groups[0]['lr'])\n",
        "\n",
        "            self._update_plots(epoch)\n",
        "\n",
        "            if val_dice > self.best_dice:\n",
        "                self.best_dice = val_dice\n",
        "                self.best_iou = val_iou\n",
        "                torch.save({\n",
        "                    'epoch': epoch+1,\n",
        "                    'model_state_dict': self.model.state_dict(),\n",
        "                    'optimizer_state_dict': self.optimizer.state_dict(),\n",
        "                    'loss': val_loss,\n",
        "                    'dice': val_dice,\n",
        "                }, f\"{self.experiment_dir}/models/best_model.pth\")\n",
        "                tqdm.write(f\"🎉 New best model: Dice {val_dice:.4f} IOU: {val_iou:.4f} at epoch {epoch+1}\")\n",
        "\n",
        "        self._save_final_artifacts()\n",
        "        print(f\"\\n🏁 Training completed! Best Dice: {self.best_dice:.4f}\")\n",
        "        return self.model.state_dict() # Return state dict of the best model\n",
        "\n",
        "    def _save_final_artifacts(self):\n",
        "        \"\"\"Save all training artifacts\"\"\"\n",
        "        torch.save({\n",
        "            'epoch': self.num_epochs,\n",
        "            'model_state_dict': self.model.state_dict(),\n",
        "            'optimizer_state_dict': self.optimizer.state_dict(),\n",
        "            'train_loss': self.train_loss,\n",
        "            'val_loss': self.val_loss,\n",
        "            'val_dice': self.val_dice,\n",
        "        }, f\"{self.experiment_dir}/models/final_model.pth\")\n",
        "\n",
        "        np.savez(\n",
        "            f\"{self.experiment_dir}/plots/training_metrics.npz\",\n",
        "            train_loss=np.array(self.train_loss),\n",
        "            val_loss=np.array(self.val_loss),\n",
        "            val_dice=np.array(self.val_dice),\n",
        "            lr_history=np.array(self.lr_history)\n",
        "        )\n",
        "\n",
        "        self._generate_final_plot()\n",
        "\n",
        "    def _generate_final_plot(self):\n",
        "        \"\"\"Generate high-quality final plot\"\"\"\n",
        "        fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(18, 6))\n",
        "\n",
        "        ax1.plot(self.train_loss, label='Train', color='blue')\n",
        "        ax1.plot(self.val_loss, label='Val', color='red')\n",
        "        ax1.set_title('Training & Validation Loss')\n",
        "        ax1.set_xlabel('Epochs')\n",
        "        ax1.legend()\n",
        "        ax1.grid(True)\n",
        "\n",
        "        ax2.plot(self.val_dice, label='Val Dice', color='green')\n",
        "        ax2.set_title('Validation Dice Score')\n",
        "        ax2.set_xlabel('Epochs')\n",
        "        ax2.legend()\n",
        "        ax2.grid(True)\n",
        "\n",
        "        ax3.plot(self.lr_history, label='Learning Rate', color='purple')\n",
        "        ax3.set_title('Learning Rate Schedule')\n",
        "        ax3.set_xlabel('Epochs')\n",
        "        ax3.set_yscale('log')\n",
        "        ax3.legend()\n",
        "        ax3.grid(True)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(f\"{self.experiment_dir}/plots/final_metrics.png\", dpi=300)\n",
        "        plt.savefig(f\"{self.experiment_dir}/plots/final_metrics.pdf\")\n",
        "        plt.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vR_aBWg6uR-a"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Initialize components outside the Trainer class's __main__ block\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model_catheter = load_base_unetmodel()\n",
        "    # model_catheter = load_base_unetmodel(\n",
        "    # Data loaders are defined above this __main__ block\n",
        "    # train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=4)\n",
        "    # val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False, num_workers=2)\n",
        "\n",
        "    # Train\n",
        "    trainer = Trainer(\n",
        "        model=model_catheter,\n",
        "        train_loader=train_data_loader, # Use the data loaders defined outside __main__\n",
        "        val_loader=val_data_loader,   # Use the data loaders defined outside __main__\n",
        "        device=device,\n",
        "        num_epochs=100,\n",
        "        experiment_name=\"catheter_unet_dice\",\n",
        "        loss_type='dice'\n",
        "    )\n",
        "    # The train method now returns the best weights state dictionary\n",
        "    best_weights_state_dict_cath = trainer.train()\n",
        "\n",
        "    # Load best weights for inference\n",
        "    # model1.load_state_dict(best_weights_state_dict)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Initialize components outside the Trainer class's __main__ block\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model_catheter = smp.Unet(in_channels=1, encoder_name='efficientnet-b7', encoder_weights='imagenet', classes=1)\n",
        "    # model_catheter = load_base_unetmodel(\n",
        "    # Data loaders are defined above this __main__ block\n",
        "    # train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=4)\n",
        "    # val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False, num_workers=2)\n",
        "\n",
        "    # Train\n",
        "    trainer = Trainer(\n",
        "        model=model_catheter,\n",
        "        train_loader=train_data_loader, # Use the data loaders defined outside __main__\n",
        "        val_loader=val_data_loader,   # Use the data loaders defined outside __main__\n",
        "        device=device,\n",
        "        num_epochs=100,\n",
        "        experiment_name=\"catheter_unet_simple\",\n",
        "        loss_type='dice'\n",
        "    )\n",
        "    # The train method now returns the best weights state dictionary\n",
        "    best_weights_state_dict_cath = trainer.train()\n",
        "\n",
        "    # Load best weights for inference\n",
        "    # model1.load_state_dict(best_weights_state_dict)"
      ],
      "metadata": {
        "id": "i_Fq8biZIYEI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zTab1b1f7x9l"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RZW962ypw6UL"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Initialize components outside the Trainer class's __main__ block\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model_catheter = load_base_unetmodel()\n",
        "    # model_catheter = load_base_unetmodel(\n",
        "    # Data loaders are defined above this __main__ block\n",
        "    # train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=4)\n",
        "    # val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False, num_workers=2)\n",
        "\n",
        "    # Train\n",
        "    trainer = Trainer(\n",
        "        model=model_catheter,\n",
        "        train_loader=train_data_loader, # Use the data loaders defined outside __main__\n",
        "        val_loader=val_data_loader,   # Use the data loaders defined outside __main__\n",
        "        device=device,\n",
        "        num_epochs=60,\n",
        "        experiment_name=\"catheter_unet\",\n",
        "        loss_type='bced'\n",
        "    )\n",
        "    # The train method now returns the best weights state dictionary\n",
        "    best_weights_state_dict_cath = trainer.train()\n",
        "\n",
        "    # Load best weights for inference\n",
        "    # model1.load_state_dict(best_weights_state_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0FmyAx5kKMa0"
      },
      "outputs": [],
      "source": [
        "!cp -r /content/experiments/catheter_unet_20250616_041515 /content/drive/MyDrive/msc_uhasselt/experiments/catheter_unet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L1TESuc6Jwl8"
      },
      "outputs": [],
      "source": [
        "free_gpu_memory()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3sjTrrrzJj3D"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "train_data_loader = DataLoader(train_dataset, batch_size=2, shuffle=True, pin_memory=True)\n",
        "val_data_loader = DataLoader(val_dataset, batch_size=2, shuffle=False,  pin_memory=True)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Initialize components outside the Trainer class's __main__ block\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model_catheter_3p = UNet_3Plus(in_channels=1)\n",
        "    # model_catheter = load_base_unetmodel(\n",
        "    # Data loaders are defined above this __main__ block\n",
        "    # train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=4)\n",
        "    # val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False, num_workers=2)\n",
        "\n",
        "    # Train\n",
        "    trainer = Trainer(\n",
        "        model=model_catheter_3p,\n",
        "        train_loader=train_data_loader, # Use the data loaders defined outside __main__\n",
        "        val_loader=val_data_loader,   # Use the data loaders defined outside __main__\n",
        "        device=device,\n",
        "        num_epochs=60,\n",
        "        experiment_name=\"catheter_unet_3p\",\n",
        "        loss_type='bced'\n",
        "    )\n",
        "    # The train method now returns the best weights state dictionary\n",
        "    best_weights_state_dict_cath = trainer.train()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kOPBz3hYxUdt"
      },
      "outputs": [],
      "source": [
        "!cp -r /content/experiments/catheter_unet_20250614_100702 /content/drive/MyDrive/msc_uhasselt/experiments/catheter_unet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oedhtVoKk8_I"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "train_data_loader = DataLoader(train_dataset, batch_size=5, shuffle=True, pin_memory=True)\n",
        "val_data_loader = DataLoader(val_dataset, batch_size=4, shuffle=False,  pin_memory=True)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Initialize components outside the Trainer class's __main__ block\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model_catheter_unet = load_base_unetmodel()\n",
        "    # model_catheter = load_base_unetmodel(\n",
        "    # Data loaders are defined above this __main__ block\n",
        "    # train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=4)\n",
        "    # val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False, num_workers=2)\n",
        "\n",
        "    # Train\n",
        "    trainer = Trainer(\n",
        "        model=model_catheter_unet,\n",
        "        train_loader=train_data_loader, # Use the data loaders defined outside __main__\n",
        "        val_loader=val_data_loader,   # Use the data loaders defined outside __main__\n",
        "        device=device,\n",
        "        num_epochs=100,\n",
        "        experiment_name=\"catheter_unet_bce\",\n",
        "        # lr=0.00001\n",
        "        loss_type='bce'\n",
        "    )\n",
        "    # The train method now returns the best weights state dictionary\n",
        "    best_weights_state_dict_cath = trainer.train()\n",
        "\n",
        "    # Load best weights for inference\n",
        "    # model1.load_state_dict(best_weights_state_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4FH-cuivVHNb"
      },
      "outputs": [],
      "source": [
        "free_gpu_memory()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KHv0KGS46oib"
      },
      "outputs": [],
      "source": [
        "!cp -r /content/experiments/catheter_unet_bce_20250609_180115 /content/drive/MyDrive/msc_uhasselt/experiments/catheter_unet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N6K99Jzk8ybs"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "train_data_loader = DataLoader(train_dataset, batch_size=5, shuffle=True, pin_memory=True)\n",
        "val_data_loader = DataLoader(val_dataset, batch_size=4, shuffle=False,  pin_memory=True)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Initialize components outside the Trainer class's __main__ block\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model_catheter_unet = load_base_unetmodel()\n",
        "    # model_catheter = load_base_unetmodel(\n",
        "    # Data loaders are defined above this __main__ block\n",
        "    # train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=4)\n",
        "    # val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False, num_workers=2)\n",
        "\n",
        "    # Train\n",
        "    trainer = Trainer(\n",
        "        model=model_catheter_unet,\n",
        "        train_loader=train_data_loader, # Use the data loaders defined outside __main__\n",
        "        val_loader=val_data_loader,   # Use the data loaders defined outside __main__\n",
        "        device=device,\n",
        "        num_epochs=100,\n",
        "        experiment_name=\"catheter_unet_bce\",\n",
        "        # lr=0.00001\n",
        "        loss_type='custom'\n",
        "    )\n",
        "    # The train method now returns the best weights state dictionary\n",
        "    best_weights_state_dict_cath = trainer.train()\n",
        "\n",
        "    # Load best weights for inference\n",
        "    # model1.load_state_dict(best_weights_state_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w4DJl4LEU62D"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "train_data_loader = DataLoader(train_dataset, batch_size=5, shuffle=True, pin_memory=True)\n",
        "val_data_loader = DataLoader(val_dataset, batch_size=4, shuffle=False,  pin_memory=True)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Initialize components outside the Trainer class's __main__ block\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model_catheter_unet_focal = load_base_unetmodel()\n",
        "    # model_catheter = load_base_unetmodel(\n",
        "    # Data loaders are defined above this __main__ block\n",
        "    # train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=4)\n",
        "    # val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False, num_workers=2)\n",
        "\n",
        "    # Train\n",
        "    trainer = Trainer(\n",
        "        model=model_catheter_unet_focal,\n",
        "        train_loader=train_data_loader, # Use the data loaders defined outside __main__\n",
        "        val_loader=val_data_loader,   # Use the data loaders defined outside __main__\n",
        "        device=device,\n",
        "        num_epochs=100,\n",
        "        experiment_name=\"catheter_unet_2plus_no_clahe\",\n",
        "        # lr=0.00001\n",
        "        loss='focal'\n",
        "    )\n",
        "    # The train method now returns the best weights state dictionary\n",
        "    best_weights_state_dict_cath = trainer.train()\n",
        "\n",
        "    # Load best weights for inference\n",
        "    # model1.load_state_dict(best_weights_state_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q2M673nDmxwq"
      },
      "outputs": [],
      "source": [
        "!cp -r /content/experiments/catheter_unet_20250609_053611 /content/drive/MyDrive/msc_uhasselt/experiments/catheter_unet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "INlPP7axtoi6"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "train_data_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, pin_memory=True)\n",
        "val_data_loader = DataLoader(val_dataset, batch_size=4, shuffle=False,  pin_memory=True)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Initialize components outside the Trainer class's __main__ block\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model_catheter_unet = load_base_unetmodel()\n",
        "    # model_catheter = load_base_unetmodel(\n",
        "    # Data loaders are defined above this __main__ block\n",
        "    # train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=4)\n",
        "    # val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False, num_workers=2)\n",
        "\n",
        "    # Train\n",
        "    trainer = Trainer(\n",
        "        model=model_catheter_unet,\n",
        "        train_loader=train_data_loader, # Use the data loaders defined outside __main__\n",
        "        val_loader=val_data_loader,   # Use the data loaders defined outside __main__\n",
        "        device=device,\n",
        "        num_epochs=100,\n",
        "        experiment_name=\"catheter_unet_2plus_focal_loss\",\n",
        "        loss_type='focal'\n",
        "        # lr=0.00001\n",
        "        # hybrid_loss=False\n",
        "    )\n",
        "    # The train method now returns the best weights state dictionary\n",
        "    best_weights_state_dict_cath = trainer.train()\n",
        "\n",
        "    # Load best weights for inference\n",
        "    # model1.load_state_dict(best_weights_state_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VG7mAk1dNa4d"
      },
      "outputs": [],
      "source": [
        "!cp -r /content/experiments/catheter_unet_2plus_focal_loss_20250609_220416 /content/drive/MyDrive/msc_uhasselt/experiments/catheter_unet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zky9Ztzmuy7w"
      },
      "outputs": [],
      "source": [
        "# Load best catheter model\n",
        "model_catheter_unet.load_state_dict(best_weights_state_dict_cath)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FN8SCDegvS_x"
      },
      "outputs": [],
      "source": [
        "SIZE = 960\n",
        "\n",
        "transform_image = transforms.Compose([  # Remember to change this to 960x960\n",
        "    transforms.Resize((SIZE, SIZE)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=(0.485), std=(0.229))\n",
        "])\n",
        "\n",
        "\n",
        "\n",
        "from torchmetrics.functional.segmentation import dice_score\n",
        "\n",
        "def calculate_dice_score(y_true, y_pred):\n",
        "    score = dice_score(y_true, y_pred, num_classes=2,  average='micro')\n",
        "    # get average score\n",
        "    return score.cpu().numpy().mean()\n",
        "\n",
        "def get_binary_masks(masks):\n",
        "\n",
        "\n",
        "    return (masks > 0).astype(np.float32)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def predict_catheter_segmentation(image_path, unet_model,\n",
        "                                  device,\n",
        "                                  size=SIZE,\n",
        "                                  transform=transform_image,\n",
        "                                  clip=None,\n",
        "                                  model_name='unet++',\n",
        "                                  prob=False):\n",
        "    # Open the image using PIL and convert to grayscale\n",
        "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "    # image_pil = Image.fromarray(image)\n",
        "    unet_model = unet_model.to(device)\n",
        "\n",
        "    # Convert to NumPy array\n",
        "    # image_np = np.array(image_pil)\n",
        "\n",
        "    # Apply CLAHE\n",
        "    if clip:\n",
        "\n",
        "      clahe = cv2.createCLAHE(clipLimit=clip, tileGridSize=(8, 8))\n",
        "      clahe_image_np = clahe.apply(image)\n",
        "    else:\n",
        "      clahe_image_np = image\n",
        "\n",
        "    # Resize image while maintaining aspect ratio\n",
        "    resized_aspx = resize_to_square(img=clahe_image_np, target_size=size)\n",
        "\n",
        "    # Convert back to PIL Image\n",
        "    clahe_image_pil = Image.fromarray(resized_aspx)\n",
        "\n",
        "    # Apply transform (e.g., ToTensor, normalization)\n",
        "    if transform:\n",
        "        image_tensor = transform(clahe_image_pil).unsqueeze(0).to(device) # unsqueeze adds a sample dimenstion (N, C, W, H)\n",
        "    else:\n",
        "        image_tensor = transforms.ToTensor()(clahe_image_pil).unsqueeze(0).to(device)\n",
        "\n",
        "    # Predict mask using U-Net++\n",
        "    unet_model.eval()\n",
        "    with torch.inference_mode():\n",
        "\n",
        "\n",
        "        if model_name == 'unet++':\n",
        "            output = torch.sigmoid(unet_model(image_tensor))\n",
        "\n",
        "        elif model_name == 'unet_deep_sup':\n",
        "            output = unet_model(image_tensor)\n",
        "            output = torch.sigmoid(output[0])\n",
        "\n",
        "        else:\n",
        "          output = unet_model(image_tensor)\n",
        "        # output = torch.sigmoid(output)\n",
        "        mask = output if prob else (output > 0.5).float()\n",
        "\n",
        "    return mask.cpu().squeeze().numpy(), resized_aspx\n",
        "\n",
        "\n",
        "def convert_to_tensor(np_array):\n",
        "    return torch.from_numpy(np_array)\n",
        "\n",
        "def get_id_from_path(path: str) -> str:\n",
        "    return path.split('/')[-1].replace('.tif', '')\n",
        "\n",
        "\n",
        "import random\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def visualize_predictions(model, test_image_paths, test_mask_paths, device, num_samples=5, clip_limit=2, figsize=(20, 10), model_name='unet++', size=SIZE):\n",
        "    \"\"\"\n",
        "    Visualize model predictions by showing original images, predicted masks, and ground truth masks.\n",
        "\n",
        "    Args:\n",
        "        model: The trained model for making predictions\n",
        "        test_image_paths: List of paths to test images\n",
        "        test_mask_paths: List of paths to corresponding ground truth masks\n",
        "        device: Device to run the model on ('cuda' or 'cpu')\n",
        "        num_samples: Number of random samples to visualize (default: 5)\n",
        "        clip_limit: CLAHE clip limit (default: 2)\n",
        "        figsize: Size of the matplotlib figure (default: (20, 10))\n",
        "    \"\"\"\n",
        "    # Randomly select samples\n",
        "    random_indices = random.sample(range(len(test_image_paths)), min(num_samples, len(test_image_paths)))\n",
        "    random_images = [test_image_paths[i] for i in random_indices]\n",
        "    random_masks = [test_mask_paths[i] for i in random_indices]\n",
        "\n",
        "    # Create subplots\n",
        "    fig, axes = plt.subplots(3, len(random_images), figsize=figsize)\n",
        "\n",
        "    # If only one sample, axes will be 1D - convert to 2D for consistency\n",
        "    if len(random_images) == 1:\n",
        "        axes = axes.reshape(3, 1)\n",
        "\n",
        "    for i, img_path in enumerate(random_images):\n",
        "        # Read ground truth mask\n",
        "        actual_mask = resize_to_square(cv2.imread(random_masks[i], cv2.IMREAD_GRAYSCALE), target_size=size)\n",
        "\n",
        "        binary_mask = get_binary_masks(actual_mask)\n",
        "        # actual\n",
        "\n",
        "        # Get prediction\n",
        "        predicted_mask, clahe_image = predict_catheter_segmentation(\n",
        "            img_path, model, device, clip=clip_limit, model_name=model_name\n",
        "        )\n",
        "\n",
        "        dice = calculate_dice_score(convert_to_tensor(binary_mask).unsqueeze(0), convert_to_tensor(predicted_mask).unsqueeze(0))\n",
        "\n",
        "        # Plot original image\n",
        "        axes[0, i].imshow(clahe_image, cmap='gray')\n",
        "        # axes[0, i].set_title(\"\")\n",
        "        axes[0, i].axis('off')\n",
        "\n",
        "         # Plot ground truth mask\n",
        "        axes[1, i].imshow(binary_mask, cmap='gray')\n",
        "        axes[1, i].set_title(\"Ground truth\", fontsize=12)\n",
        "        axes[1, i].axis('off')\n",
        "\n",
        "\n",
        "        # Plot predicted mask\n",
        "        axes[2, i].imshow(predicted_mask, cmap='gray')\n",
        "        axes[2, i].set_title(f'Predicted mask--DSC:{dice:.3f}', fontsize=12)\n",
        "        axes[2, i].axis('off')\n",
        "\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mLg3hW9YPKvS"
      },
      "outputs": [],
      "source": [
        "visualize_predictions(model_catheter, valid_test_paths, valid_test_cathetr_paths, device, num_samples=5, clip_limit=2, figsize=(20, 10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xYWsDaC4PObY"
      },
      "outputs": [],
      "source": [
        "!cp -r /content/experiments/catheter_unet_20250605_075915 /content/drive/MyDrive/msc_uhasselt/experiments/catheter_unet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E82IFVhqKQ4I"
      },
      "outputs": [],
      "source": [
        "from math import pi\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import albumentations as A\n",
        "\n",
        "train_transform = A.Compose([\n",
        "    # --- Spatial Augmentations ---\n",
        "    A.HorizontalFlip(p=0.3),  # Safe for atrial anatomy\n",
        "    A.Rotate(limit=15, p=0.2, border_mode=cv2.BORDER_CONSTANT),\n",
        "\n",
        "    # Finer GridDistortion (controlled warping)\n",
        "\n",
        "\n",
        "    # Optional: Combined with ElasticTransform\n",
        "    A.OneOf([\n",
        "        A.ElasticTransform(\n",
        "                alpha=300,\n",
        "                sigma=10,\n",
        "                interpolation=cv2.INTER_LINEAR,\n",
        "                approximate=False,\n",
        "                same_dxdy=True,\n",
        "                mask_interpolation=cv2.INTER_NEAREST,\n",
        "                noise_distribution=\"gaussian\",\n",
        "                keypoint_remapping_method=\"mask\",\n",
        "                border_mode=cv2.BORDER_CONSTANT,\n",
        "                fill=0,\n",
        "                fill_mask=0,\n",
        "                p=0.3\n",
        "),\n",
        "        A.GridDistortion(distort_limit=0.1, p=0.3)  # Even subtler variant\n",
        "    ], p=0.4),\n",
        "\n",
        "    # --- Intensity Augmentations ---\n",
        "    # A.CLAHE(clip_limit=2.0, p=0.3),\n",
        "    A.RandomBrightnessContrast(\n",
        "        brightness_limit=(-0.1, 0.1),\n",
        "        contrast_limit=(-0.1, 0.1),\n",
        "        p=0.4\n",
        "    ),\n",
        "    A.GaussNoise(std_range=(0.01, 0.05), p=0.2),\n",
        "    # --- Normalization ---\n",
        "    A.Normalize(mean=(0.485), std=(0.229)),\n",
        "    A.ToTensorV2(),\n",
        "])\n",
        "\n",
        "val_transform = A.Compose([\n",
        "    A.Normalize(mean=(0.485), std=(0.229)),\n",
        "    A.ToTensorV2(),\n",
        "])\n",
        "\n",
        "\n",
        "\n",
        "train_dataset_atria_seg = SegmentationDataset(\n",
        "    image_paths=valid_images_paths,\n",
        "    mask_paths=valid_atrial_paths,\n",
        "    image_size=960,\n",
        "    transform=val_transform,\n",
        "    apply_clahe=True,\n",
        "    clahe_limit=2 # Atrium needs higher clahe\n",
        ")\n",
        "\n",
        "val_dataset_atria_seg = SegmentationDataset(\n",
        "    image_paths=valid_test_paths,\n",
        "    mask_paths=valid_test_atrial_paths,\n",
        "    image_size=960,\n",
        "    transform=val_transform,\n",
        "    apply_clahe=True,\n",
        "    clahe_limit=2\n",
        ")\n",
        "\n",
        "train_data_loader = DataLoader(train_dataset_atria_seg, batch_size=5, shuffle=True, pin_memory=True)\n",
        "val_data_loader = DataLoader(val_dataset_atria_seg, batch_size=4, shuffle=False, pin_memory=True)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jNK5DTDpWjnm"
      },
      "outputs": [],
      "source": [
        "\n",
        "img, mask = train_dataset_atria_seg[0]\n",
        "print(img.shape, mask.shape)\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "# Access the image tensor at index 0, remove channel dim, convert to numpy\n",
        "plt.imshow(img.squeeze().numpy(), cmap='gray')\n",
        "plt.title('Image')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "# Access the mask tensor at index 1, remove channel dim, convert to numpy\n",
        "plt.imshow(mask.squeeze().numpy(), cmap='gray')\n",
        "plt.title('Mask')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VD1vp_jAL9Xk"
      },
      "outputs": [],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # Initialize components outside the Trainer class's __main__ block\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model_atrium_unet_2plus = load_base_unetmodel()\n",
        "    # Data loaders are defined above this __main__ block\n",
        "    # train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=4)\n",
        "    # val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False, num_workers=2)\n",
        "\n",
        "    # Train\n",
        "    trainer = Trainer(\n",
        "        model=model_atrium_unet_2plus,\n",
        "        train_loader=train_data_loader, # Use the data loaders defined outside __main__\n",
        "        val_loader=val_data_loader,   # Use the data loaders defined outside __main__\n",
        "        device=device,\n",
        "        num_epochs=100,\n",
        "        experiment_name=\"atrium_unet_focal\",\n",
        "        loss_type='hybrid'\n",
        "    )\n",
        "    # The train method now returns the best weights state dictionary\n",
        "    best_weights_state_dict_atrium = trainer.train()\n",
        "\n",
        "    # Load best weights for inference\n",
        "    # model1.load_state_dict(best_weights_state_dict)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # Initialize components outside the Trainer class's __main__ block\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model_atrium_unet_2plus = load_base_unetmodel()\n",
        "    # Data loaders are defined above this __main__ block\n",
        "    # train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=4)\n",
        "    # val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False, num_workers=2)\n",
        "\n",
        "    # Train\n",
        "    trainer = Trainer(\n",
        "        model=model_atrium_unet_2plus,\n",
        "        train_loader=train_data_loader, # Use the data loaders defined outside __main__\n",
        "        val_loader=val_data_loader,   # Use the data loaders defined outside __main__\n",
        "        device=device,\n",
        "        num_epochs=100,\n",
        "        experiment_name=\"atrium_unet-dice\",\n",
        "        loss_type='dice'\n",
        "    )\n",
        "    # The train method now returns the best weights state dictionary\n",
        "    best_weights_state_dict_atrium = trainer.train()\n",
        "\n",
        "    # Load best weights for inference\n",
        "    # model1.load_state_dict(best_weights_state_dict)"
      ],
      "metadata": {
        "id": "nwiCkAR0bFOr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r /content/experiments/catheter_unet_dice_20250617_084412 /content/drive/MyDrive/msc_uhasselt/experiments/catheter_unet/"
      ],
      "metadata": {
        "id": "7qR8cEtqv22P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NplBQ7CJxZ89"
      },
      "outputs": [],
      "source": [
        "free_gpu_memory()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Xn2UBk5AxH1Y"
      },
      "outputs": [],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # Initialize components outside the Trainer class's __main__ block\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model_atrium_unet_2plus = load_base_unetmodel()\n",
        "    # Data loaders are defined above this __main__ block\n",
        "    # train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=4)\n",
        "    # val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False, num_workers=2)\n",
        "\n",
        "    # Train\n",
        "    trainer = Trainer(\n",
        "        model=model_atrium_unet_2plus,\n",
        "        train_loader=train_data_loader, # Use the data loaders defined outside __main__\n",
        "        val_loader=val_data_loader,   # Use the data loaders defined outside __main__\n",
        "        device=device,\n",
        "        num_epochs=100,\n",
        "        experiment_name=\"atrium_unet_bce_dice\",\n",
        "        loss_type='bced'\n",
        "    )\n",
        "    # The train method now returns the best weights state dictionary\n",
        "    best_weights_state_dict_atrium = trainer.train()\n",
        "\n",
        "    # Load best weights for inference\n",
        "    # model1.load_state_dict(best_weights_state_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hlJUcwkclHNl"
      },
      "outputs": [],
      "source": [
        "!cp -r /content/experiments/atrium_unet_2plus_no_augmentation_20250614_115800 /content/drive/MyDrive/msc_uhasselt/experiments/atrium_unet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D5ZMjYGP88Z6"
      },
      "outputs": [],
      "source": [
        "model_atrium_unet_2plus.load_state_dict(best_weights_state_dict_atrium)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Obx_0thQmdmU"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n",
        "class UNet3PlusDeepSupTrainer(Trainer):\n",
        "    def __init__(self, model, train_loader, val_loader, device, num_epochs=100, experiment_name=\"\"):\n",
        "        super().__init__(model, train_loader, val_loader, device, num_epochs, experiment_name)\n",
        "        # Use same optimizer, scheduler, etc.\n",
        "        # Expect self.criterion to accept prediction & mask pairs\n",
        "\n",
        "        # Weights for each deep supervision output, adjust as needed\n",
        "        self.ds_weights = [0.5, 0.25, 0.125, 0.0625, 0.0625]\n",
        "\n",
        "    def train_epoch(self, epoch):\n",
        "        self.model.train()\n",
        "        epoch_loss = 0.0\n",
        "\n",
        "        with tqdm(self.train_loader, unit=\"batch\", desc=f\"Epoch {epoch+1}/{self.num_epochs} [Train]\") as pbar:\n",
        "            for images, masks in pbar:\n",
        "                images = images.to(self.device, non_blocking=True)\n",
        "                masks = masks.to(self.device, non_blocking=True)\n",
        "\n",
        "                # Mixed precision forward\n",
        "                with autocast():\n",
        "                    outs = self.model(images)  # d1, d2, d3, d4, d5\n",
        "                    # All outputs are same shape as mask\n",
        "                    total_loss = 0\n",
        "                    for idx, out in enumerate(outs):\n",
        "                        total_loss += self.ds_weights[idx] * self.criterion(out, masks)\n",
        "\n",
        "                self.optimizer.zero_grad()\n",
        "                self.scaler.scale(total_loss).backward()\n",
        "                self.scaler.step(self.optimizer)\n",
        "                self.scaler.update()\n",
        "\n",
        "                epoch_loss += total_loss.item()\n",
        "                pbar.set_postfix({\"loss\": f\"{total_loss.item():.4f}\", \"lr\": f\"{self.optimizer.param_groups[0]['lr']:.2e}\"})\n",
        "\n",
        "        return epoch_loss / len(self.train_loader)\n",
        "\n",
        "    def validate_epoch(self, epoch):\n",
        "        self.model.eval()\n",
        "        val_loss = 0.0\n",
        "        dice_scores = []\n",
        "\n",
        "        with tqdm(self.val_loader, unit=\"batch\", desc=f\"Epoch {epoch+1}/{self.num_epochs} [Val]\") as pbar:\n",
        "            with torch.no_grad():\n",
        "                for images, masks in pbar:\n",
        "                    images = images.to(self.device, non_blocking=True)\n",
        "                    masks = masks.to(self.device, non_blocking=True)\n",
        "\n",
        "                    with autocast():\n",
        "                        outs = self.model(images)\n",
        "                        total_loss = 0\n",
        "                        for idx, out in enumerate(outs):\n",
        "                            total_loss += self.ds_weights[idx] * self.criterion(out, masks)\n",
        "\n",
        "                    val_loss += total_loss.item()\n",
        "\n",
        "                    # Use the first output (highest resolution) for Dice calculation\n",
        "                    preds = torch.sigmoid(outs[0])\n",
        "                    dice = self._calculate_dice(preds.cpu(), masks.cpu())\n",
        "                    dice_scores.append(dice)\n",
        "\n",
        "                    pbar.set_postfix({\"val_loss\": f\"{total_loss.item():.4f}\", \"dice\": f\"{dice:.4f}\"})\n",
        "\n",
        "        mean_dice = np.mean(dice_scores)\n",
        "        return val_loss / len(self.val_loader), mean_dice\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QKWtUNIZbHnR"
      },
      "outputs": [],
      "source": [
        "free_gpu_memory()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0gRDQe2e9Erq"
      },
      "outputs": [],
      "source": [
        "visualize_predictions(model_atrium_unet_2plus, valid_test_paths, valid_test_atrial_paths, device, num_samples=5, figsize=(20, 10), clip_limit=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_SsBy87TirPv"
      },
      "outputs": [],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # Initialize components outside the Trainer class's __main__ block\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model_atrium = load_base_unetmodel()\n",
        "    # Data loaders are defined above this __main__ block\n",
        "    # train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=4)\n",
        "    # val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False, num_workers=2)\n",
        "\n",
        "    # Train\n",
        "    trainer = Trainer(\n",
        "        model=model_atrium,\n",
        "        train_loader=train_data_loader, # Use the data loaders defined outside __main__\n",
        "        val_loader=val_data_loader,   # Use the data loaders defined outside __main__\n",
        "        device=device,\n",
        "        # num_epochs=150,\n",
        "        experiment_name=\"atrium_unet_bce_loss\", loss_type='bce'\n",
        "    )\n",
        "    # The train method now returns the best weights state dictionary\n",
        "    best_weights_state_dict_atrium = trainer.train()\n",
        "\n",
        "    # Load best weights for inference\n",
        "    # model1.load_state_dict(best_weights_state_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cNGn-msc6QQP"
      },
      "outputs": [],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # Initialize components outside the Trainer class's __main__ block\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model_atrium = load_base_unetmodel()\n",
        "    # Data loaders are defined above this __main__ block\n",
        "    # train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=4)\n",
        "    # val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False, num_workers=2)\n",
        "\n",
        "    # Train\n",
        "    trainer = Trainer(\n",
        "        model=model_atrium,\n",
        "        train_loader=train_data_loader, # Use the data loaders defined outside __main__\n",
        "        val_loader=val_data_loader,   # Use the data loaders defined outside __main__\n",
        "        device=device,\n",
        "        # num_epochs=150,\n",
        "        experiment_name=\"atrium_unet_focal_loss\", loss_type='focal'\n",
        "    )\n",
        "    # The train method now returns the best weights state dictionary\n",
        "    best_weights_state_dict_atrium = trainer.train()\n",
        "\n",
        "    # Load best weights for inference\n",
        "    # model1.load_state_dict(best_weights_state_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hqlXESrQ_r1a"
      },
      "outputs": [],
      "source": [
        "!cp -r /content/experiments/atrium_unet_focal_loss_20250610_101136 /content/drive/MyDrive/msc_uhasselt/experiments/atrium_unet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9-9z4IKkit7Y"
      },
      "outputs": [],
      "source": [
        "model_atrium.load_state_dict(best_weights_state_dict_atrium)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kamH4kCiGepm"
      },
      "outputs": [],
      "source": [
        "visualize_predictions(model_atrium, valid_test_paths, valid_test_atrial_paths, device, num_samples=5, figsize=(20, 10), clip_limit=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XFHee2SMB6_h"
      },
      "outputs": [],
      "source": [
        "\n",
        "# train_transform = A.Compose([\n",
        "#     # --- Spatial Augmentations ---\n",
        "#     A.HorizontalFlip(p=0.3),  # Safe for atrial anatomy\n",
        "\n",
        "#     # Finer GridDistortion (controlled warping)\n",
        "\n",
        "#     A.Rotate(limit=15, p=0.4, border_mode=cv2.BORDER_CONSTANT),\n",
        "#     A.GridDistortion(\n",
        "#         num_steps=5,           # Smoother transitions (default=5)\n",
        "#         distort_limit=0.15,    # Reduced from 0.3 (gentler distortion)\n",
        "#         interpolation=cv2.INTER_LINEAR,\n",
        "#         border_mode=cv2.BORDER_CONSTANT,\n",
        "#         p=0.3\n",
        "#     ),\n",
        "\n",
        "#     # Optional: Combined with ElasticTransform\n",
        "#     A.OneOf([\n",
        "#         A.ElasticTransform(\n",
        "#             alpha=120,         # Magnitude of distortion (reduced from default)\n",
        "#             sigma=120 * 0.05,  # Smoothness (sigma=alpha*factor)\n",
        "#             # alpha_affine=0,    # No longer a parameter - removed\n",
        "#             p=0.5\n",
        "#         ),\n",
        "#         A.GridDistortion(distort_limit=0.1, p=0.5)  # Even subtler variant\n",
        "#     ], p=0.4),\n",
        "\n",
        "#     # --- Intensity Augmentations ---\n",
        "#     # A.CLAHE(clip_limit=2.0, p=0.3),\n",
        "#     A.RandomBrightnessContrast(\n",
        "#         brightness_limit=(-0.1, 0.1),\n",
        "#         contrast_limit=(-0.1, 0.1),\n",
        "#         p=0.4\n",
        "#     ),\n",
        "#     A.GaussNoise(std_range=(0.01, 0.02), p=0.2),\n",
        "#     # --- Normalization ---\n",
        "#     A.Normalize(mean=(0.485), std=(0.229)),\n",
        "#     A.ToTensorV2(),\n",
        "# ])\n",
        "\n",
        "# val_transform = A.Compose([\n",
        "#     A.Normalize(mean=(0.485), std=(0.229)),\n",
        "#     A.ToTensorV2(),\n",
        "# ])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# train_dataset = SegmentationDataset(\n",
        "#     image_paths=valid_images_paths,\n",
        "#     mask_paths=valid_cathetr_paths,\n",
        "#     image_size=960,\n",
        "#     transform=train_transform,\n",
        "#     apply_clahe=True\n",
        "# )\n",
        "\n",
        "# val_dataset = SegmentationDataset(\n",
        "#     image_paths=valid_test_paths,\n",
        "#     mask_paths=valid_test_cathetr_paths,\n",
        "#     image_size=960,\n",
        "#     transform=val_transform,\n",
        "#     apply_clahe=True\n",
        "# )\n",
        "\n",
        "# train_data_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, pin_memory=True)\n",
        "# val_data_loader = DataLoader(val_dataset, batch_size=4, shuffle=False,  pin_memory=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v5muiUaTr0jA"
      },
      "outputs": [],
      "source": [
        "free_gpu_memory()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bFIHdg15p1RB"
      },
      "outputs": [],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # Initialize components outside the Trainer class's __main__ block\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model_atrium = load_base_unetmodel()\n",
        "    # Data loaders are defined above this __main__ block\n",
        "    # train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=4)\n",
        "    # val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False, num_workers=2)\n",
        "\n",
        "    # Train\n",
        "    trainer = Trainer(\n",
        "        model=model_atrium,\n",
        "        train_loader=train_data_loader, # Use the data loaders defined outside __main__\n",
        "        val_loader=val_data_loader,   # Use the data loaders defined outside __main__\n",
        "        device=device,\n",
        "        # num_epochs=150,\n",
        "        experiment_name=\"atrium_unet_bce_loss\", loss_type='bce'\n",
        "    )\n",
        "    # The train method now returns the best weights state dictionary\n",
        "    best_weights_state_dict_atrium = trainer.train()\n",
        "\n",
        "    # Load best weights for inference\n",
        "    # model1.load_state_dict(best_weights_state_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VWJAl8GnbBbP"
      },
      "outputs": [],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # Initialize components outside the Trainer class's __main__ block\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model_atrium = load_base_unetmodel()\n",
        "    # Data loaders are defined above this __main__ block\n",
        "    # train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=4)\n",
        "    # val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False, num_workers=2)\n",
        "\n",
        "    # Train\n",
        "    trainer = Trainer(\n",
        "        model=model_atrium,\n",
        "        train_loader=train_data_loader, # Use the data loaders defined outside __main__\n",
        "        val_loader=val_data_loader,   # Use the data loaders defined outside __main__\n",
        "        device=device,\n",
        "        # num_epochs=150,\n",
        "        experiment_name=\"atrium_unet_focal_update_loss\", loss_type='bce'\n",
        "    )\n",
        "    # The train method now returns the best weights state dictionary\n",
        "    best_weights_state_dict_atrium = trainer.train()\n",
        "\n",
        "    # Load best weights for inference\n",
        "    # model1.load_state_dict(best_weights_state_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZjUEB8-BFiR7"
      },
      "outputs": [],
      "source": [
        "!cp -r /content/experiments/atrium_unet_focal_update_loss_20250610_151901  /content/drive/MyDrive/msc_uhasselt/experiments/atrium_unet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tDSgMLIYF1b5"
      },
      "outputs": [],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # Initialize components outside the Trainer class's __main__ block\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model_atrium = load_base_unetmodel()\n",
        "    # Data loaders are defined above this __main__ block\n",
        "    # train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=4)\n",
        "    # val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False, num_workers=2)\n",
        "\n",
        "    # Train\n",
        "    trainer = Trainer(\n",
        "        model=model_atrium,\n",
        "        train_loader=train_data_loader, # Use the data loaders defined outside __main__\n",
        "        val_loader=val_data_loader,   # Use the data loaders defined outside __main__\n",
        "        device=device,\n",
        "        # num_epochs=150,\n",
        "        experiment_name=\"atrium_unet_bce_loss\", loss_type='hybrid'\n",
        "    )\n",
        "    # The train method now returns the best weights state dictionary\n",
        "    best_weights_state_dict_atrium = trainer.train()\n",
        "\n",
        "    # Load best weights for inference\n",
        "    # model1.load_state_dict(best_weights_state_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tQ5zWIx_ABPX"
      },
      "outputs": [],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # Initialize components outside the Trainer class's __main__ block\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model_cath_deep_sup = UNet_3Plus_DeepSup(in_channels=1)\n",
        "    # Data loaders are defined above this __main__ block\n",
        "    # train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=4)\n",
        "    # val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False, num_workers=2)\n",
        "\n",
        "    # Train\n",
        "    trainer = UNet3PlusDeepSupTrainer(\n",
        "        model=model_cath_deep_sup,\n",
        "        train_loader=train_data_loader, # Use the data loaders defined outside __main__\n",
        "        val_loader=val_data_loader,   # Use the data loaders defined outside __main__\n",
        "        device=device,\n",
        "        # num_epochs=150,\n",
        "        experiment_name=\"catheter_unet_deep_sup\"\n",
        "    )\n",
        "    # The train method now returns the best weights state dictionary\n",
        "    best_weights_state_dict_cath_deep_sup = trainer.train()\n",
        "\n",
        "    # Load best weights for inference\n",
        "    # model1.load_state_dict(best_weights_state_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JArkiCfKAG7y"
      },
      "outputs": [],
      "source": [
        "visualize_predictions(model_cath_deep_sup, valid_test_paths, valid_test_cathetr_paths, device, num_samples=5, clip_limit=3.5, figsize=(20, 10), deep_sup=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jCrfUEkWBEMM"
      },
      "source": [
        "### Get Masks from trained"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vcyTy5sBAyHs"
      },
      "outputs": [],
      "source": [
        "# !cp -r /content/experiments/catheter_unet_deep_sup_20250527_043857 /content/drive/MyDrive/msc_uhasselt/experiments/catheter_unet/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n7_vM-zOBhez"
      },
      "outputs": [],
      "source": [
        "# Ensure models are saved correctly\n",
        "unet_atrium_model_load = UNet_3Plus_DeepSup(in_channels=1)\n",
        "# Load the entire checkpoint dictionary first\n",
        "checkpoint = torch.load('/content/drive/MyDrive/msc_uhasselt/experiments/atrium_unet/atrium_unet_deep_sup_20250526_235713/models/best_model.pth', weights_only=False)\n",
        "\n",
        "unet_atrium_model_load.load_state_dict(checkpoint['model_state_dict'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8YHvV46DFTHN"
      },
      "outputs": [],
      "source": [
        "unet_cath_model_load = UNet_3Plus_DeepSup(in_channels=1)\n",
        "checkpoint = torch.load('/content/drive/MyDrive/msc_uhasselt/experiments/catheter_unet/catheter_unet_deep_sup_20250527_043857/models/best_model.pth', weights_only=False)\n",
        "\n",
        "unet_cath_model_load.load_state_dict(checkpoint['model_state_dict'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4xZ2hb2UMpDq"
      },
      "outputs": [],
      "source": [
        "unet_atrium_base_model = UNet_3Plus(in_channels=1)\n",
        "checkpoint = torch.load('/content/drive/MyDrive/msc_uhasselt/experiments/atrium_unet/atrium_unet_20250526_180651/models/best_model.pth', weights_only=False)\n",
        "\n",
        "unet_atrium_base_model.load_state_dict(checkpoint['model_state_dict'])\n",
        "\n",
        "unet_cath_base_model = UNet_3Plus(in_channels=1)\n",
        "checkpoint = torch.load('/content/drive/MyDrive/msc_uhasselt/experiments/catheter_unet/catheter_unet_20250526_131827/models/best_model.pth', weights_only=False)\n",
        "\n",
        "unet_cath_base_model.load_state_dict(checkpoint['model_state_dict'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SXVRoj8xCfge"
      },
      "outputs": [],
      "source": [
        "unet_2plus_cath = load_base_unetmodel()\n",
        "checkpoint = torch.load('/content/drive/MyDrive/msc_uhasselt/experiments/catheter_unet/catheter_unet_2plus_20250606_100927/models/best_model.pth', weights_only=False)\n",
        "unet_2plus_cath.load_state_dict(checkpoint['model_state_dict'])\n",
        "\n",
        "unet_2plus_cath_noaug = load_base_unetmodel()\n",
        "checkpoint = torch.load('/content/drive/MyDrive/msc_uhasselt/experiments/catheter_unet/catheter_unet_2plus_20250605_233907/models/best_model.pth', weights_only=False)\n",
        "unet_2plus_cath_noaug.load_state_dict(checkpoint['model_state_dict'])\n",
        "\n",
        "\n",
        "unet_2plus_atrium = load_base_unetmodel()\n",
        "checkpoint = torch.load('/content/drive/MyDrive/msc_uhasselt/experiments/atrium_unet/atrium_unet_2plus_20250606_073341/models/best_model.pth', weights_only=False)\n",
        "unet_2plus_atrium.load_state_dict(checkpoint['model_state_dict'])\n",
        "\n",
        "\n",
        "unet_cath_no_clahe = load_base_unetmodel()\n",
        "checkpoint = torch.load('/content/drive/MyDrive/msc_uhasselt/experiments/catheter_unet/catheter_unet_2plus_no_clahe_20250608_155846/models/best_model.pth', weights_only=False)\n",
        "unet_cath_no_clahe.load_state_dict(checkpoint['model_state_dict'])\n",
        "\n",
        "unet_atrium_no_clahe = load_base_unetmodel()\n",
        "checkpoint = torch.load('/content/drive/MyDrive/msc_uhasselt/experiments/atrium_unet/atrium_unet_no_clahe_20250608_174402/models/best_model.pth', weights_only=False)\n",
        "unet_atrium_no_clahe.load_state_dict(checkpoint['model_state_dict'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aR5A-t3GQ5vV"
      },
      "outputs": [],
      "source": [
        "unet_atrium_bce = load_base_unetmodel()\n",
        "checkpoint = torch.load('/content/drive/MyDrive/msc_uhasselt/experiments/atrium_unet/atrium_unet_bce_loss_20250610_115239/models/best_model.pth', weights_only=False)\n",
        "unet_atrium_bce.load_state_dict(checkpoint['model_state_dict'])\n",
        "\n",
        "unet_cath_bce = load_base_unetmodel()\n",
        "checkpoint = torch.load('/content/drive/MyDrive/msc_uhasselt/experiments/catheter_unet/catheter_unet_bce_20250609_180115/models/best_model.pth', weights_only=False)\n",
        "unet_cath_bce.load_state_dict(checkpoint['model_state_dict'])\n",
        "\n",
        "\n",
        "unet_atrium_focal = load_base_unetmodel()\n",
        "checkpoint = torch.load('/content/drive/MyDrive/msc_uhasselt/experiments/atrium_unet/atrium_unet_focal_update_loss_20250610_151901/models/best_model.pth', weights_only=False)\n",
        "unet_atrium_focal.load_state_dict(checkpoint['model_state_dict'])\n",
        "\n",
        "unet_cath_focal = load_base_unetmodel()\n",
        "checkpoint = torch.load('/content/drive/MyDrive/msc_uhasselt/experiments/catheter_unet/catheter_unet_2plus_focal_loss_20250609_220416/models/best_model.pth', weights_only=False)\n",
        "unet_cath_focal.load_state_dict(checkpoint['model_state_dict'])\n",
        "\n",
        "# unet_atrium_hybrid = load_base_unetmodel()\n",
        "# checkpoint = torch.load('/content/drive/MyDrive/msc_uhasselt/experiments/atrium_unet/atrium_unet_2plus_hybrid_loss_20250609_234508/models/best_model.pth', weights_only=False)\n",
        "# une_atrium_focal.load_state_dict(checkpoint['model_state_dict'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NC4N3Q8_aOBv"
      },
      "outputs": [],
      "source": [
        "# !cp -r /content/experiments/atrium_unet_focal_loss_20250610_101136 /content/drive/MyDrive/msc_uhasselt/experiments/atrium_unet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R2758DrhDv3V"
      },
      "outputs": [],
      "source": [
        "visualize_predictions(unet_2plus_cath,\n",
        "                      valid_test_paths,\n",
        "                      valid_test_cathetr_paths,\n",
        "                      device, num_samples=5,\n",
        "                      clip_limit=2,\n",
        "                      figsize=(20, 12),\n",
        "                      model_name='unet++')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1kAvu9oeFlyf"
      },
      "outputs": [],
      "source": [
        "visualize_predictions(unet_cath_no_clahe,\n",
        "                      valid_test_paths,\n",
        "                      valid_test_cathetr_paths,\n",
        "                      device,\n",
        "                      num_samples=5,\n",
        "                      # clip_limit=4.1,\n",
        "                      figsize=(20, 10),\n",
        "                      model_name='unet++')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7o65GV6dDYER"
      },
      "outputs": [],
      "source": [
        "visualize_predictions(unet_2plus_atrium,\n",
        "                      valid_test_paths,\n",
        "                      valid_test_atrial_paths,\n",
        "                      device,\n",
        "                      num_samples=5,\n",
        "                      clip_limit=2,\n",
        "                      figsize=(20, 12),\n",
        "                      model_name='unet++')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g0RVJ4Z-KVgm"
      },
      "outputs": [],
      "source": [
        "def get_individual_masks(image_paths, unet_model, device, clahe=None, clip=2, model_name='unet_deep_sup'):\n",
        "    all_predictions = []\n",
        "    clahe_images = []\n",
        "\n",
        "    for image_path in image_paths:\n",
        "        mask, clahe_image = predict_catheter_segmentation(image_path, unet_model, device, clip=clip, model_name=model_name)\n",
        "        all_predictions.append(mask)\n",
        "\n",
        "        if clahe:\n",
        "            clahe_images.append(clahe_image)\n",
        "\n",
        "    return np.array(all_predictions), np.array(clahe_images) if clahe else None\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WtZBK7IIK5k4"
      },
      "source": [
        "Get mask from pretained models\n",
        "* For both mask, their respective base UNet+++ and UNet+++ with deep supervision will be obtained\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0IsxlgDxNz1r"
      },
      "outputs": [],
      "source": [
        "def process_masks(image_paths,\n",
        "                  unet_cath_model,\n",
        "                  unet_atrium_model,\n",
        "                  device,\n",
        "                  clip=None,\n",
        "                  clip_atrium=None,\n",
        "                  model_name='unet_deep_sup',\n",
        "                  prob=False):\n",
        "    \"\"\"\n",
        "    Processes images to get predicted catheter and atrial masks using trained models.\n",
        "\n",
        "    Args:\n",
        "        image_paths (list[str]): List of paths to the images.\n",
        "        unet_cath_model: The trained model for catheter segmentation.\n",
        "        unet_atrium_model: The trained model for atrial segmentation.\n",
        "        device: The device to run the models on ('cuda' or 'cpu').\n",
        "        clip_atrium (float): CLAHE clip limit for atrium images.\n",
        "        deep_sup (bool): Whether the models use deep supervision.\n",
        "\n",
        "    Returns:\n",
        "        tuple: Contains four tensors:\n",
        "               - catheter_masks_tensor (torch.Tensor)\n",
        "               - atrial_masks_tensor (torch.Tensor)\n",
        "               - clahe_images (list[np.ndarray])\n",
        "    \"\"\"\n",
        "    catheter_masks = []\n",
        "    atrial_masks = []\n",
        "    clahe_images = []\n",
        "\n",
        "    for img_path in tqdm(image_paths, desc=\"Processing Images\"):\n",
        "        # Process for catheter mask\n",
        "        cath_mask, clahe_image = predict_catheter_segmentation(\n",
        "            img_path, unet_cath_model, device, model_name=model_name, prob=prob, clip=clip\n",
        "        )\n",
        "        catheter_masks.append(cath_mask)\n",
        "        clahe_images.append(clahe_image)\n",
        "\n",
        "        # Process for atrial mask\n",
        "        atrial_mask, _ = predict_catheter_segmentation(\n",
        "            img_path, unet_atrium_model, device, clip=clip_atrium, model_name=model_name, prob=prob\n",
        "        )\n",
        "        atrial_masks.append(atrial_mask)\n",
        "\n",
        "    # Convert lists of numpy arrays to single numpy arrays\n",
        "    catheter_masks_np = np.stack(catheter_masks)\n",
        "    atrial_masks_np = np.stack(atrial_masks)\n",
        "\n",
        "    # Convert numpy arrays to tensors\n",
        "    catheter_masks_tensor = convert_np_tensor(catheter_masks_np)\n",
        "    atrial_masks_tensor = convert_np_tensor(atrial_masks_np)\n",
        "\n",
        "\n",
        "    return catheter_masks_tensor, atrial_masks_tensor, clahe_images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6E-GIhkaRFZp"
      },
      "outputs": [],
      "source": [
        "def get_orginal_maks(train_paths, test_paths, size = 960):\n",
        "\n",
        "  return read_image_frompath(train_paths, size=size), read_image_frompath(test_paths, size=size)\n",
        "\n",
        "def get_binary_masks(masks):\n",
        "\n",
        "\n",
        "  return (masks > 0).float()\n",
        "\n",
        "def convert_np_tensor(np_array):\n",
        "\n",
        "  if isinstance(np_array, torch.Tensor):\n",
        "    return np_array\n",
        "  elif isinstance(np_array, np.ndarray):\n",
        "    return torch.from_numpy(np_array)\n",
        "  elif isinstance(np_array, list):\n",
        "    return torch.stack([torch.from_numpy(arr) for arr in np_array])\n",
        "  else:\n",
        "    raise ValueError(\"Unsupported data type\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gb6d0y0XODlg"
      },
      "outputs": [],
      "source": [
        "from tqdm.notebook import tqdm\n",
        "train_catheter_tensor_base, train_atrial_tensor_base, train_clahe_images = process_masks(valid_images_paths,\n",
        "                                                                                 unet_cath_base_model,\n",
        "                                                                                 unet_atrium_base_model,\n",
        "\n",
        "\n",
        "                                                                                 device, model_name='unet3+',\n",
        "\n",
        "                                                                                         clip=2,\n",
        "                                                                                         clip_atrium=3.5)\n",
        "\n",
        "test_catheter_tensor_base, test_atrial_tensor_base, test_clahe_images = process_masks(valid_test_paths,\n",
        "                                                                                 unet_cath_base_model,\n",
        "                                                                                 unet_atrium_base_model,\n",
        "                                                                                 device, model_name='unet3+',\n",
        "                                                                                      clip=2,\n",
        "                                                                                         clip_atrium=3.5\n",
        "\n",
        "                                                                                      )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ll329zHjQX7u"
      },
      "outputs": [],
      "source": [
        "train_catheter_tensor_ds, train_atrial_tensor_ds, _ = process_masks(valid_images_paths,\n",
        "                                                                                 unet_cath_model_load,\n",
        "                                                                                 unet_atrium_model_load,\n",
        "                                                                                 device, model_name='unet_deep_sup',\n",
        "                                                                    clip=2,\n",
        "                                                                                         clip_atrium=3.5)\n",
        "test_catheter_tensor_ds, test_atrial_tensor_ds, _ = process_masks(valid_test_paths,\n",
        "                                                                                 unet_cath_model_load,\n",
        "                                                                                 unet_atrium_model_load,\n",
        "                                                                                 device, model_name='unet_deep_sup',\n",
        "                                                                  clip=2,\n",
        "                                                                                         clip_atrium=3.5)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VYm8eBztlG0h"
      },
      "outputs": [],
      "source": [
        "train_catheter_tensor_u2plus, train_atrial_tensor_u2plus, _ = process_masks(valid_images_paths,\n",
        "                                                                                 unet_2plus_cath,\n",
        "                                                                                 unet_2plus_atrium,\n",
        "                                                                                 device, model_name='unet++')\n",
        "test_catheter_tensor_u2plus, test_atrial_tensor_u2plus, _ = process_masks(valid_test_paths,\n",
        "                                                                                 unet_2plus_cath,\n",
        "                                                                                 unet_2plus_atrium,\n",
        "                                                                                 device, model_name='unet++')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7sMoUHzGClvJ"
      },
      "outputs": [],
      "source": [
        "train_catheter_tensor_u2plus_no_clahe, train_atrial_tensor_u2plus_no_clahe, _ = process_masks(valid_images_paths,\n",
        "                                                                                 unet_cath_no_clahe,\n",
        "                                                                                 unet_atrium_no_clahe,\n",
        "                                                                                 device, model_name='unet++')\n",
        "test_catheter_tensor_u2plus_no_clahe, test_atrial_tensor_u2plus_no_clahe, _ = process_masks(valid_test_paths,\n",
        "                                                                                            unet_cath_no_clahe,\n",
        "                                                                                 unet_atrium_no_clahe,\n",
        "                                                                                            device, model_name='unet++')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FyIo2xXlUm_v"
      },
      "outputs": [],
      "source": [
        "test_catheter_tensor_bce, test_atrial_tensor_bce, _ = process_masks(valid_test_paths,\n",
        "                                                                                 unet_cath_bce,\n",
        "                                                                                 unet_atrium_bce,\n",
        "                                                                                 device, model_name='unet++',\n",
        "                                                                                clip=2, clip_atrium=2)\n",
        "\n",
        "test_catheter_tensor_focal, test_atrial_tensor_focal , _ = process_masks(valid_test_paths,\n",
        "                                                                                 unet_cath_focal,\n",
        "                                                                                 unet_atrium_focal,\n",
        "                                                                                 device, model_name='unet++',\n",
        "                                                                                clip=2, clip_atrium=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XnTfzFH3XBZc"
      },
      "outputs": [],
      "source": [
        "# !cp -r /content/experiments/atrium_unet_focal_loss_20250610_101136 /content/drive/MyDrive/msc_uhasselt/experiments/atrium_unet/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vLjms4qlRlHP"
      },
      "source": [
        "Load the ground truth masks for both the catheter and the right atria border, this will enable us to obtain validation (\"test\") metrics for the different segmentation models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_dkw6D4fT0Tz"
      },
      "outputs": [],
      "source": [
        "original_catheter_mask_train, original_catheter_mask_test = get_orginal_maks(valid_cathetr_paths, valid_test_cathetr_paths)\n",
        "\n",
        "original_atrial_mask_train, original_atrial_mask_test = get_orginal_maks(valid_atrial_paths, valid_test_atrial_paths)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HJqoF4oTVk3Q"
      },
      "outputs": [],
      "source": [
        "original_catheter_mask_train[0].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V-hW207eUd6q"
      },
      "outputs": [],
      "source": [
        "ground_truth_catheter_tensor_train = get_binary_masks(convert_np_tensor(original_catheter_mask_train))\n",
        "ground_truth_atrial_tensor_train = get_binary_masks(convert_np_tensor(original_atrial_mask_train))\n",
        "\n",
        "ground_truth_catheter_tensor_test = get_binary_masks(convert_np_tensor(original_catheter_mask_test))\n",
        "ground_truth_atrial_tensor_test = get_binary_masks(convert_np_tensor(original_atrial_mask_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gP_nbf2CkUPp"
      },
      "outputs": [],
      "source": [
        "clahe_images = np.stack(train_clahe_images + test_clahe_images)\n",
        "clahe_images.shape\n",
        "\n",
        "plt.imshow(clahe_images[0], cmap='gray')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IqF-TaEK5eAc"
      },
      "source": [
        "## Visually inspect some difficult images with UNet+++ with/wo deep suervision\n",
        "\n",
        "- Does deep supervision aid in identifying difficult regions??"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HqoEyoqm51J2"
      },
      "outputs": [],
      "source": [
        "difficult_images = ['IMG-0456-00001', 'IMG-0468-00001', 'IMG-0462-00001', 'IMG-0464-00001', 'IMG-0459-00001', 'IMG-0273-00001']\n",
        "# keep pathi if id in not in difficult_images\n",
        "difficult_path = [path for path in valid_test_paths if path.split('/')[-1].split('.')[0] in difficult_images]\n",
        "difficult_catheter_path = [path for path in valid_test_cathetr_paths if path.split('/')[-1].split('.')[0] in difficult_images]\n",
        "difficult_atrial_path = [path for path in valid_test_atrial_paths if path.split('/')[-1].split('.')[0] in difficult_images]\n",
        "\n",
        "# print(f\"Number of images: {len(difficult_path)}, path: {' '.join(difficult_path)}\")\n",
        "# print(f\"Number of catheter masks: {len(difficult_catheter_path)}, paths: {' '.join(difficult_catheter_path)}\")\n",
        "print(f\"Number of atrial masks: {len(difficult_atrial_path)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BSHu9Dd8-Gnj"
      },
      "outputs": [],
      "source": [
        "diff_cath_tensor_base, diff_atrial_tensor_base, diff_images = process_masks(difficult_path,\n",
        "                                                                                 unet_cath_base_model,\n",
        "                                                                                 unet_atrium_base_model,\n",
        "                                                                                 device, model_name='unet3+')\n",
        "diff_cath_tensor_ds, diff_atrial_tensor_ds, _ = process_masks(difficult_path,\n",
        "                                                              unet_cath_model_load,\n",
        "                                                              unet_atrium_model_load,\n",
        "                                                              device, model_name='unet_deep_sup')\n",
        "\n",
        "diff_cath_tensor_u2plus, diff_atrial_tensor_u2plus, _ = process_masks(difficult_path,\n",
        "                                                              unet_2plus_cath,\n",
        "                                                              unet_2plus_atrium,\n",
        "                                                              device, model_name='unet++')\n",
        "\n",
        "diff_cath_gt, diff_atrial_gt = get_orginal_maks(difficult_catheter_path, difficult_atrial_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZA5J1XKQ_kar"
      },
      "outputs": [],
      "source": [
        "diff_cath_gt = get_binary_masks(convert_np_tensor(diff_cath_gt))\n",
        "diff_atrial_gt = get_binary_masks(convert_np_tensor(diff_atrial_gt))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Y6qbOx0_56k"
      },
      "outputs": [],
      "source": [
        "type(diff_images[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pzpoLZjrqhLU"
      },
      "outputs": [],
      "source": [
        "from torchmetrics.functional.segmentation import dice_score, mean_iou\n",
        "\n",
        "def calculate_dice_score(y_true, y_pred):\n",
        "    score = dice_score(y_true, y_pred, num_classes=2,  average='micro')\n",
        "    # get average score\n",
        "    return score.cpu().numpy().mean()\n",
        "\n",
        "def calculate_iou_score(y_true, y_pred):\n",
        "    # Convert floating point tensors (0 or 1) to long integer type (0 or 1)\n",
        "    # mean_iou expects class indices or boolean\n",
        "    y_true = y_true.long()\n",
        "    y_pred = y_pred.long()\n",
        "    score = mean_iou(y_true, y_pred, include_background=False, num_classes=2)\n",
        "    # get average score\n",
        "    return score.cpu().numpy().mean()\n",
        "\n",
        "# Now call the function with the converted tensors\n",
        "calculate_iou_score(ground_truth_catheter_tensor_train, train_catheter_tensor_u2plus) # sanity chec should be == 1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bQJBLHRts1JQ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ThfQR5J_MtD"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def visualize_comparison(original, gt, pred_no_ds, pred_ds):\n",
        "    fig, axes = plt.subplots(1, 4, figsize=(20, 5))\n",
        "\n",
        "\n",
        "    dice_base = calculate_dice_score(torch.from_numpy(gt).unsqueeze(0), torch.from_numpy(pred_no_ds).unsqueeze(0))\n",
        "    dice_ds = calculate_dice_score(torch.from_numpy(gt).unsqueeze(0), torch.from_numpy(pred_ds).unsqueeze(0))\n",
        "\n",
        "    # Original Image\n",
        "    axes[0].imshow(original, cmap='gray')\n",
        "    axes[0].set_title(\"Input Image\", fontsize=9)\n",
        "    axes[0].axis('off')\n",
        "\n",
        "    # Ground Truth\n",
        "    axes[1].imshow(original, cmap='gray')\n",
        "    axes[1].imshow(gt, alpha=0.3, cmap='Blues')\n",
        "    axes[1].set_title(\"Ground Truth\", fontsize=9)\n",
        "    axes[1].axis('off')\n",
        "\n",
        "    # Without Deep Supervision\n",
        "    axes[2].imshow(original, cmap='gray')\n",
        "    axes[2].imshow(pred_no_ds, alpha=0.3, cmap='Reds')\n",
        "    axes[2].set_title(f\"UNet+++ (No DS) dice: {dice_base:.3f}\", fontsize=9)\n",
        "    axes[2].axis('off')\n",
        "\n",
        "    # With Deep Supervision\n",
        "    axes[3].imshow(original, cmap='gray')\n",
        "    axes[3].imshow(pred_ds, alpha=0.3, cmap='Greens')\n",
        "    axes[3].set_title(f\"UNet+++ (With DS) dice:{dice_ds:.3f}\", fontsize=9)\n",
        "    axes[3].axis('off')\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "idx = 3\n",
        "\n",
        "# Example usage:\n",
        "original = diff_images[idx]\n",
        "gt = diff_atrial_gt[idx].cpu().numpy()\n",
        "pred_no_ds = diff_atrial_tensor_base[idx].cpu().numpy()\n",
        "pred_ds = diff_atrial_tensor_u2plus[idx].cpu().numpy()\n",
        "visualize_comparison(original, gt, pred_no_ds, pred_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7OJPa5XMsz13"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rvB9i-ujHMYk"
      },
      "outputs": [],
      "source": [
        "def do_clahe(image, clip_limit=4.0):\n",
        "    clahe = cv2.createCLAHE(clipLimit=clip_limit, tileGridSize=(8, 8))\n",
        "    return clahe.apply(image)\n",
        "\n",
        "# create a function which creates randomly selects 5 images in the top tow row and their correponsing clahe in the bottom row\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Tca2BV7oNEF"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def visualize_random_images_with_clahe(image_paths: list[str],\n",
        "                                       target_size: int = 960,\n",
        "                                       num_samples: int = 5):\n",
        "    \"\"\"\n",
        "    Randomly selects and visualizes images with and without CLAHE.\n",
        "\n",
        "    Args:\n",
        "        image_paths (list[str]): List of paths to image files.\n",
        "        target_size (int): The size to resize the images to.\n",
        "        num_samples (int): The number of random images to display.\n",
        "    \"\"\"\n",
        "    if not image_paths:\n",
        "        print(\"No image paths provided.\")\n",
        "        return\n",
        "\n",
        "    # Ensure num_samples is not more than the number of available images\n",
        "    num_samples = min(num_samples, len(image_paths))\n",
        "\n",
        "    # Randomly select image paths\n",
        "    selected_paths = random.sample(image_paths, num_samples)\n",
        "\n",
        "    fig, axes = plt.subplots(2, num_samples, figsize=(num_samples * 4, 8))\n",
        "\n",
        "    # If only one sample, axes will be 1D - convert to 2D for consistency\n",
        "    if num_samples == 1:\n",
        "        axes = axes.reshape(2, 1)\n",
        "\n",
        "    for i, img_path in enumerate(selected_paths):\n",
        "        # Read original image\n",
        "        original_image = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "        if original_image is None:\n",
        "            print(f\"Warning: Could not read image at {img_path}\")\n",
        "            continue\n",
        "\n",
        "        # Resize original image to square\n",
        "        resized_original = resize_to_square(original_image, target_size)\n",
        "\n",
        "        # Apply CLAHE and resize to square\n",
        "        clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8, 8))\n",
        "        clahe_image = clahe.apply(original_image)\n",
        "        resized_clahe = resize_to_square(clahe_image, target_size)\n",
        "\n",
        "        # Plot original (resized) image\n",
        "        axes[0, i].imshow(resized_original, cmap='gray')\n",
        "        axes[0, i].set_title(f\"Original\", fontsize=10)\n",
        "        axes[0, i].axis('off')\n",
        "\n",
        "        # Plot CLAHE (resized) image\n",
        "        axes[1, i].imshow(resized_clahe, cmap='gray')\n",
        "        axes[1, i].set_title(\"CLAHE Applied\", fontsize=10)\n",
        "        axes[1, i].axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Example usage (assuming valid_images_paths is defined from your code)\n",
        "visualize_random_images_with_clahe(valid_images_paths, target_size=960, num_samples=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gpmR6F3qkgMx"
      },
      "outputs": [],
      "source": [
        "dice_atrium_base_train = calculate_dice_score(ground_truth_atrial_tensor_train, train_atrial_tensor_base)\n",
        "dice_atrium_base_test = calculate_dice_score(ground_truth_atrial_tensor_test, test_atrial_tensor_base)\n",
        "dice_atrium_ds_train = calculate_dice_score(ground_truth_atrial_tensor_train, train_atrial_tensor_ds)\n",
        "dice_atrium_ds_test = calculate_dice_score(ground_truth_atrial_tensor_test, test_atrial_tensor_ds)\n",
        "dice_atrium_u2plus_train = calculate_dice_score(ground_truth_atrial_tensor_train, train_atrial_tensor_u2plus)\n",
        "dice_atrium_u2plus_test = calculate_dice_score(ground_truth_atrial_tensor_test, test_atrial_tensor_u2plus)\n",
        "dice_atrium_u2plus_no_clahe_train = calculate_dice_score(ground_truth_atrial_tensor_train, train_atrial_tensor_u2plus_no_clahe)\n",
        "dice_atrium_u2plus_no_clahe_test = calculate_dice_score(ground_truth_atrial_tensor_test, test_atrial_tensor_u2plus_no_clahe)\n",
        "dice_atrium_bce_test = calculate_dice_score(ground_truth_atrial_tensor_test, test_atrial_tensor_bce)\n",
        "dice_atrium_focal_test = calculate_dice_score(ground_truth_atrial_tensor_test, test_atrial_tensor_focal)\n",
        "\n",
        "# IOU score for atrial models\n",
        "iou_atrium_base_train = calculate_iou_score(ground_truth_atrial_tensor_train, train_atrial_tensor_base)\n",
        "iou_atrium_base_test = calculate_iou_score(ground_truth_atrial_tensor_test, test_atrial_tensor_base)\n",
        "iou_atrium_ds_train = calculate_iou_score(ground_truth_atrial_tensor_train, train_atrial_tensor_ds)\n",
        "iou_atrium_ds_test = calculate_iou_score(ground_truth_atrial_tensor_test, test_atrial_tensor_ds)\n",
        "iou_atrium_u2plus_train = calculate_iou_score(ground_truth_atrial_tensor_train, train_atrial_tensor_u2plus)\n",
        "iou_atrium_u2plus_test = calculate_iou_score(ground_truth_atrial_tensor_test, test_atrial_tensor_u2plus)\n",
        "iou_atrium_u2plus_no_clahe_train = calculate_iou_score(ground_truth_atrial_tensor_train, train_atrial_tensor_u2plus_no_clahe)\n",
        "iou_atrium_u2plus_no_clahe_test = calculate_iou_score(ground_truth_atrial_tensor_test, test_atrial_tensor_u2plus_no_clahe)\n",
        "iou_atrium_bce_test = calculate_iou_score(ground_truth_atrial_tensor_test, test_atrial_tensor_bce)\n",
        "iou_atrium_focal_test = calculate_iou_score(ground_truth_atrial_tensor_test, test_atrial_tensor_focal)\n",
        "\n",
        "# Dice score for catheter models\n",
        "dice_cath_base_train = calculate_dice_score(ground_truth_catheter_tensor_train, train_catheter_tensor_base)\n",
        "dice_cath_base_test = calculate_dice_score(ground_truth_catheter_tensor_test, test_catheter_tensor_base)\n",
        "dice_cath_ds_train = calculate_dice_score(ground_truth_catheter_tensor_train, train_catheter_tensor_ds)\n",
        "dice_score_cath_ds_test = calculate_dice_score(ground_truth_catheter_tensor_test, test_catheter_tensor_ds)\n",
        "dice_cath_u2plus_train = calculate_dice_score(ground_truth_catheter_tensor_train, train_catheter_tensor_u2plus)\n",
        "dice_cath_u2plus_test = calculate_dice_score(ground_truth_catheter_tensor_test, test_catheter_tensor_u2plus)\n",
        "dice_cath_u2plus_no_clahe_train = calculate_dice_score(ground_truth_catheter_tensor_train, train_catheter_tensor_u2plus_no_clahe)\n",
        "dice_cath_u2plus_no_clahe_test = calculate_dice_score(ground_truth_catheter_tensor_test, test_catheter_tensor_u2plus_no_clahe)\n",
        "dice_cathe_bce_test = calculate_dice_score(ground_truth_catheter_tensor_test, test_catheter_tensor_bce)\n",
        "dice_cathe_focal_test = calculate_dice_score(ground_truth_catheter_tensor_test, test_catheter_tensor_focal)\n",
        "\n",
        "# IOU score for catheter models\n",
        "iou_cath_base_train = calculate_iou_score(ground_truth_catheter_tensor_train, train_catheter_tensor_base)\n",
        "iou_cath_base_test = calculate_iou_score(ground_truth_catheter_tensor_test, test_catheter_tensor_base)\n",
        "iou_cath_ds_train = calculate_iou_score(ground_truth_catheter_tensor_train, train_catheter_tensor_ds)\n",
        "iou_cath_ds_test = calculate_iou_score(ground_truth_catheter_tensor_test, test_catheter_tensor_ds)\n",
        "iou_cath_u2plus_train = calculate_iou_score(ground_truth_catheter_tensor_train, train_catheter_tensor_u2plus)\n",
        "iou_cath_u2plus_test = calculate_iou_score(ground_truth_catheter_tensor_test, test_catheter_tensor_u2plus)\n",
        "iou_cath_u2plus_no_clahe_train = calculate_iou_score(ground_truth_catheter_tensor_train, train_catheter_tensor_u2plus_no_clahe)\n",
        "iou_cath_u2plus_no_clahe_test = calculate_iou_score(ground_truth_catheter_tensor_test, test_catheter_tensor_u2plus_no_clahe)\n",
        "iou_cath_bce_test = calculate_iou_score(ground_truth_catheter_tensor_test, test_catheter_tensor_bce)\n",
        "iou_cath_focal_test = calculate_iou_score(ground_truth_catheter_tensor_test, test_catheter_tensor_focal)\n",
        "\n",
        "print(f'Model: Base UNet+++; Atrial Segmentation-- Dice: {dice_atrium_base_test:.4f}; mIoU: {iou_atrium_base_test:.4f} , CVC segmentation--Dice {dice_cath_base_test:.4f};   mIoU: {iou_cath_base_test:.4f}')\n",
        "print(f'==\\n')\n",
        "print(f'Model: UNet+++ with Deep Supervision; Atrial Segmentation--Dice: {dice_atrium_ds_test:.4f}; mIoU: {iou_atrium_ds_test:.4f} , CVC segmentation--Dice {dice_score_cath_ds_test:.4f};   mIoU: {iou_cath_ds_test:.4f}')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V15vwMm9qVFk"
      },
      "outputs": [],
      "source": [
        "print(f'UNet++ model: Atrial Segmentation -- Dice: {dice_atrium_u2plus_test:.4f}; mIoU: {iou_atrium_u2plus_test:.4f} , CVC segmentation--Dice {dice_cath_u2plus_test:.4f};   mIoU: {iou_cath_u2plus_test:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gzhv6RARFU24"
      },
      "outputs": [],
      "source": [
        "print(f'UNet++ model: Atrial Segmentation -- Dice: {dice_atrium_u2plus_no_clahe_test:.4f}; mIoU: {iou_atrium_u2plus_no_clahe_test:.4f} , CVC segmentation--Dice {dice_cath_u2plus_no_clahe_test:.4f};   mIoU: {iou_cath_u2plus_no_clahe_test:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T-JsWsYnYqbX"
      },
      "outputs": [],
      "source": [
        "print(f'UNet++ model: Atrial Segmentation -- Dice: {dice_atrium_bce_test:.4f}; mIoU: {iou_atrium_bce_test:.4f} , CVC segmentation--Dice {dice_cathe_bce_test:.4f};   mIoU: {iou_cath_bce_test:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_6wqnabxYzll"
      },
      "outputs": [],
      "source": [
        "print(f'UNet++ model: Atrial Segmentation -- Dice: {dice_atrium_focal_test:.4f}; mIoU: {iou_atrium_focal_test:.4f} , CVC segmentation--Dice {dice_cathe_focal_test:.4f};   mIoU: {iou_cath_focal_test:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "17kT53kNkz_I"
      },
      "outputs": [],
      "source": [
        "# Download and save utils file from git hub\n",
        "url = 'https://raw.githubusercontent.com/Blaise-bf/thesis-files/refs/heads/main/utills.py'\n",
        "\n",
        "save_file = 'utills.py'\n",
        "\n",
        "save_file_locally(url, save_file)\n",
        "\n",
        "save_file_locally('https://raw.githubusercontent.com/Blaise-bf/thesis-files/refs/heads/main/model_setup.py', 'model_setup.py')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-N-GYMLLqw6"
      },
      "source": [
        "### Calibration of thresh hold for segmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IeSPfaxfO9VU"
      },
      "outputs": [],
      "source": [
        "train_catheter_tensor_ds_prob, train_atrial_tensor_ds_prob, _ = process_masks(valid_images_paths,\n",
        "                                                                                 unet_cath_model_load,\n",
        "                                                                                 unet_atrium_model_load,\n",
        "                                                                                 device,\n",
        "                                                                              model_name='unet_deep_sup',\n",
        "                                                                              prob=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GRTdv93fRFzZ"
      },
      "outputs": [],
      "source": [
        "test_catheter_tensor_ds_prob, test_atrial_tensor_ds_prob, _ = process_masks(valid_test_paths,\n",
        "                                                                                 unet_cath_model_load,\n",
        "                                                                                 unet_atrium_model_load,\n",
        "                                                                                 device,\n",
        "                                                                                 model_name='unet_deep_sup',\n",
        "                                                                                   prob=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lh23SH6qRLza"
      },
      "outputs": [],
      "source": [
        "ground_truth_catheter_tensor_test.cpu().numpy().flatten()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KXrhojekL1Op"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "# Flatten to 1D arrays\n",
        "y_true_flat = ground_truth_catheter_tensor_test[0].cpu().numpy().flatten()  # shape [H*W]\n",
        "y_prob_flat = test_catheter_tensor_ds_prob[0].cpu().numpy().flatten()  # shape [H*W]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bgm3HiErTMXL"
      },
      "outputs": [],
      "source": [
        "from sklearn.calibration import calibration_curve\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "prob_true, prob_pred = calibration_curve(y_true_flat, y_prob_flat, n_bins=10)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(prob_pred, prob_true, marker='o', label='Your Model')\n",
        "plt.plot([0, 1], [0, 1], linestyle='--', label='Perfectly Calibrated')\n",
        "plt.xlabel('Predicted Probability')\n",
        "plt.ylabel('True Probability')\n",
        "plt.title('Calibration Curve')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qzsM6l0aT9Aw"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import precision_recall_curve, f1_score\n",
        "\n",
        "precision, recall, thresholds = precision_recall_curve(y_true_flat, y_prob_flat)\n",
        "\n",
        "# Calculate F1 scores\n",
        "f1_scores = 2 * (precision * recall) / (precision + recall + 1e-9)\n",
        "\n",
        "# Optimal threshold (max F1)\n",
        "optimal_idx = np.argmax(f1_scores[:-1])  # last threshold is added by sklearn\n",
        "optimal_threshold = thresholds[optimal_idx]\n",
        "\n",
        "print(f\"Optimal threshold: {optimal_threshold:.3f}\")\n",
        "print(f\"Max F1-score: {f1_scores[optimal_idx]:.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZOpy-lMDT2Hp"
      },
      "outputs": [],
      "source": [
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Reshape for sklearn (needs 2D input)\n",
        "X_calib = y_prob_flat.reshape(-1, 1)\n",
        "y_calib = y_true_flat\n",
        "\n",
        "# Platt scaling calibration\n",
        "calibrator = LogisticRegression(C=1e5, solver='lbfgs')\n",
        "calibrator.fit(X_calib, y_calib)\n",
        "\n",
        "# Calibrated probabilities\n",
        "y_prob_calibrated = calibrator.predict_proba(X_calib)[:, 1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-v8TNouUUOdP"
      },
      "outputs": [],
      "source": [
        "# Plot a historgam of predicted probabilities and color them by the minary labels from the ground truth\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.hist(y_prob_calibrated, bins=20, alpha=0.5, label='Predicted Probabilities')\n",
        "plt.xlabel('Predicted Probability')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Histogram of Predicted Probabilities')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4HUILQR3JTsU"
      },
      "source": [
        "### Non Deep Learning approach:\n",
        "\n",
        "This sections aims to setup a baseline model which will later on be compared to the deep learning approach. The general Idea is to mimic the logic used by radiologist to ascertain whether a catheter is adequately positioned or not. These is based on the following features.\n",
        "* Distance for catheter's tip to top of the upper border of the atrial mask\n",
        "* Dsitance from the catheter's tip to the lower border of the atrium (too short and two high is might indequate inadequate positioning)\n",
        "* Fraction of catheter in the upper third for the right atrail border. This tries to mimic the recommended location of CVC's\n",
        "*Inter section of over nnion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "64Ksqy6k2x9N"
      },
      "outputs": [],
      "source": [
        "from utills import extract_features, plot_catheter_feature_correlation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c2fT6oyHEc6I"
      },
      "outputs": [],
      "source": [
        "def combine_channels(chanel1, chanel2):\n",
        "\n",
        "    return torch.stack([chanel1, chanel2], dim = 1)\n",
        "\n",
        "def combine_tensor_batch(batch1, batch2):\n",
        "    return torch.cat([batch1, batch2], dim=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OIKdZdVwHR7R"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def extract_features_from_tensors(atrium_tensor, catheter_tensor, extract_features_func):\n",
        "    \"\"\"\n",
        "    Extracts features from batches of atrium and catheter masks.\n",
        "\n",
        "    Args:\n",
        "        atrium_tensor (torch.Tensor): Batch of atrium masks (N, H, W).\n",
        "        catheter_tensor (torch.Tensor): Batch of catheter masks (N, H, W).\n",
        "        extract_features_func (function): The function to extract features from individual masks.\n",
        "\n",
        "    Returns:\n",
        "        tuple: A tuple containing:\n",
        "            - features_df (pd.DataFrame): DataFrame containing the extracted features.\n",
        "            - error_indices (list): List of indices where feature extraction failed.\n",
        "    \"\"\"\n",
        "    all_features = []\n",
        "    error_indices = []\n",
        "\n",
        "    for i in range(atrium_tensor.shape[0]):\n",
        "        features = extract_features_func(atrium_tensor[i], catheter_tensor[i], index=i)\n",
        "        if features is not None:\n",
        "            all_features.append(features)\n",
        "        else:\n",
        "            error_indices.append(i)\n",
        "\n",
        "    if all_features:\n",
        "        features_df = pd.DataFrame(all_features)\n",
        "    else:\n",
        "        print(\"No features extracted successfully. DataFrame could not be created.\")\n",
        "        features_df = pd.DataFrame() # Return an empty DataFrame\n",
        "\n",
        "    return features_df, error_indices\n",
        "\n",
        "# Example usage (assuming atrium_tensor, catheter_tensor, and extract_features exist)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J3t7Sd89IVbs"
      },
      "outputs": [],
      "source": [
        "ground_truth_atrial_tensor_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2rsKNMGAH-xD"
      },
      "outputs": [],
      "source": [
        "catheter_tensor_original = combine_tensor_batch(ground_truth_catheter_tensor_train, ground_truth_catheter_tensor_test)\n",
        "atria_tensor_original = combine_tensor_batch(ground_truth_atrial_tensor_train, ground_truth_atrial_tensor_test)\n",
        "\n",
        "original_features_df, error_indices = extract_features_from_tensors(catheter_tensor_original,\n",
        "                                                                    atria_tensor_original,\n",
        "                                                                  extract_features)\n",
        "\n",
        "print(f\"Error indices: {error_indices}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LuCmXxF4IqNb"
      },
      "outputs": [],
      "source": [
        "catheter_tensor_base = combine_tensor_batch(train_catheter_tensor_base, test_catheter_tensor_base)\n",
        "atria_tensor_base = combine_tensor_batch(train_atrial_tensor_base, test_atrial_tensor_base)\n",
        "\n",
        "predicted_features_base_df, error_indices = extract_features_from_tensors(catheter_tensor_base,\n",
        "                                                        atria_tensor_base,\n",
        "                                                        extract_features)\n",
        "print(f\"Error indices: {error_indices}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0j8Cy5FxL9X6"
      },
      "outputs": [],
      "source": [
        "catheter_tensor_ds = combine_tensor_batch(train_catheter_tensor_ds, test_catheter_tensor_ds)\n",
        "atria_tensor_ds = combine_tensor_batch(train_atrial_tensor_ds, test_atrial_tensor_ds)\n",
        "\n",
        "predicted_features_ds_df , error_indices = extract_features_from_tensors(catheter_tensor_ds,\n",
        "                                                                         atria_tensor_ds,\n",
        "                                                                         extract_features)\n",
        "print(f\"Error indices: {error_indices}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SiNsFNXPF10r"
      },
      "outputs": [],
      "source": [
        "catheter_tensor_u2plus = combine_tensor_batch(train_catheter_tensor_u2plus, test_catheter_tensor_u2plus)\n",
        "atria_tensor_u2plus = combine_tensor_batch(train_atrial_tensor_u2plus, test_atrial_tensor_u2plus)\n",
        "\n",
        "predicted_features_u2plus_df, error_indices = extract_features_from_tensors(catheter_tensor_u2plus,\n",
        "                                                                             atria_tensor_u2plus,\n",
        "                                                                             extract_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b_Pa3eSWGC7Q"
      },
      "outputs": [],
      "source": [
        "catheter_tensor_u2plus_no_clahe = combine_tensor_batch(train_catheter_tensor_u2plus_no_clahe, test_catheter_tensor_u2plus_no_clahe)\n",
        "atria_tensor_u2plus_no_clahe = combine_tensor_batch(train_atrial_tensor_u2plus_no_clahe, test_atrial_tensor_u2plus_no_clahe)\n",
        "\n",
        "predicted_features_u2plus_no_clahe_df, error_indices = extract_features_from_tensors(catheter_tensor_u2plus_no_clahe,\n",
        "                                                                             atria_tensor_u2plus_no_clahe,\n",
        "                                                                              extract_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aSV3QrruCefW"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.patches import Rectangle, Circle, Patch\n",
        "from skimage.measure import regionprops\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def viz_spatial_features(atrium_mask, catheter_mask, features):\n",
        "    \"\"\"\n",
        "    Visualizes spatial features extracted from atrium and catheter masks.\n",
        "\n",
        "    Args:\n",
        "        atrium_mask: Atrium segmentation mask (NumPy array).\n",
        "        catheter_mask: Catheter segmentation mask (NumPy array).\n",
        "        features: Dictionary containing extracted features.\n",
        "    \"\"\"\n",
        "\n",
        "    # Assuming atrium_mask and catheter_mask are NumPy arrays\n",
        "    # Get region properties for the atrium to calculate minr, minc, maxr, maxc\n",
        "    atrium_props = regionprops(atrium_mask.astype(int))[0]\n",
        "    minr, minc, maxr, maxc = atrium_props.bbox\n",
        "    H = maxr - minr\n",
        "    width = maxc - minc  # Calculate width for bounding box\n",
        "\n",
        "    # Get region properties for the catheter to calculate centroid\n",
        "    catheter_props = regionprops(catheter_mask.astype(int))[0]\n",
        "    r_cent, c_cent = catheter_props.centroid\n",
        "\n",
        "    # Calculate third for upper-third region\n",
        "    third = H // 3\n",
        "\n",
        "    fig, ax = plt.subplots()\n",
        "\n",
        "    # Show atrium mask as background with transparency\n",
        "    atrium_mask_rgba = np.zeros((*atrium_mask.shape, 4), dtype=np.float32)\n",
        "    atrium_mask_rgba[atrium_mask > 0, 3] = 0.3  # Set alpha to 0.3 where mask is True\n",
        "    atrium_mask_rgba[atrium_mask > 0, 1] = 1  # Set green channel to 1\n",
        "    ax.imshow(atrium_mask_rgba)\n",
        "\n",
        "    # Show catheter mask on top with transparency\n",
        "    catheter_mask_rgba = np.zeros((*catheter_mask.shape, 4), dtype=np.float32)\n",
        "    catheter_mask_rgba[catheter_mask > 0, 3] = 0.8  # Set alpha to 0.8 where mask is True\n",
        "    catheter_mask_rgba[catheter_mask > 0, 0] = 1  # Set red channel to 1\n",
        "    ax.imshow(catheter_mask_rgba)\n",
        "\n",
        "    # Bounding box (blue)\n",
        "    bbox_patch = Rectangle((minc, minr), width, H, fill=False, linewidth=2, edgecolor='blue')\n",
        "    ax.add_patch(bbox_patch)\n",
        "\n",
        "    # Centroid (yellow)\n",
        "    centroid_patch = Circle((c_cent, r_cent), radius=5, fill=True, color='yellow')\n",
        "    ax.add_patch(centroid_patch)\n",
        "\n",
        "    # Upper-third region (cyan)\n",
        "    upper_third_patch = Rectangle((minc, minr), width, 2 * third, fill=True, alpha=0.2, color='cyan')\n",
        "    ax.add_patch(upper_third_patch)\n",
        "\n",
        "    # Create legend elements\n",
        "    legend_elements = [\n",
        "        Patch(facecolor='blue', edgecolor='blue', label='Atrium bbox'),\n",
        "        Patch(facecolor='red', edgecolor='red', label='Catheter', alpha=0.8),  # Adjust alpha for legend\n",
        "        Patch(facecolor='yellow', edgecolor='yellow', label='Centroid'),\n",
        "        Patch(facecolor='cyan', edgecolor='cyan', label='Upper-third', alpha=0.2),  # Adjust alpha for legend\n",
        "    ]\n",
        "\n",
        "    # Add legend\n",
        "    ax.legend(handles=legend_elements, loc='upper right')\n",
        "\n",
        "    plt.axis(\"off\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# Convert the tensors to NumPy arrays\n",
        "atrium_mask_np = atria_tensor_u2plus[10].cpu().numpy()\n",
        "catheter_mask_np = catheter_tensor_u2plus[10].cpu().numpy()\n",
        "# Call viz_spatial_features\n",
        "viz_spatial_features(atrium_mask_np, catheter_mask_np, predicted_features_u2plus_df.iloc[10])\n",
        "\n",
        "viz_spatial_features(atrium_mask_np, catheter_mask_np, original_features_df.iloc[10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "miS9tcjQLyld"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.patches import Rectangle, Circle, Patch\n",
        "from skimage.measure import regionprops\n",
        "\n",
        "# 1) Modify viz_spatial_features to accept an Axes:\n",
        "def viz_spatial_features(atrium_mask, catheter_mask, features, ax):\n",
        "    # compute bbox & centroid exactly as before…\n",
        "    atrium_props = regionprops(atrium_mask.astype(int))[0]\n",
        "    minr, minc, maxr, maxc = atrium_props.bbox\n",
        "    H = maxr - minr\n",
        "    width = maxc - minc\n",
        "\n",
        "    catheter_props = regionprops(catheter_mask.astype(int))[0]\n",
        "    r_cent, c_cent = catheter_props.centroid\n",
        "    third = H // 3\n",
        "\n",
        "    # draw atrium background (green, α=0.3)\n",
        "    atrium_rgba = np.zeros((*atrium_mask.shape, 4), float)\n",
        "    atrium_rgba[atrium_mask>0,1] = 1\n",
        "    atrium_rgba[atrium_mask>0,3] = 0.3\n",
        "    ax.imshow(atrium_rgba)\n",
        "\n",
        "    # draw catheter (red, α=0.8)\n",
        "    cath_rgba = np.zeros((*catheter_mask.shape,4), float)\n",
        "    cath_rgba[catheter_mask>0,0] = 1\n",
        "    cath_rgba[catheter_mask>0,3] = 0.8\n",
        "    ax.imshow(cath_rgba)\n",
        "\n",
        "    # bbox, centroid, upper‐third\n",
        "    ax.add_patch(Rectangle((minc, minr), width, H,\n",
        "                           fill=False, lw=2, edgecolor='blue'))\n",
        "    ax.add_patch(Circle((c_cent, r_cent), 5, color='yellow'))\n",
        "    ax.add_patch(Rectangle((minc, minr), width, 2*third,\n",
        "                           fill=True, alpha=0.2, color='cyan'))\n",
        "\n",
        "    ax.set_xticks([]); ax.set_yticks([])\n",
        "\n",
        "# 2) Prepare your 9 samples:\n",
        "#    Suppose you have lists: atria = [atrium1, …, atrium9],\n",
        "#                            caths = [cat1, …, cat9],\n",
        "#                            feats = [feat1, …, feat9]\n",
        "#    Replace these with your actual data.\n",
        "atria = atria_tensor_u2plus[:9]\n",
        "caths = catheter_tensor_u2plus[:9]\n",
        "feats = predicted_features_u2plus_df.head(9)  # your real features dicts go here\n",
        "\n",
        "# 3) Create 3×3 grid and plot\n",
        "fig, axes = plt.subplots(3,3, figsize=(9,9))\n",
        "for ax, atr_mask, cath_mask, fdict in zip(axes.flat, atria, caths, feats):\n",
        "    viz_spatial_features(atr_mask.numpy(), cath_mask.numpy(), fdict, ax)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bApumICiK3-k"
      },
      "outputs": [],
      "source": [
        "met_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "akJJumShHyDJ"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# Reverse coding of the 'tip' column\n",
        "met_df['tip'] = met_df['tip'].apply(lambda x: 0 if x == 1 else 1)\n",
        "met_df['tip_lab'] = met_df['tip'].apply(lambda x: 'Malpositioned' if x == 1 else 'Not malpositioned')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KRMTS_6atqz-"
      },
      "outputs": [],
      "source": [
        "met_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zegf0AvNQGHb"
      },
      "outputs": [],
      "source": [
        "id_label_pair = dict(zip(met_df['ap_id'], met_df['tip']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rlCX2b-tQYMg"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3zAloF4AOwLR"
      },
      "outputs": [],
      "source": [
        "all_ids = common_ids + common_ids_test\n",
        "labels = [int(id_label_pair[id]) for id in all_ids]\n",
        "original_features_df['tip'] = labels\n",
        "predicted_features_base_df['tip'] = labels\n",
        "predicted_features_ds_df['tip'] = labels\n",
        "predicted_features_u2plus_df['tip'] = labels\n",
        "predicted_features_u2plus_no_clahe_df['tip'] = labels\n",
        "\n",
        "predicted_features_ds_df['tip_lab'] = predicted_features_ds_df['tip'].apply(lambda x: 'Malpositioned' if x == 1 else 'Not malpositioned')\n",
        "predicted_features_base_df['tip_lab'] = predicted_features_base_df['tip'].apply(lambda x: 'Malpositioned' if x == 1 else 'Not malpositioned')\n",
        "original_features_df['tip_lab'] = original_features_df['tip'].apply(lambda x: 'Malpositioned' if x == 1 else 'Not malpositioned')\n",
        "predicted_features_u2plus_df['tip_lab'] = predicted_features_u2plus_df['tip'].apply(lambda x: 'Malpositioned' if x == 1 else 'Not malpositioned')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1xOjYIkK5Pmv"
      },
      "outputs": [],
      "source": [
        "met_df['tip'].value_counts(normalize=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U7zqwtOnQtsh"
      },
      "outputs": [],
      "source": [
        "plot_catheter_feature_correlation(original_features_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RaiYQFHBwwNu"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Define selected features\n",
        "selected_columns = [\n",
        "    \"loc_norm\", \"frac_atrium_covered\", \"dist_to_atria_top\", \"dist_to_atria_bottom\", \"length\",\n",
        "    \"orientation\", \"eccentricity\", \"curvature\"\n",
        "] + [f\"hu_catheter_{i}\" for i in range(7)]\n",
        "\n",
        "# Filter and drop NA\n",
        "filtered_df = original_features_df[selected_columns + ['tip']].dropna() # Keep 'tip' in the filtering process\n",
        "X = filtered_df[selected_columns]\n",
        "y = filtered_df['tip']  # Target variable is now aligned with X\n",
        "\n",
        "# ... (rest of your code)\n",
        "# Standardize and reduce to 10 PCs in pipeline\n",
        "pipeline = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('pca', PCA(n_components=10)),\n",
        "    ('clf', RandomForestClassifier(random_state=42))\n",
        "])\n",
        "\n",
        "# Perform 5-fold cross-validation\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "scores = cross_val_score(pipeline, X, y, cv=cv, scoring='accuracy')\n",
        "\n",
        "# Display results\n",
        "mean_score = scores.mean()\n",
        "std_score = scores.std()\n",
        "\n",
        "mean_score, std_score\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0puuSrtSxAOF"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import make_scorer, f1_score, roc_auc_score\n",
        "from sklearn.model_selection import cross_validate\n",
        "\n",
        "# Define custom scoring\n",
        "scoring = {\n",
        "    'accuracy': 'accuracy',\n",
        "    'f1': make_scorer(f1_score),\n",
        "    'roc_auc': 'roc_auc'\n",
        "}\n",
        "\n",
        "'tip_lab' in predicted_features_ds_df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "df75gROGhaYT"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "\n",
        "sns.pairplot(predicted_features_ds_df[[\n",
        "       \"loc_norm\", \"iou\", \"frac_upper\", \"dist_to_atria_top\", \"dist_to_atria_bottom\", \"tip_lab\"]], hue='tip_lab')\n",
        "\n",
        "# for the selected columns, remove _ from them in the axis lables\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n-j6u_ulGVBm"
      },
      "outputs": [],
      "source": [
        "sns.pairplot(predicted_features_u2plus_df[[\n",
        "       \"loc_norm\", \"iou\", \"frac_upper\", \"dist_to_atria_top\", \"dist_to_atria_bottom\", \"tip_lab\"]], hue='tip_lab')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M4v-mB6JjzjM"
      },
      "outputs": [],
      "source": [
        "# \"loc_norm\", \"frac_atrium_covered\", \"dist_to_atria_top\", \"dist_to_atria_bottom\"\n",
        "\n",
        "# create a box plot for each of the columns above with respect to the target variable (tip_lab)\n",
        "sns.boxplot(x='tip_lab', y='iou', hue='tip_lab', data=predicted_features_u2plus_df)\n",
        "plt.xlabel('Tip Position', fontsize=12);\n",
        "plt.ylabel('IOU', fontsize=12);\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7X0FiY3Zk8dc"
      },
      "outputs": [],
      "source": [
        "sns.boxplot(x='tip_lab', y='frac_upper', hue='tip_lab', data=predicted_features_u2plus_df)\n",
        "plt.ylabel('Upper third fraction covered', fontsize=12)\n",
        "plt.xlabel('Tip Position', fontsize=12);\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K5VothELlHNT"
      },
      "outputs": [],
      "source": [
        "\n",
        "sns.boxplot(x='tip_lab', y='dist_to_atria_top', hue='tip_lab', data=predicted_features_u2plus_df)\n",
        "plt.ylabel('Distance to top of atrial border', fontsize=12)\n",
        "plt.xlabel('Tip Position', fontsize=12);\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uLQLuvA0lPxa"
      },
      "outputs": [],
      "source": [
        "\n",
        "sns.boxplot(x='tip_lab', y='dist_to_atria_bottom', hue='tip_lab', data=predicted_features_u2plus_df)\n",
        "plt.ylabel('Distance to bottom of atrial border', fontsize=12)\n",
        "plt.xlabel('Tip Position', fontsize=12);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J20OeFaExPUS"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import StratifiedKFold, cross_validate\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics import make_scorer, f1_score, roc_auc_score, matthews_corrcoef, recall_score, precision_score\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def evaluate_classifiers_with_pca(dataframe, target_column='tip', n_components=10):\n",
        "    \"\"\"\n",
        "    Performs PCA and evaluates multiple classifiers using 5-fold cross-validation.\n",
        "\n",
        "    Args:\n",
        "        dataframe (pd.DataFrame): The input feature dataframe (must include `target_column`).\n",
        "        target_column (str): The name of the target column (default is 'tip').\n",
        "        n_components (int): Number of PCA components to retain (default is 10).\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: A summary of mean and std of accuracy, F1 score, and AUC for each model.\n",
        "    \"\"\"\n",
        "    # Define classifiers\n",
        "    classifiers = {\n",
        "        \"Logistic Regression\": LogisticRegression(max_iter=1000, random_state=42),\n",
        "        \"SVM (RBF Kernel)\": SVC(kernel='rbf', probability=True, random_state=42),\n",
        "        \"Random Forest\": RandomForestClassifier(random_state=42)\n",
        "    }\n",
        "\n",
        "    # Scoring metrics\n",
        "    scoring = {\n",
        "        'accuracy': 'accuracy',\n",
        "        'f1': make_scorer(f1_score),\n",
        "        'roc_auc': 'roc_auc',\n",
        "        # 'matthews_corrcoef': make_scorer(matthews_corrcoef),\n",
        "        'recall': make_scorer(recall_score),\n",
        "        'precision': make_scorer(precision_score)\n",
        "    }\n",
        "\n",
        "    # Define selected features\n",
        "    selected_columns = [\n",
        "        \"loc_norm\", \"frac_upper\", \"dist_to_atria_top\", \"dist_to_atria_bottom\", \"iou\"\n",
        "\n",
        "    ]\n",
        "    # + [f\"hu_catheter_{i}\" for i in range(7)\n",
        "\n",
        "\n",
        "    # Drop missing values and align X/y\n",
        "    filtered_df = dataframe[selected_columns + [target_column]].dropna()\n",
        "    X = filtered_df[selected_columns]\n",
        "    y = filtered_df[target_column]\n",
        "\n",
        "    # 5-fold stratified CV\n",
        "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "    # Evaluate each classifier\n",
        "    results = {}\n",
        "    for name, clf in classifiers.items():\n",
        "        pipeline = Pipeline([\n",
        "            ('scaler', StandardScaler()),\n",
        "            # ('pca', PCA(n_components=n_components)),\n",
        "            ('classifier', clf)\n",
        "        ])\n",
        "        scores = cross_validate(pipeline, X, y, cv=cv, scoring=scoring)\n",
        "        results[name] = {\n",
        "            \"mean_accuracy\": scores['test_accuracy'].mean(),\n",
        "            \"std_accuracy\": scores['test_accuracy'].std(),\n",
        "            \"mean_f1\": scores['test_f1'].mean(),\n",
        "            \"std_f1\": scores['test_f1'].std(),\n",
        "            \"mean_auc\": scores['test_roc_auc'].mean(),\n",
        "            \"std_auc\": scores['test_roc_auc'].std(),\n",
        "            \"mean_recall\": scores['test_recall'].mean(),\n",
        "            \"std_recall\": scores['test_recall'].std(),\n",
        "            \"mean_precision\": scores['test_precision'].mean(),\n",
        "            \"std_precision\": scores['test_precision'].std()\n",
        "        }\n",
        "\n",
        "\n",
        "    return pd.DataFrame(results).T\n",
        "predicted_mask_metrics_ds = evaluate_classifiers_with_pca(predicted_features_ds_df)\n",
        "predicted_mask_metrics_base = evaluate_classifiers_with_pca(predicted_features_base_df)\n",
        "predicted_mask_metrics_u2plus = evaluate_classifiers_with_pca(predicted_features_u2plus_df)\n",
        "\n",
        "original_mask_metrics = evaluate_classifiers_with_pca(original_features_df)\n",
        "predicted_mask_metrics_u2plus_no_clahe = evaluate_classifiers_with_pca(predicted_features_u2plus_no_clahe_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t28urXahxixE"
      },
      "outputs": [],
      "source": [
        "predicted_mask_metrics_ds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cWt6XV2Jxup_"
      },
      "outputs": [],
      "source": [
        "predicted_mask_metrics_base"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sBwAPy_lIPpz"
      },
      "outputs": [],
      "source": [
        "predicted_mask_metrics_u2plus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zunLTWCLxram"
      },
      "outputs": [],
      "source": [
        "original_mask_metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cSMlxvOYG7Dq"
      },
      "outputs": [],
      "source": [
        "predicted_mask_metrics_u2plus_no_clahe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "53cOi5UR0qKa"
      },
      "outputs": [],
      "source": [
        "original_features_df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_sncA95kzLtS"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV, StratifiedKFold\n",
        "from scipy.stats import loguniform\n",
        "import numpy as np\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "def nested_cv_classifiers(dataframe, target_column='tip', n_components=10):\n",
        "    \"\"\"\n",
        "    Performs nested cross-validation with random search hyperparameter tuning.\n",
        "\n",
        "    Args:\n",
        "        dataframe (pd.DataFrame): Input feature dataframe\n",
        "        target_column (str): Name of target column\n",
        "        n_components (int): PCA components (currently unused)\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: Performance metrics with standard deviations\n",
        "        dict: Best hyperparameters for each model\n",
        "    \"\"\"\n",
        "    # Define classifiers with hyperparameter grids\n",
        "    classifiers = {\n",
        "        \"Logistic Regression\": {\n",
        "            \"estimator\": LogisticRegression(max_iter=1000, random_state=42),\n",
        "            \"params\": {\n",
        "                'classifier__C': loguniform(1e-4, 100),\n",
        "                'classifier__penalty': ['l1', 'l2'],\n",
        "                'classifier__solver': ['saga']\n",
        "            }\n",
        "        },\n",
        "        \"SVM (RBF Kernel)\": {\n",
        "            \"estimator\": SVC(probability=True, random_state=42),\n",
        "            \"params\": {\n",
        "                'classifier__C': loguniform(1e-4, 100),\n",
        "                'classifier__gamma': loguniform(1e-4, 100),\n",
        "                'classifier__kernel': ['rbf']\n",
        "            }\n",
        "        },\n",
        "        \"Random Forest\": {\n",
        "            \"estimator\": RandomForestClassifier(random_state=42),\n",
        "            \"params\": {\n",
        "                'classifier__n_estimators': [50, 100, 200, 400],\n",
        "                'classifier__max_depth': [None, 10, 20, 30, 50],\n",
        "                'classifier__min_samples_split': [2, 5, 10],\n",
        "                'classifier__min_samples_leaf': [1, 2, 4],\n",
        "                'classifier__max_features': ['sqrt', 'log2']\n",
        "            }\n",
        "        },\n",
        "        'XGBoost': {\n",
        "            \"estimator\": XGBClassifier(random_state=42),\n",
        "            \"params\": {\n",
        "                'classifier__n_estimators': [50, 100, 200, 400],\n",
        "                'classifier__max_depth': [3, 5, 7, 10],\n",
        "                'classifier__learning_rate': [0.01, 0.1, 0.2, 0.3],\n",
        "                'classifier__subsample': [0.8, 0.9, 1.0],\n",
        "                'classifier__colsample_bytree': [0.8, 0.9, 1.0],\n",
        "                'classifier__gamma': [0, 0.1, 0.2, 0.3, 0.4]\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "\n",
        "    # Define metrics\n",
        "    scoring = {\n",
        "        'accuracy': 'accuracy',\n",
        "        'f1': make_scorer(f1_score),\n",
        "        'roc_auc': 'roc_auc',\n",
        "        'recall': make_scorer(recall_score),\n",
        "        'precision': make_scorer(precision_score)\n",
        "\n",
        "        # 'matthews_corrcoef': make_scorer(matthews_corrcoef)\n",
        "    }\n",
        "\n",
        "    # Feature selection\n",
        "    selected_columns = [\n",
        "        \"frac_upper\", \"loc_norm\",\n",
        "        \"dist_to_atria_top\", \"dist_to_atria_bottom\", \"iou\"\n",
        "    ]\n",
        "\n",
        "    # Prepare data\n",
        "    filtered_df = dataframe[selected_columns + [target_column]].dropna()\n",
        "    X = filtered_df[selected_columns]\n",
        "    y = filtered_df[target_column]\n",
        "\n",
        "    # Cross-validation setup\n",
        "    inner_cv = StratifiedKFold(n_splits=2, shuffle=True, random_state=42)\n",
        "    outer_cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "    # Results storage\n",
        "    results = {}\n",
        "    best_params = {}\n",
        "\n",
        "    for name, config in classifiers.items():\n",
        "        # Create pipeline\n",
        "        pipeline = Pipeline([\n",
        "            ('scaler', StandardScaler()),\n",
        "            ('classifier', config[\"estimator\"])\n",
        "        ])\n",
        "\n",
        "        # Randomized search setup\n",
        "        search = RandomizedSearchCV(\n",
        "            estimator=pipeline,\n",
        "            param_distributions=config[\"params\"],\n",
        "            n_iter=20,\n",
        "            scoring='f1',\n",
        "            cv=inner_cv,\n",
        "            refit=True,\n",
        "            random_state=42,\n",
        "            n_jobs=-1\n",
        "        )\n",
        "\n",
        "        # Nested CV with multiple metrics\n",
        "        cv_results = cross_validate(\n",
        "            search,\n",
        "            X, y,\n",
        "            cv=outer_cv,\n",
        "            scoring=scoring,\n",
        "            return_estimator=True\n",
        "        )\n",
        "\n",
        "        # Store best parameters\n",
        "        best_params[name] = [est.best_params_ for est in cv_results['estimator']]\n",
        "\n",
        "        # Aggregate results\n",
        "        results[name] = {\n",
        "            'mean_accuracy': np.mean(cv_results['test_accuracy']),\n",
        "            'std_accuracy': np.std(cv_results['test_accuracy']),\n",
        "            'mean_f1': np.mean(cv_results['test_f1']),\n",
        "            'std_f1': np.std(cv_results['test_f1']),\n",
        "            'mean_auc': np.mean(cv_results['test_roc_auc']),\n",
        "            'std_auc': np.std(cv_results['test_roc_auc']),\n",
        "            'mean_recall': np.mean(cv_results['test_recall']),\n",
        "            'std_recall': np.std(cv_results['test_recall']),\n",
        "            'mean_precision': np.mean(cv_results['test_precision']),\n",
        "            'std_precision': np.std(cv_results['test_precision'])\n",
        "        }\n",
        "\n",
        "    return pd.DataFrame(results).T, best_params\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4B62KaWHsVdR"
      },
      "outputs": [],
      "source": [
        "original_features_df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rl64ogO021WZ"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV, StratifiedKFold, cross_validate\n",
        "from sklearn.linear_model import LogisticRegression # Added missing import\n",
        "from sklearn.svm import SVC                       # Added missing import\n",
        "from sklearn.ensemble import RandomForestClassifier # Added missing import\n",
        "from sklearn.preprocessing import StandardScaler   # Added missing import\n",
        "from sklearn.pipeline import Pipeline             # Added missing import\n",
        "from sklearn.metrics import make_scorer, f1_score, recall_score, precision_score # Added missing imports\n",
        "from scipy.stats import loguniform\n",
        "import numpy as np\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "def nested_cv_classifiers(dataframe, target_column='tip', n_components=10):\n",
        "    \"\"\"\n",
        "    Performs nested cross-validation with random search hyperparameter tuning.\n",
        "\n",
        "    Args:\n",
        "        dataframe (pd.DataFrame): Input feature dataframe\n",
        "        target_column (str): Name of target column\n",
        "        n_components (int): PCA components (currently unused)\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: Performance metrics with standard deviations\n",
        "        dict: Best hyperparameters for each model\n",
        "    \"\"\"\n",
        "    # Define classifiers with hyperparameter grids\n",
        "    classifiers = {\n",
        "        \"Logistic Regression\": {\n",
        "            \"estimator\": LogisticRegression(max_iter=1000, random_state=42),\n",
        "            \"params\": {\n",
        "                'classifier__C': loguniform(1e-4, 100),\n",
        "                'classifier__penalty': ['l1', 'l2'],\n",
        "                'classifier__solver': ['saga']\n",
        "            }\n",
        "        },\n",
        "        \"SVM (RBF Kernel)\": {\n",
        "            \"estimator\": SVC(probability=True, random_state=42),\n",
        "            \"params\": {\n",
        "                'classifier__C': loguniform(1e-4, 100),\n",
        "                'classifier__gamma': loguniform(1e-4, 100),\n",
        "                'classifier__kernel': ['rbf']\n",
        "            }\n",
        "        },\n",
        "        \"Random Forest\": {\n",
        "            \"estimator\": RandomForestClassifier(random_state=42),\n",
        "            \"params\": {\n",
        "                'classifier__n_estimators': [50, 100, 200, 400],\n",
        "                'classifier__max_depth': [None, 10, 20, 30, 50],\n",
        "                'classifier__min_samples_split': [2, 5, 10],\n",
        "                'classifier__min_samples_leaf': [1, 2, 4],\n",
        "                'classifier__max_features': ['sqrt', 'log2']\n",
        "            }\n",
        "        },\n",
        "        'XGBoost': {\n",
        "            \"estimator\": XGBClassifier(random_state=42),\n",
        "            \"params\": {\n",
        "                'classifier__n_estimators': [50, 100, 200, 400],\n",
        "                'classifier__max_depth': [3, 5, 7, 10],\n",
        "                'classifier__learning_rate': [0.01, 0.1, 0.2, 0.3],\n",
        "                'classifier__subsample': [0.8, 0.9, 1.0],\n",
        "                'classifier__colsample_bytree': [0.8, 0.9, 1.0],\n",
        "                'classifier__gamma': [0, 0.1, 0.2, 0.3, 0.4]\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "\n",
        "    # Define metrics\n",
        "    scoring = {\n",
        "        'accuracy': 'accuracy',\n",
        "        'f1': make_scorer(f1_score),\n",
        "        'roc_auc': 'roc_auc',\n",
        "        'recall': make_scorer(recall_score),\n",
        "        'precision': make_scorer(precision_score)\n",
        "\n",
        "        # 'matthews_corrcoef': make_scorer(matthews_corrcoef)\n",
        "    }\n",
        "\n",
        "    # Feature selection\n",
        "    selected_columns = [\n",
        "        \"frac_upper\", \"loc_norm\",\n",
        "        \"dist_to_atria_top\", \"dist_to_atria_bottom\", \"iou\"\n",
        "    ]\n",
        "\n",
        "    # Prepare data\n",
        "    filtered_df = dataframe[selected_columns + [target_column]].dropna()\n",
        "    X = filtered_df[selected_columns]\n",
        "    y = filtered_df[target_column]\n",
        "\n",
        "    # Cross-validation setup\n",
        "    inner_cv = StratifiedKFold(n_splits=2, shuffle=True, random_state=42)\n",
        "    outer_cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "    # Results storage\n",
        "    results = {}\n",
        "    best_params = {}\n",
        "\n",
        "    for name, config in classifiers.items():\n",
        "        # Create pipeline\n",
        "        pipeline = Pipeline([\n",
        "            ('scaler', StandardScaler()),\n",
        "            ('classifier', config[\"estimator\"])\n",
        "        ])\n",
        "\n",
        "        # Randomized search setup\n",
        "        # Set n_jobs=1 to avoid multiprocessing issues\n",
        "        search = RandomizedSearchCV(\n",
        "            estimator=pipeline,\n",
        "            param_distributions=config[\"params\"],\n",
        "            n_iter=20,\n",
        "            scoring='f1',\n",
        "            cv=inner_cv,\n",
        "            refit=True,\n",
        "            random_state=42,\n",
        "            n_jobs=1  # Changed from -1 to 1\n",
        "        )\n",
        "\n",
        "        # Nested CV with multiple metrics\n",
        "        # Set n_jobs=1 to avoid multiprocessing issues\n",
        "        cv_results = cross_validate(\n",
        "            search,\n",
        "            X, y,\n",
        "            cv=outer_cv,\n",
        "            scoring=scoring,\n",
        "            return_estimator=True,\n",
        "            n_jobs=1 # Changed from -1 to 1\n",
        "        )\n",
        "\n",
        "        # Store best parameters\n",
        "        # The estimator returned by cross_validate when n_jobs=1 is the fitted search object\n",
        "        best_params[name] = [est.best_params_ for est in cv_results['estimator']]\n",
        "\n",
        "        # Aggregate results\n",
        "        results[name] = {\n",
        "            'mean_accuracy': np.mean(cv_results['test_accuracy']),\n",
        "            'std_accuracy': np.std(cv_results['test_accuracy']),\n",
        "            'mean_f1': np.mean(cv_results['test_f1']),\n",
        "            'std_f1': np.std(cv_results['test_f1']),\n",
        "            'mean_auc': np.mean(cv_results['test_roc_auc']),\n",
        "            'std_auc': np.std(cv_results['test_roc_auc']),\n",
        "            'mean_recall': np.mean(cv_results['test_recall']),\n",
        "            'std_recall': np.std(cv_results['test_recall']),\n",
        "            'mean_precision': np.mean(cv_results['test_precision']),\n",
        "            'std_precision': np.std(cv_results['test_precision'])\n",
        "        }\n",
        "\n",
        "    return pd.DataFrame(results).T, best_params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zLU4bc9Wz0gX"
      },
      "outputs": [],
      "source": [
        "results_original, _ = nested_cv_classifiers(original_features_df)\n",
        "results_predicted_ds, best_parms = nested_cv_classifiers(predicted_features_ds_df)\n",
        "results_predicted_base, _ = nested_cv_classifiers(predicted_features_base_df)\n",
        "results_predicted_u2plus, _ = nested_cv_classifiers(predicted_features_u2plus_df)\n",
        "results_predicted_u2plus_no_clahe, _ = nested_cv_classifiers(predicted_features_u2plus_no_clahe_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V3nJZ-cK0F7O"
      },
      "outputs": [],
      "source": [
        "results_original"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sFy1cLEf3tzK"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0AaxELaU0JKq"
      },
      "outputs": [],
      "source": [
        "results_predicted_ds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bjz1fPjU0Mv3"
      },
      "outputs": [],
      "source": [
        "results_predicted_base"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZtGH-myBJDtd"
      },
      "outputs": [],
      "source": [
        "results_predicted_u2plus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y2k1s7p-HOQk"
      },
      "outputs": [],
      "source": [
        "results_predicted_u2plus_no_clahe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "blvZzzdk1nE3"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "cleaned_params = {\n",
        "    key.replace('classifier__', ''): value\n",
        "    for key, value in best_parms['Random Forest'][0].items()\n",
        "}\n",
        "#\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tyozvVCipBqc"
      },
      "outputs": [],
      "source": [
        "selected_columns = [\n",
        "        \"frac_upper\", \"loc_norm\",\n",
        "        \"dist_to_atria_top\", \"dist_to_atria_bottom\", \"iou\"\n",
        "    ]\n",
        "\n",
        "X = original_features_df[selected_columns]\n",
        "y = original_features_df['tip']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P01uHRQRre-E"
      },
      "outputs": [],
      "source": [
        "# Do a correlation heat map for selected columns\n",
        "import seaborn as sns\n",
        "\n",
        "corr_matrix = original_features_df[selected_columns].corr()\n",
        "sns.heatmap(corr_matrix, annot=True)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mymq2-vqolRe"
      },
      "outputs": [],
      "source": [
        "pipeline = Pipeline([\n",
        "            ('scaler', StandardScaler()),\n",
        "            ('classifier', RandomForestClassifier(random_state=42, **cleaned_params))\n",
        "        ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9nU6CnvbpGsh"
      },
      "outputs": [],
      "source": [
        "model_rf = pipeline.fit(X_train, y_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PudGp03FpUkR"
      },
      "outputs": [],
      "source": [
        "model_rf.score(X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ylwz-6SbpuXE"
      },
      "outputs": [],
      "source": [
        "# Get shapley values for RF\n",
        "import shap\n",
        "\n",
        "rf_model = model_rf.named_steps['classifier']\n",
        "\n",
        "\n",
        "explainer = shap.TreeExplainer(rf_model, data=X_train)\n",
        "\n",
        "\n",
        "shap_values = explainer.shap_values(X_test)\n",
        "\n",
        "\n",
        "shap.summary_plot(shap_values[:,:, 1], X_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fLucYXsLO-2e"
      },
      "outputs": [],
      "source": [
        "# plot feature importance from the random forest model\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "feature_importances = model_rf.named_steps['classifier'].feature_importances_\n",
        "sorted_idx = np.argsort(feature_importances)[::-1]\n",
        "\n",
        "# Get the sorted feature names\n",
        "sorted_feature_names = np.array(selected_columns)[sorted_idx]\n",
        "\n",
        "# Process the feature names: replace _ with space and capitalize the first word\n",
        "processed_feature_names = [\n",
        "    name.replace('_', ' ').capitalize() for name in sorted_feature_names\n",
        "]\n",
        "\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "# Use barh for horizontal bars\n",
        "ax.barh(range(feature_importances.shape[0]), feature_importances[sorted_idx],\n",
        "        color='dodgerblue')\n",
        "\n",
        "# Set y-axis ticks and labels (since bars are horizontal) using processed names\n",
        "ax.set_yticks(range(feature_importances.shape[0]))\n",
        "ax.set_yticklabels(processed_feature_names) # Use the processed names here\n",
        "\n",
        "# Set axis labels and title (swapped for horizontal bars)\n",
        "ax.set_xlabel('Feature Importance')\n",
        "ax.set_ylabel('') # Y-axis now represents the features\n",
        "ax.set_title('Random Forest Feature Importance')\n",
        "\n",
        "# Invert the y-axis so the most important feature is at the top\n",
        "ax.invert_yaxis()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OEkJSFQ8nuWi"
      },
      "source": [
        "### Deep Learning approach\n",
        "\n",
        "* This section builds models based on the predicted masks obtained from the segmentation models, with use of transfer learning.\n",
        "* The key Idea here is to make use of well informed data transformation to ensure there is less overfitting.\n",
        "Some transformations to consider inscludes:\n",
        "  - Mild Grid and Elastic distortion\n",
        "  - Horizontal flip (THe prediction should be robust to this)\n",
        "  - Mild Rotations\n",
        "\n",
        "`Albumentation` is a great packge for such transformtions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HBt3oQoU0L3R"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WYuow2_Wo1Eq"
      },
      "outputs": [],
      "source": [
        "!pip install -U albumentations --quiet\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "from model_setup import train_step, test_step, call_model, train_kfold_model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V49S4_ZRuBqe"
      },
      "outputs": [],
      "source": [
        "import albumentations as A\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
        "from torch.optim import AdamW\n",
        "from torch.optim.lr_scheduler import LinearLR, CosineAnnealingLR, SequentialLR\n",
        "from sklearn.model_selection import KFold\n",
        "import numpy as np\n",
        "from tqdm.auto import tqdm\n",
        "from torchmetrics import F1Score\n",
        "import gc\n",
        "\n",
        "def free_gpu_memory():\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ou1fcpng0W3g"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "import albumentations as A\n",
        "import cv2\n",
        "\n",
        "class ClassificationDataset(Dataset):\n",
        "    def __init__(self, catheter_predictions, atria_predictions,\n",
        "                 labels, ids=None, original_images=None,\n",
        "                 transform=None, normalize=False):\n",
        "        \"\"\"\n",
        "        Modified dataset class with Albumentations support and proper normalization\n",
        "\n",
        "        Args:\n",
        "            catheter_predictions: Tensor/Numpy array of shape (N, H, W)\n",
        "            atria_predictions: Tensor/Numpy array of shape (N, H, W)\n",
        "            labels: List/Tensor of labels\n",
        "            original_images: Optional original images (N, H, W) or (N, 3, H, W)\n",
        "            transform: Albumentations transform pipeline\n",
        "            normalize: Whether to normalize masks from 0-255 to 0-1\n",
        "        \"\"\"\n",
        "        self.predictions = catheter_predictions\n",
        "        self.labels = torch.tensor(labels, dtype=torch.float32)\n",
        "        self.transform = transform\n",
        "        self.atrial_mask = atria_predictions\n",
        "        self.original_images = original_images\n",
        "        self.ids = ids\n",
        "        self.normalize = normalize\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Get raw data elements\n",
        "        mask = self.predictions[idx]  # Shape (H, W)\n",
        "        label = self.labels[idx]\n",
        "        atria = self.atrial_mask[idx]\n",
        "\n",
        "        # Convert to tensors if needed\n",
        "        if isinstance(mask, np.ndarray):\n",
        "            mask = torch.from_numpy(mask)\n",
        "        if isinstance(atria, np.ndarray):\n",
        "            atria = torch.from_numpy(atria)\n",
        "\n",
        "        # Normalization for binary masks\n",
        "        if self.normalize:\n",
        "            mask = mask.float().div(255)\n",
        "            atria = atria.float().div(255)\n",
        "        else:\n",
        "            mask = mask.float()\n",
        "            atria = atria.float()\n",
        "\n",
        "        # Handle third channel\n",
        "        if self.original_images is not None:\n",
        "            third_channel = self.original_images[idx]\n",
        "            if isinstance(third_channel, np.ndarray):\n",
        "                third_channel = torch.from_numpy(third_channel)\n",
        "            third_channel = third_channel.float().div(255)\n",
        "        else:\n",
        "            third_channel = torch.zeros_like(mask)\n",
        "\n",
        "        # Create 3-channel input (C, H, W)\n",
        "        feature = torch.stack([mask, atria, third_channel], dim=0)\n",
        "\n",
        "        # Convert to numpy array for Albumentations (H, W, C)\n",
        "        feature_np = feature.permute(1, 2, 0).numpy()\n",
        "\n",
        "        # Apply transformations\n",
        "        if self.transform:\n",
        "            transformed = self.transform(image=feature_np)\n",
        "            feature = transformed['image']  # Albumentations handles HWC -> CHW\n",
        "\n",
        "        if self.ids is not None:\n",
        "            return feature, label, self.ids[idx]\n",
        "        return feature, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PbCZd519zPlk"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "from torchmetrics import Accuracy, Precision, Recall, AUROC, F1Score\n",
        "from tqdm.auto import tqdm\n",
        "from typing import Dict, List, Tuple"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JbbBTZNj7uHD"
      },
      "outputs": [],
      "source": [
        "def test_step(model: nn.Module,\n",
        "              dataloader: torch.utils.data.DataLoader,\n",
        "              loss_fn: nn.Module,\n",
        "              device: torch.device,\n",
        "              return_predictions: float = False) -> Tuple[float, float, float, float, float, float]:\n",
        "    \"\"\"Test step with proper type handling and metric reset\"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    # Initialize metrics\n",
        "    metrics = {\n",
        "        'acc': Accuracy(task='binary').to(device),\n",
        "        'precision': Precision(task='binary').to(device),\n",
        "        'recall': Recall(task='binary').to(device),\n",
        "        'auc': AUROC(task='binary').to(device),\n",
        "        'f1': F1Score(task='binary').to(device)\n",
        "    }\n",
        "\n",
        "    test_loss = 0.0\n",
        "    all_probs = []\n",
        "    all_labels = []\n",
        "\n",
        "    try:\n",
        "        with torch.no_grad():\n",
        "            for images, labels, _ in dataloader:\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "                # Forward pass\n",
        "                outputs = model(images)\n",
        "                if isinstance(outputs, tuple):\n",
        "                    outputs = outputs[0]\n",
        "\n",
        "                # Calculate loss (ensure proper types)\n",
        "                loss = loss_fn(outputs, labels.float().unsqueeze(1))\n",
        "                test_loss += loss.item() * images.size(0)\n",
        "\n",
        "                # Get probabilities and ensure proper shapes\n",
        "                probs = torch.sigmoid(outputs)\n",
        "                preds = (probs > 0.5).float()\n",
        "                all_probs.append(probs.cpu())\n",
        "                all_labels.append(labels.cpu())\n",
        "\n",
        "                # Reshape if needed\n",
        "                if len(labels.shape) == 1:\n",
        "                    labels = labels.unsqueeze(1)\n",
        "                if len(preds.shape) == 1:\n",
        "                    preds = preds.unsqueeze(1)\n",
        "\n",
        "                # Update metrics\n",
        "                for metric in metrics.values():\n",
        "                    metric.update(preds, labels)\n",
        "\n",
        "        # Compute final metrics (ensure float conversion)\n",
        "        avg_loss = float(test_loss / len(dataloader.dataset))\n",
        "        results = {\n",
        "            'loss': avg_loss,\n",
        "            'acc': float(metrics['acc'].compute().item()) ,\n",
        "            'precision': float(metrics['precision'].compute().item()),\n",
        "            'recall': float(metrics['recall'].compute().item()),\n",
        "            'auc': float(metrics['auc'].compute().item()),\n",
        "            'f1': float(metrics['f1'].compute().item())\n",
        "        }\n",
        "\n",
        "        # Concatenate all predictions\n",
        "        preds_retrun = torch.cat(all_probs).numpy(), torch.cat(all_labels).numpy()\n",
        "\n",
        "\n",
        "        return (\n",
        "            results['loss'],\n",
        "            results['acc'],\n",
        "            results['precision'],\n",
        "            results['recall'],\n",
        "            results['auc'],\n",
        "            results['f1'],\n",
        "            preds_retrun\n",
        "        )\n",
        "\n",
        "    finally:\n",
        "        # Reset metrics\n",
        "        for metric in metrics.values():\n",
        "            metric.reset()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TLIpJHvi3rh-"
      },
      "outputs": [],
      "source": [
        "def train_kfold_model(catheter_predictions,\n",
        "                     atria_predictions,\n",
        "                     labels,\n",
        "                     ids=None,\n",
        "                     original_images=None,\n",
        "                     size=600,\n",
        "                     model_name='efficientnet_b7',\n",
        "                     num_epochs=60,\n",
        "                     batch_size=8,\n",
        "                     k=5,\n",
        "                     fine_tune='last_two',\n",
        "                      data_aug=True):\n",
        "    \"\"\"Stratified K-fold training with tqdm progress bars\"\"\"\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    num_gpus = torch.cuda.device_count()\n",
        "    IMG_SIZE = size\n",
        "\n",
        "\n",
        "\n",
        "    if data_aug:\n",
        "\n",
        "      train_transform = A.Compose([\n",
        "          A.Resize(IMG_SIZE, IMG_SIZE, interpolation=cv2.INTER_NEAREST),\n",
        "          A.HorizontalFlip(p=0.3),\n",
        "          A.Rotate(limit=15, p=0.2, border_mode=cv2.BORDER_CONSTANT),\n",
        "          A.GridElasticDeform(\n",
        "        num_grid_xy=(5, 5),\n",
        "            magnitude=3,\n",
        "          interpolation=cv2.INTER_NEAREST,\n",
        "                  mask_interpolation=cv2.INTER_NEAREST,\n",
        "            p=0.2\n",
        "        )  ,\n",
        "          A.ToTensorV2()\n",
        "      ])\n",
        "    else:\n",
        "      train_transform = A.Compose([\n",
        "          A.Resize(IMG_SIZE, IMG_SIZE, interpolation=cv2.INTER_NEAREST),\n",
        "          A.ToTensorV2()\n",
        "      ])\n",
        "\n",
        "\n",
        "    val_transform = A.Compose([\n",
        "        A.Resize(IMG_SIZE, IMG_SIZE, interpolation=cv2.INTER_NEAREST),\n",
        "        A.ToTensorV2()\n",
        "    ])\n",
        "\n",
        "    # Use StratifiedKFold instead of KFold\n",
        "    splits = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)\n",
        "    foldperf = {}\n",
        "    fold_predictions = {}  # Store predictions for each fold\n",
        "    # labels_int = [int(label) for label in labels]\n",
        "\n",
        "    # Convert labels to numpy array for stratified splitting\n",
        "    labels_np = np.array(labels)\n",
        "\n",
        "    # StratifiedKFold.split needs both features (X) and labels (y)\n",
        "    # We'll use indices as dummy features since we have separate components\n",
        "    dummy_X = np.arange(len(labels_np))\n",
        "\n",
        "    for fold, (train_idx, val_idx) in enumerate(splits.split(dummy_X, labels_np)):\n",
        "        print(f'\\n=== Fold {fold + 1}/{k} ===')\n",
        "        print(f\"Train class distribution: {np.bincount(labels_np[train_idx])}\")\n",
        "        print(f\"Val class distribution: {np.bincount(labels_np[val_idx])}\")\n",
        "\n",
        "        # Split raw data components using stratified fold indices\n",
        "        train_catheter = catheter_predictions[train_idx]\n",
        "        train_atria = atria_predictions[train_idx]\n",
        "        train_labels = [labels[i] for i in train_idx]\n",
        "        train_ids = [ids[i] for i in train_idx] if ids else None\n",
        "        train_originals = original_images[train_idx] if original_images is not None else None\n",
        "\n",
        "        val_catheter = catheter_predictions[val_idx]\n",
        "        val_atria = atria_predictions[val_idx]\n",
        "        val_labels = [labels[i] for i in val_idx]\n",
        "        val_ids = [ids[i] for i in val_idx] if ids else None\n",
        "        val_originals = original_images[val_idx] if original_images is not None else None\n",
        "\n",
        "\n",
        "        # Create datasets with appropriate transforms\n",
        "        train_dataset = ClassificationDataset(\n",
        "            catheter_predictions=train_catheter,\n",
        "            atria_predictions=train_atria,\n",
        "            labels=train_labels,\n",
        "            ids=train_ids,\n",
        "            original_images=train_originals,\n",
        "            transform=train_transform\n",
        "        )\n",
        "\n",
        "        val_dataset = ClassificationDataset(\n",
        "            catheter_predictions=val_catheter,\n",
        "            atria_predictions=val_atria,\n",
        "            labels=val_labels,\n",
        "            ids=val_ids,\n",
        "            original_images=val_originals,\n",
        "            transform=val_transform\n",
        "        )\n",
        "\n",
        "        # Create dataloaders with stratified batches\n",
        "        effective_batch = batch_size * max(1, num_gpus)\n",
        "\n",
        "        # For training, we can use StratifiedSampler if needed (optional)\n",
        "        train_loader = DataLoader(train_dataset, batch_size=effective_batch,\n",
        "                                shuffle=True, pin_memory=True, num_workers=2)\n",
        "        test_loader = DataLoader(val_dataset, batch_size=effective_batch,\n",
        "                               shuffle=False, pin_memory=True, num_workers=2)\n",
        "\n",
        "        # Rest of your training code remains the same...\n",
        "        model = call_model(model_name=model_name, device='cpu', fine_tune=fine_tune)\n",
        "        if num_gpus > 1:\n",
        "            model = nn.DataParallel(model)\n",
        "        model = model.to(device)\n",
        "\n",
        "        criterion = nn.BCEWithLogitsLoss()\n",
        "        optimizer = AdamW(filter(lambda p: p.requires_grad, model.parameters()),\n",
        "                        lr=0.0001, weight_decay=0.001)\n",
        "\n",
        "        # LR scheduling\n",
        "        warmup_scheduler = LinearLR(optimizer, start_factor=0.01,\n",
        "                                  end_factor=1.0, total_iters=5)\n",
        "        cosine_scheduler = CosineAnnealingLR(optimizer,\n",
        "                                           T_max=num_epochs-5, eta_min=1e-6)\n",
        "        scheduler = SequentialLR(optimizer,\n",
        "                               schedulers=[warmup_scheduler, cosine_scheduler],\n",
        "                               milestones=[5])\n",
        "\n",
        "        history = {\n",
        "            'train_loss': [], 'test_loss': [],\n",
        "            'train_acc': [], 'test_acc': [],\n",
        "            'test_precision': [], 'test_recall': [],\n",
        "            'test_auc': [], 'test_f1': []\n",
        "        }\n",
        "        # For storing final fold predictions\n",
        "        fold_probs = None\n",
        "        fold_labels = None\n",
        "\n",
        "        for epoch in tqdm(range(num_epochs), desc=f'Epochs'):\n",
        "            free_gpu_memory()\n",
        "\n",
        "            # Training\n",
        "            train_loss, train_acc = train_step(\n",
        "                model, train_loader, criterion, optimizer, scheduler, device)\n",
        "\n",
        "            # Validation - get predictions only on last epoch\n",
        "            return_preds = (epoch == num_epochs - 1)\n",
        "            test_metrics = test_step(\n",
        "                model, test_loader, criterion, device, return_predictions=return_preds)\n",
        "\n",
        "            (test_loss, test_acc, test_precision,\n",
        "             test_recall, test_auc, test_f1, preds) = test_metrics\n",
        "\n",
        "            # Store predictions if available\n",
        "            if return_preds and preds is not None:\n",
        "                fold_probs, fold_labels = preds\n",
        "\n",
        "            # # Training\n",
        "            # train_loss, train_acc = train_step(\n",
        "            #     model, train_loader, criterion, optimizer, scheduler, device)\n",
        "\n",
        "            # # Validation with all metrics\n",
        "            # (test_loss, test_acc, test_precision,\n",
        "            #  test_recall, test_auc, test_f1) = test_step(\n",
        "            #     model, test_loader, criterion, device)\n",
        "\n",
        "            # Store results\n",
        "            history['train_loss'].append(train_loss)\n",
        "            history['train_acc'].append(train_acc)\n",
        "            history['test_loss'].append(test_loss)\n",
        "            history['test_acc'].append(test_acc)\n",
        "            history['test_precision'].append(test_precision)\n",
        "            history['test_recall'].append(test_recall)\n",
        "            history['test_auc'].append(test_auc)\n",
        "            history['test_f1'].append(test_f1)\n",
        "\n",
        "            # Enhanced progress reporting\n",
        "            if (epoch + 1) % 10 == 0 or epoch == 0 or (epoch + 1) == num_epochs:\n",
        "                print(f\"Epoch {epoch+1:03d} | \"\n",
        "                      f\"Train Loss: {train_loss:.4f} | \"\n",
        "                      f\"Train Acc: {train_acc:.2f}% | \"\n",
        "                      f\"Test Loss: {test_loss:.4f}\\n\"\n",
        "                      f\"Test Metrics: \"\n",
        "                      f\"Acc: {test_acc*100:.2f}% | \"\n",
        "                      f\"Precision: {test_precision:.4f} | \"\n",
        "                      f\"Recall: {test_recall:.4f} | \"\n",
        "                      f\"AUC: {test_auc:.4f} | \"\n",
        "                      f\"F1: {test_f1:.4f}\")\n",
        "\n",
        "        foldperf[f'fold{fold+1}'] = history\n",
        "        fold_predictions[f'fold{fold+1}'] = (fold_probs, fold_labels)\n",
        "\n",
        "    return foldperf, fold_predictions\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D7qfb6rWoxnk"
      },
      "outputs": [],
      "source": [
        "def summarize_kfold_metrics(foldperf):\n",
        "    \"\"\"Comprehensive metric summary\"\"\"\n",
        "    metrics = {\n",
        "        'acc': [], 'precision': [], 'recall': [],\n",
        "        'auc': [], 'f1': []\n",
        "    }\n",
        "\n",
        "    print(\"\\n=== Comprehensive Fold Performance ===\")\n",
        "    for fold in sorted(foldperf.keys()):\n",
        "        fold_metrics = {\n",
        "            'acc': foldperf[fold]['test_acc'][-1],\n",
        "            'precision': foldperf[fold]['test_precision'][-1],\n",
        "            'recall': foldperf[fold]['test_recall'][-1],\n",
        "            'auc': foldperf[fold]['test_auc'][-1],\n",
        "            'f1': foldperf[fold]['test_f1'][-1]\n",
        "        }\n",
        "\n",
        "        print(f\"\\n{fold}:\")\n",
        "        print(f\"Accuracy: {fold_metrics['acc']*100:.2f}%\")\n",
        "        print(f\"Precision: {fold_metrics['precision']:.4f}\")\n",
        "        print(f\"Recall: {fold_metrics['recall']:.4f}\")\n",
        "        print(f\"AUC: {fold_metrics['auc']:.4f}\")\n",
        "        print(f\"F1: {fold_metrics['f1']:.4f}\")\n",
        "\n",
        "        for k in metrics.keys():\n",
        "            metrics[k].append(fold_metrics[k])\n",
        "\n",
        "    print(\"\\n=== Aggregate Metrics ===\")\n",
        "    for metric, values in metrics.items():\n",
        "        unit = '%' if metric == 'acc' else ''\n",
        "        print(f\"Mean {metric.capitalize()}: {np.mean(values):.4f}{unit} ± {np.std(values):.4f}\")\n",
        "\n",
        "    return metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tGcY2F5ne7-o"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import roc_auc_score, auc, roc_curve\n",
        "\n",
        "def calculate_auc_metrics(fold_predictions):\n",
        "    \"\"\"\n",
        "    Calculate average AUC (mean of fold AUCs) and macro AUC (combined predictions)\n",
        "\n",
        "    Args:\n",
        "        fold_predictions: Dictionary from train_kfold_model containing\n",
        "                         (probs, labels) for each fold\n",
        "\n",
        "    Returns:\n",
        "        dict: Dictionary containing AUC metrics and combined predictions\n",
        "    \"\"\"\n",
        "    # Initialize storage\n",
        "    fold_aucs = []\n",
        "    all_probs = []\n",
        "    all_labels = []\n",
        "\n",
        "    # Process each fold\n",
        "    for fold, (probs, labels) in fold_predictions.items():\n",
        "        # Calculate fold AUC\n",
        "        fold_auc = roc_auc_score(labels, probs)\n",
        "        fold_aucs.append(fold_auc)\n",
        "\n",
        "        # Collect for macro calculation\n",
        "        all_probs.append(probs)\n",
        "        all_labels.append(labels)\n",
        "\n",
        "    # Convert to arrays\n",
        "    all_probs = np.concatenate(all_probs)\n",
        "    all_labels = np.concatenate(all_labels)\n",
        "\n",
        "    # Calculate metrics\n",
        "    metrics = {\n",
        "        'average_auc': np.mean(fold_aucs),\n",
        "        'std_auc': np.std(fold_aucs),\n",
        "        'macro_auc': roc_auc_score(all_labels, all_probs),\n",
        "        'fold_aucs': fold_aucs,\n",
        "        'all_probs': all_probs,\n",
        "        'all_labels': all_labels\n",
        "    }\n",
        "\n",
        "    # Print summary\n",
        "    print(f\"Average AUC (mean of folds): {metrics['average_auc']:.4f} ± {metrics['std_auc']:.4f}\")\n",
        "    print(f\"Macro AUC (combined data):   {metrics['macro_auc']:.4f}\")\n",
        "    print(\"\\nIndividual Fold AUCs:\")\n",
        "    for fold, auc_value in zip(fold_predictions.keys(), metrics['fold_aucs']):\n",
        "        print(f\"{fold}: {auc_value:.4f}\")\n",
        "\n",
        "    return metrics\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fuoCB8EfRmMB"
      },
      "outputs": [],
      "source": [
        "fold_perf_no_aug, fold_predictions_no_aug = train_kfold_model(catheter_tensor_u2plus,\n",
        "                                                               atria_tensor_u2plus,\n",
        "                              labels, all_ids, num_epochs=120,\n",
        "                              batch_size=8, data_aug=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vhpVMdDutCIK"
      },
      "outputs": [],
      "source": [
        "metrics_no_aug = summarize_kfold_metrics(fold_perf_no_aug)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pyY72zCe2IsC"
      },
      "outputs": [],
      "source": [
        "fold_perf_ds_ori_img, fold_predictions_ds_ori_img = train_kfold_model(catheter_tensor_ds,\n",
        "                              atria_tensor_ds,\n",
        "\n",
        "                              labels, all_ids, original_images=clahe_images,\n",
        "                                num_epochs=120,\n",
        "                              batch_size=8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XsK08m9_odbk"
      },
      "outputs": [],
      "source": [
        "metrics_ori_img_ds = summarize_kfold_metrics(fold_perf_ds_ori_img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xg8emWy550r_"
      },
      "outputs": [],
      "source": [
        "fold_perf_base_ori_img, fold_predictions_base_ori_img = train_kfold_model(catheter_tensor_base,\n",
        "                              atria_tensor_base,\n",
        "\n",
        "                              labels, all_ids, original_images=clahe_images,\n",
        "                                num_epochs=120,\n",
        "                              batch_size=8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iZZFub__olRk"
      },
      "outputs": [],
      "source": [
        "metrics_ori_img_base = summarize_kfold_metrics(fold_perf_base_ori_img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ufRgE8-kEWcm"
      },
      "outputs": [],
      "source": [
        "free_gpu_memory()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jhBAyZ8l4XIw"
      },
      "outputs": [],
      "source": [
        "fold_perf, fold_predictions = train_kfold_model(catheter_tensor_original,\n",
        "                              atria_tensor_original,\n",
        "                              labels, all_ids, num_epochs=120,\n",
        "                              batch_size=8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZBcNGq0botpW"
      },
      "outputs": [],
      "source": [
        "original_metrics = summarize_kfold_metrics(fold_perf)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LAk2RbU1ECjM"
      },
      "outputs": [],
      "source": [
        "metrics_real = summarize_kfold_metrics(fold_perf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wxi4LYMwnjt_"
      },
      "outputs": [],
      "source": [
        "auc_metrics_real_mask = calculate_auc_metrics(fold_predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rfZpcmNn0TDt"
      },
      "outputs": [],
      "source": [
        "fold_perf, fold_predictions = train_kfold_model(catheter_tensor_original,\n",
        "                              atria_tensor_original,\n",
        "                              labels, all_ids, num_epochs=120,\n",
        "                              batch_size=8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HZbTPn_NBA7E"
      },
      "outputs": [],
      "source": [
        "\n",
        "from sklearn.metrics import roc_curve, precision_recall_curve, auc\n",
        "def plot_combined_roc_curves(fold_predictions):\n",
        "    \"\"\"Plot all ROC curves in one figure with legend\"\"\"\n",
        "    plt.figure(figsize=(8, 6))\n",
        "\n",
        "    # Plot each fold's ROC curve\n",
        "    for fold, (probs, labels) in fold_predictions.items():\n",
        "        fpr, tpr, _ = roc_curve(labels, probs)\n",
        "        roc_auc = auc(fpr, tpr)\n",
        "        plt.plot(fpr, tpr, label=f'{fold} (AUC = {roc_auc:.2f})')\n",
        "\n",
        "    # Plot diagonal line\n",
        "    plt.plot([0, 1], [0, 1], 'k--', label='Random (AUC = 0.50)')\n",
        "\n",
        "    # Formatting\n",
        "    plt.xlabel('False Positive Rate', fontsize=10)\n",
        "    plt.ylabel('True Positive Rate', fontsize=10)\n",
        "    # plt.title('Combined ROC Curves Across Folds', fontsize=14)\n",
        "    plt.legend(loc='lower right', fontsize=10)\n",
        "    plt.grid(True, alpha=0.1)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def plot_combined_pr_curves(fold_predictions):\n",
        "    \"\"\"Plot all Precision-Recall curves in one figure with legend\"\"\"\n",
        "    plt.figure(figsize=(8, 6))\n",
        "\n",
        "    # Calculate baseline (percentage of positive cases)\n",
        "    _, first_labels = next(iter(fold_predictions.values()))\n",
        "    baseline = np.mean(first_labels)\n",
        "\n",
        "    # Plot each fold's PR curve\n",
        "    for fold, (probs, labels) in fold_predictions.items():\n",
        "        precision, recall, _ = precision_recall_curve(labels, probs)\n",
        "        pr_auc = auc(recall, precision)\n",
        "        plt.plot(recall, precision, label=f'{fold} (AUC = {pr_auc:.2f})')\n",
        "\n",
        "    # Plot baseline\n",
        "    plt.axhline(y=baseline, color='k', linestyle='--',\n",
        "                label=f'Baseline (AUC = {baseline:.2f})')\n",
        "\n",
        "    # Formatting\n",
        "    plt.xlabel('Recall', fontsize=10)\n",
        "    plt.ylabel('Precision', fontsize=10)\n",
        "    # plt.title('Combined Precision-Recall Curves Across Folds', fontsize=14)\n",
        "    plt.legend(loc='best', fontsize=10)\n",
        "    plt.grid(True, alpha=0.1)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Usage after training:\n",
        "# foldperf, fold_predictions = train_kfold_model(...)\n",
        "# plot_combined_roc_curves(fold_predictions)\n",
        "# plot_combined_pr_curves(fold_predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sb2P7SPfEeSA"
      },
      "outputs": [],
      "source": [
        "fold_perf_u2plus_last_conv, fold_predictions_u2plus_last_conv = train_kfold_model(catheter_tensor_u2plus,\n",
        "                              atria_tensor_u2plus,\n",
        "                              labels, all_ids, num_epochs=120,\n",
        "                              fine_tune='head_only',\n",
        "                              batch_size=8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "enAJih43C-Xz"
      },
      "outputs": [],
      "source": [
        "metrics_u2plus_last_conv = summarize_kfold_metrics(fold_perf_u2plus_last_conv)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "70mz7PArDCKt"
      },
      "outputs": [],
      "source": [
        "auc_metrics_u2plus_last_conv = calculate_auc_metrics(fold_predictions_u2plus_last_conv)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rERBr_tNDH4_"
      },
      "outputs": [],
      "source": [
        "fold_perf_u2plus_feat_extra, fold_predictions_u2plus_feat_extra = train_kfold_model(catheter_tensor_u2plus,\n",
        "                              atria_tensor_u2plus,\n",
        "                              labels, all_ids, num_epochs=120,\n",
        "                              fine_tune=None,\n",
        "                              batch_size=16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oaPHQt9_U-xe"
      },
      "outputs": [],
      "source": [
        "metrics_u2plus_feat_extra = summarize_kfold_metrics(fold_perf_u2plus_feat_extra)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5p-0YOrzVLG-"
      },
      "outputs": [],
      "source": [
        "auc_metrics_feat_extra = calculate_auc_metrics(fold_predictions_u2plus_feat_extra)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jGJpnFKul06V"
      },
      "outputs": [],
      "source": [
        "fold_perf_uplus2, fold_predictions_uplus2 = train_kfold_model(catheter_tensor_u2plus,\n",
        "                              atria_tensor_u2plus,\n",
        "                              labels, all_ids, num_epochs=120,\n",
        "                              batch_size=8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WasFBGkaPI4y"
      },
      "outputs": [],
      "source": [
        "metrics_uplus2 = summarize_kfold_metrics(fold_perf_uplus2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3jabwmU4PQrq"
      },
      "outputs": [],
      "source": [
        "auc_metrics_uplus2 = calculate_auc_metrics(fold_predictions_uplus2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QxxndwEtPXl3"
      },
      "outputs": [],
      "source": [
        "plot_combined_roc_curves(fold_predictions_uplus2)\n",
        "plot_combined_pr_curves(fold_predictions_uplus2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "30kwgES-PeqH"
      },
      "outputs": [],
      "source": [
        "fold_predictions_uplus2['fold1']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XPsPtxWMR0Sv"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "\n",
        "all_preds = []\n",
        "all_true = []\n",
        "\n",
        "for train_index, test_index in kf.split(probs.reshape(-1, 1), labels):\n",
        "    # Usually, you'd train your model here using train_index\n",
        "    # For this static example, just collect predictions and true labels\n",
        "    prob_fold = probs[test_index]\n",
        "    true_fold = labels[test_index]\n",
        "\n",
        "    # Convert probabilities to binary predictions (threshold = 0.5)\n",
        "    preds_fold = (prob_fold >= 0.5).astype(int)\n",
        "\n",
        "    all_preds.extend(preds_fold)\n",
        "    all_true.extend(true_fold)\n",
        "\n",
        "# Compute confusion matrix\n",
        "cm = confusion_matrix(all_true, all_preds)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(cm)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KBbz-wyHR_HP"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "def get_kfold_confusion_matrix(fold_predictions, threshold=0.5):\n",
        "\n",
        "  all_preds = []\n",
        "  all_true = []\n",
        "\n",
        "  for fold, (probs, labels) in fold_predictions.items():\n",
        "    # Convert probabilities to binary predictions (threshold = 0.5)\n",
        "    preds_fold = (probs >= threshold).astype(int)\n",
        "    all_preds.extend(preds_fold)\n",
        "    all_true.extend(labels)\n",
        "\n",
        "    # get the recall\n",
        "\n",
        "    # get the specificity\n",
        "\n",
        "\n",
        "\n",
        "  # Compute confusion matrix\n",
        "  cm = confusion_matrix(all_true, all_preds)\n",
        "  print(\"Confusion Matrix:\")\n",
        "  print(cm)\n",
        "  return cm\n",
        "\n",
        "  from sklearn.metrics import confusion_matrix\n",
        "\n",
        "def evaluate_folds(fold_predictions, threshold=0.5):\n",
        "    all_preds = []\n",
        "    all_true = []\n",
        "\n",
        "    for fold, (probs, labels) in fold_predictions.items():\n",
        "        # Convert probabilities to binary predictions\n",
        "        preds_fold = (probs >= threshold).astype(int)\n",
        "        all_preds.extend(preds_fold)\n",
        "        all_true.extend(labels)\n",
        "\n",
        "    # Compute confusion matrix\n",
        "    cm = confusion_matrix(all_true, all_preds)\n",
        "    print(\"Confusion Matrix:\")\n",
        "    print(cm)\n",
        "\n",
        "    # Extract components from 2x2 matrix\n",
        "    TN, FP, FN, TP = cm.ravel()\n",
        "\n",
        "    # Calculate metrics\n",
        "    recall = TP / (TP + FN)  # Sensitivity/Recall\n",
        "    specificity = TN / (TN + FP)  # Specificity\n",
        "\n",
        "    print(\"\\nPerformance Metrics:\")\n",
        "    print(f\"Recall (Sensitivity): {recall:.4f}\")\n",
        "    print(f\"Specificity: {specificity:.4f}\")\n",
        "    print(f\"Accuracy:    {(TP + TN)/(TP+TN+FP+FN):.4f}\")\n",
        "\n",
        "    return cm, recall, specificity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mx-S-pRnSY8w"
      },
      "outputs": [],
      "source": [
        "cm_05, _, _= evaluate_folds(fold_predictions_uplus2, threshold=0.5)\n",
        "plot_confusion_matrix(conf_mat=cm_05, figsize=(5, 5));"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ip1gr_EQTlrg"
      },
      "outputs": [],
      "source": [
        "cm_04, _, _= evaluate_folds(fold_predictions_uplus2, threshold=0.4)\n",
        "plot_confusion_matrix(conf_mat=cm_04, figsize=(5, 5));\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vn5y9dPlTwWM"
      },
      "outputs": [],
      "source": [
        "cm_03, _, _= evaluate_folds(fold_predictions_uplus2, threshold=0.3)\n",
        "plot_confusion_matrix(conf_mat=cm_03, figsize=(5, 5));"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xj0XHZI9WHYP"
      },
      "outputs": [],
      "source": [
        "cm_02, _, _= evaluate_folds(fold_predictions_uplus2, threshold=0.2)\n",
        "plot_confusion_matrix(conf_mat=cm_02, figsize=(5, 5));"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m5WzKf9xT3ca"
      },
      "outputs": [],
      "source": [
        "cm_01, _, _= evaluate_folds(fold_predictions_uplus2, threshold=0.1)\n",
        "plot_confusion_matrix(conf_mat=cm_01, figsize=(5, 5));"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-8tl9jBGT-kr"
      },
      "outputs": [],
      "source": [
        "cm_02 = get_kfold_confusion_matrix(fold_predictions_uplus2, threshold=0.2)\n",
        "plot_confusion_matrix(conf_mat=cm_02, figsize=(5, 5));"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ozLIxlmNUDux"
      },
      "outputs": [],
      "source": [
        "cm_01 = get_kfold_confusion_matrix(fold_predictions_uplus2, threshold=0.1)\n",
        "plot_confusion_matrix(conf_mat=cm_01, figsize=(5, 5));"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BDhUHdkpI-6E"
      },
      "outputs": [],
      "source": [
        "fold_perf_uplus, fold_predictions_uplus = train_kfold_model(catheter_tensor_u2plus,\n",
        "                              atria_tensor_u2plus,\n",
        "                              labels, all_ids, num_epochs=120,\n",
        "                              batch_size=8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TqG8Y9DOldEk"
      },
      "outputs": [],
      "source": [
        "fold_perf_unet2, fold_predictions_unet2 = train_kfold_model(catheter_tensor_u2plus,\n",
        "                              atria_tensor_u2plus,\n",
        "                              labels, all_ids, num_epochs=120,\n",
        "                              batch_size=8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_vQtWO8DmR6W"
      },
      "outputs": [],
      "source": [
        "metrics_unetp2 = summarize_kfold_metrics(fold_perf_unet2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_V1tgcjcn3LS"
      },
      "outputs": [],
      "source": [
        "auc_metrics_unetp2 = calculate_auc_metrics(fold_predictions_unet2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DpIHcz_7maH2"
      },
      "outputs": [],
      "source": [
        "plot_combined_roc_curves(fold_predictions_unet2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N44AmzfBmeyI"
      },
      "outputs": [],
      "source": [
        "plot_combined_pr_curves(fold_predictions_unet2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LSjbX_yYk8Am"
      },
      "outputs": [],
      "source": [
        "metris_uplus = summarize_kfold_metrics(fold_perf_uplus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DZsofW-55YTZ"
      },
      "outputs": [],
      "source": [
        "metrics_uplus2 =  summarize_kfold_metrics(fold_perf_uplus2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DvbO_-H13dX5"
      },
      "outputs": [],
      "source": [
        "fold_perf_uplus2_ds, fold_predictions_uplus2_ds = train_kfold_model(catheter_tensor_original,\n",
        "                              atria_tensor_u2plus,\n",
        "                              labels, all_ids, num_epochs=120,\n",
        "                              batch_size=8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yPHaHTO12DwW"
      },
      "outputs": [],
      "source": [
        "metrics_uplus2_ds = summarize_kfold_metrics(fold_perf_uplus2_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "taVu7xCPdRcO"
      },
      "outputs": [],
      "source": [
        "# summarize_kfold_metrics(fold_perf_uplus2_ds)\n",
        "metrics_dict = {\n",
        "    'Original masks': original_metrics,\n",
        "    'UNet++': metrics_unetp2,\n",
        "    'UNet++ OA': metrics_uplus2_ori_atr,\n",
        "    'UNet++ OC': metrics_uplus_oricath\n",
        "    # 'Uplus': metris_uplus\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b-61vv8PdWzJ"
      },
      "outputs": [],
      "source": [
        "fold_perf_uplus2_ori_cath, fold_predictions_uplus2_ori_img = train_kfold_model(catheter_tensor_u2plus,\n",
        "                              atria_tensor_original,\n",
        "                              labels, all_ids,\n",
        "                              num_epochs=120,\n",
        "                              batch_size=8)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yXIp-kfEV6lu"
      },
      "outputs": [],
      "source": [
        "metrics_uplus2_ori_atr = summarize_kfold_metrics(fold_perf_uplus2_ori_cath)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u2UagrqRoJ-A"
      },
      "outputs": [],
      "source": [
        "\n",
        "import json\n",
        "# with open('/content/drive/MyDrive/msc_uhasselt/experiments/classification/metrics_uplus2.json', 'w') as f:\n",
        "#     json.dump(metrics_dict, f)\n",
        "\n",
        "with open('/content/drive/MyDrive/msc_uhasselt/experiments/classification/metrics_uplus2.json', 'r') as f:\n",
        "    metrics_dict_prev = json.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n-9pUrX558at"
      },
      "outputs": [],
      "source": [
        "metrics_uplus_oricath = summarize_kfold_metrics(fold_perf_uplus2_ori_cath)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "97bk_XaabFsN"
      },
      "outputs": [],
      "source": [
        "fold_perf_uplus2_ori_atr, fold_predictions_uplus2_ori_atr = train_kfold_model(catheter_tensor_u2plus,\n",
        "                              atria_tensor_original,\n",
        "                              labels, all_ids,\n",
        "                              num_epochs=120,\n",
        "                              batch_size=8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W9akDdSIZ2Gg"
      },
      "outputs": [],
      "source": [
        "metrics_uplus2_ori_atr = summarize_kfold_metrics(fold_perf_uplus2_ori_atr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ssTQTe_q3dGy"
      },
      "outputs": [],
      "source": [
        "mwtrics_uplus2_ori_atr = summarize_kfold_metrics(fold_perf_uplus2_ori_atr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Ki0d18w5y6h"
      },
      "outputs": [],
      "source": [
        "metrics_uplus2_ori_img = summarize_kfold_metrics(fold_perf_uplus2_ori_img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LxYoTXyqoRSW"
      },
      "outputs": [],
      "source": [
        "def create_metrics_dataframe(metrics_dict, dataset_name):\n",
        "    \"\"\"Create formatted metrics DataFrame for a single dataset\"\"\"\n",
        "    df = pd.DataFrame(metrics_dict)\n",
        "    stats = pd.DataFrame({\n",
        "        'Mean': df.mean(),\n",
        "        'Std': df.std()\n",
        "    }).round(4)\n",
        "    # stats['Mean ± Std'] = stats['Mean'].astype(str) + ' ± ' + stats['Std'].astype(str)\n",
        "    stats['Dataset'] = dataset_name\n",
        "    stats['metric'] = ['acc', 'precision', 'recall', 'auc', 'f1-score']\n",
        "    return stats\n",
        "\n",
        "# Create comparison table for all datasets\n",
        "comparison_dfs = []\n",
        "for dataset_name, metrics in metrics_dict.items():\n",
        "    comparison_dfs.append(create_metrics_dataframe(metrics, dataset_name))\n",
        "\n",
        "final_comparison = pd.concat(comparison_dfs)\n",
        "# Convert to wide format\n",
        "wide_df = final_comparison.pivot(index=\"Dataset\", columns=\"metric\", values=[\"Mean\", \"Std\"])\n",
        "\n",
        "# Flatten multi-index columns and rename\n",
        "wide_df.columns = [f\"{stat}_{metric}\" for stat, metric in wide_df.columns]\n",
        "wide_df = wide_df.reset_index()\n",
        "\n",
        "# Reorder columns logically\n",
        "metric_order = [\"acc\", \"precision\", \"recall\", \"auc\", \"f1-score\"]\n",
        "column_order = [\"Dataset\"] + [f\"{stat}_{met}\" for met in metric_order for stat in [\"Mean\", \"Std\"]]\n",
        "wide_df = wide_df[column_order]\n",
        "wide_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N67g4gpeGP3B"
      },
      "outputs": [],
      "source": [
        "print(f'AUC fold summary for original maks\\n')\n",
        "auc_metrics_real_mask = calculate_auc_metrics(fold_predictions)\n",
        "\n",
        "print(f'AUC fold summary for UNet++\\n')\n",
        "auc_metrics_unetp2 = calculate_auc_metrics(fold_predictions_unet2)\n",
        "\n",
        "print(f'AUC fold summary for UNet++  OC\\n')\n",
        "auc_metrics_uplus_oricath = calculate_auc_metrics(fold_predictions_uplus2_ori_img)\n",
        "\n",
        "print(f'AUC fold summary for UNet++ OA\\n')\n",
        "auc_metrics_uplus2_ori_atr = calculate_auc_metrics(fold_predictions_uplus2_ori_atr)\n",
        "print(f'AUC fold summary for UNet++ no clahe\\n')\n",
        "auc_metrics_uplus2_ds = calculate_auc_metrics(fold_predictions_no_clahe)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XtGsDRMMzWCQ"
      },
      "outputs": [],
      "source": [
        "plot_combined_roc_curves(fold_predictions_uplus2_ori_atr)\n",
        "plot_combined_pr_curves(fold_predictions_uplus2_ori_atr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dc1YiWumIPyh"
      },
      "outputs": [],
      "source": [
        "plot_combined_pr_curves(fold_predictions_uplus2_ori_img) # UNet++ predicted atrium + original catheter\n",
        "plot_combined_roc_curves(fold_predictions_uplus2_ori_img) #"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z2WCYD3_591I"
      },
      "outputs": [],
      "source": [
        "fold_perf_uplus2_ori_atrium, fold_predictions_uplus2_ori_atrium = train_kfold_model(catheter_tensor_original,\n",
        "                              atria_tensor_u2plus,\n",
        "                              labels, all_ids, original_images=clahe_images,\n",
        "                              num_epochs=120,\n",
        "                              batch_size=8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AQDx4vxV-DcH"
      },
      "outputs": [],
      "source": [
        "free_gpu_memory()\n",
        "\n",
        "IMG_SIZE = 600\n",
        "\n",
        "train_transform = A.Compose([\n",
        "    A.Resize(IMG_SIZE, IMG_SIZE, interpolation=cv2.INTER_NEAREST),\n",
        "        A.HorizontalFlip(p=0.3),\n",
        "        A.Rotate(limit=15, p=0.2, border_mode=cv2.BORDER_CONSTANT),\n",
        "        A.GridElasticDeform(\n",
        "       num_grid_xy=(5, 5),\n",
        "           magnitude=4,\n",
        "         interpolation=cv2.INTER_NEAREST,\n",
        "                mask_interpolation=cv2.INTER_NEAREST,\n",
        "           p=0.3\n",
        "       )  ,\n",
        "        A.ToTensorV2()\n",
        "    ])\n",
        "\n",
        "val_transform = A.Compose([\n",
        "        A.Resize(IMG_SIZE, IMG_SIZE, interpolation=cv2.INTER_NEAREST),\n",
        "        A.ToTensorV2()\n",
        "    ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "juIe7VOXoroc"
      },
      "outputs": [],
      "source": [
        "fold_perf_ds, fold_predictions_ds = train_kfold_model(catheter_tensor_ds,\n",
        "                              atria_tensor_ds,\n",
        "                              labels, all_ids, num_epochs=120,\n",
        "                              batch_size=8)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kLVgF1xKHawV"
      },
      "outputs": [],
      "source": [
        "metrics_ds = summarize_kfold_metrics(fold_perf_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7h3zItONUtik"
      },
      "outputs": [],
      "source": [
        "plot_combined_roc_curves(fold_predictions_ds)\n",
        "plot_combined_pr_curves(fold_predictions_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t4WKI283HhyE"
      },
      "outputs": [],
      "source": [
        "fold_perf_base, fold_predictions_base = train_kfold_model(catheter_tensor_base,\n",
        "                              atria_tensor_base,\n",
        "                              labels, all_ids, num_epochs=120,\n",
        "                              batch_size=8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FVfR5QEQFjzp"
      },
      "outputs": [],
      "source": [
        "plot_combined_roc_curves(fold_predictions_base)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rhzm4NSWybV9"
      },
      "outputs": [],
      "source": [
        "metrics_base = summarize_kfold_metrics(fold_perf_base)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1R2V4DwK1PJ0"
      },
      "outputs": [],
      "source": [
        "fold_ori_atrium_pred_cath_perf = train_kfold_model(catheter_tensor_ds,\n",
        "                              atria_tensor_original,\n",
        "                              labels, all_ids, num_epochs=120,\n",
        "                              batch_size=8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "exyaRVXH1oCe"
      },
      "outputs": [],
      "source": [
        "metrics_ori_atrium = summarize_kfold_metrics(fold_ori_atrium_pred_cath_perf[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "hXoyxrQ9UJaS"
      },
      "outputs": [],
      "source": [
        "plot_combined_roc_curves(fold_ori_atrium_pred_cath_perf[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "Q_ct_MKEWDYz"
      },
      "outputs": [],
      "source": [
        "fold_ori_cath_pred_atrium_perf, fold_predictins_ori_cath_pred = train_kfold_model(catheter_tensor_original,\n",
        "                              atria_tensor_ds,\n",
        "                              labels, all_ids, num_epochs=120,\n",
        "                              batch_size=8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "1_YLQfYS17h4"
      },
      "outputs": [],
      "source": [
        "metrics_ori_cath = summarize_kfold_metrics(fold_ori_cath_pred_atrium_perf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "EEATQRNuT_gw"
      },
      "outputs": [],
      "source": [
        "plot_combined_roc_curves(fold_predictions_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4LT-BvJ2ziY8"
      },
      "outputs": [],
      "source": [
        "kfol_experiments = {\n",
        "    'Original masks': fold_perf,\n",
        "    'UNet +++ DS': fold_perf_ds,\n",
        "    'UNet +++': fold_perf_base,\n",
        "    'Cath DS + Original Atrium': fold_ori_atrium_pred_cath_perf[0],\n",
        "    'Atrium DS + Original Cath': fold_ori_cath_pred_atrium_perf\n",
        "\n",
        "}\n",
        "# Save as json file\n",
        "import json\n",
        "with open('/content/drive/MyDrive/msc_uhasselt/experiments/classification/kfold_experiments.json', 'w') as f:\n",
        "    json.dump(kfol_experiments, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ez1DOnR9yuiA"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "experiments = {\n",
        "    'Original masks': original_metrics,\n",
        "    'UNet +++ DS': metrics_ds,\n",
        "    'UNet +++': metrics_base,\n",
        "    'Cath DS + Original Atrium': metrics_ori_atrium,\n",
        "    'Atrium DS + Original Cath': metrics_ori_cath\n",
        "}\n",
        "\n",
        "with open('/content/drive/MyDrive/msc_uhasselt/experiments/classification/metrics.json', 'w') as f:\n",
        "\n",
        "\n",
        "    json.dump(experiments, f)\n",
        "\n",
        "# read back saved json\n",
        "with open('/content/drive/MyDrive/msc_uhasselt/experiments/classification/metrics.json', 'r') as f:\n",
        "    experiments = json.load(f)\n",
        "\n",
        "\n",
        "wide_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W29ELj0Pa3cJ"
      },
      "outputs": [],
      "source": [
        "IMG_SIZE = 600\n",
        "train_transform = A.Compose([\n",
        "        A.Resize(IMG_SIZE, IMG_SIZE, interpolation=cv2.INTER_NEAREST),\n",
        "        A.HorizontalFlip(p=0.3),\n",
        "        A.Rotate(limit=15, p=0.2, border_mode=cv2.BORDER_CONSTANT),\n",
        "        A.GridElasticDeform(\n",
        "       num_grid_xy=(7, 7),\n",
        "           magnitude=3,\n",
        "         interpolation=cv2.INTER_NEAREST,\n",
        "                mask_interpolation=cv2.INTER_NEAREST,\n",
        "           p=0.2\n",
        "       )  ,\n",
        "        A.ToTensorV2()\n",
        "    ])\n",
        "\n",
        "\n",
        "val_transform = A.Compose([\n",
        "        A.Resize(IMG_SIZE, IMG_SIZE, interpolation=cv2.INTER_NEAREST),\n",
        "        A.ToTensorV2()\n",
        "    ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fg5m5E1SAWiR"
      },
      "outputs": [],
      "source": [
        "dataset_uplus = ClassificationDataset(catheter_tensor_u2plus,\n",
        "                                         atria_tensor_u2plus,\n",
        "                                         labels, ids=all_ids,\n",
        "                                         transform=train_transform)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_J_OYfrFAhb1"
      },
      "outputs": [],
      "source": [
        "idx = 100\n",
        "\n",
        "img, label, id = dataset_uplus[idx]\n",
        "\n",
        "plt.imshow(img.permute(1, 2, 0))\n",
        "plt.title(f\"Label: {label}, ID: {id}\")\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jBVBtz71AjKu"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Upsi2BhlTMy"
      },
      "source": [
        "Fine tune only the last conv block of ConvNeXt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rG_XI1320I1o"
      },
      "outputs": [],
      "source": [
        "auc_metrics_uplus2 = calculate_auc_metrics(fold_predictions_uplus2)\n",
        "\n",
        "auc_metrics_up2_oricath = calculate_auc_metrics(fold_predictions_uplus2_ori_img)\n",
        "\n",
        "auc_metrics_up2_ori_atrium = calculate_auc_metrics(fold_predictions_uplus2_ori_atr)\n",
        "\n",
        "# np.savez('/content/drive/MyDrive/msc_uhasselt/experiments/classification/fold_pred_uplus2.npz', **fold_predictions_uplus2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G_M-5rBo2fx-"
      },
      "outputs": [],
      "source": [
        "fold_predictions_to_save = {}\n",
        "for fold, (probs, labels) in fold_predictions_uplus2_ori_atr.items():\n",
        "    # Explicitly convert probs and labels to numpy arrays\n",
        "    fold_predictions_to_save[fold + '_probs'] = np.array(probs)\n",
        "    fold_predictions_to_save[fold + '_labels'] = np.array(labels)\n",
        "\n",
        "# Save the prepared dictionary\n",
        "np.savez('/content/drive/MyDrive/msc_uhasselt/experiments/classification/fold_pred_uplus2_oriatr.npz', **fold_predictions_to_save)\n",
        "# --- FIX ENDS HERE ---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "knkeH9dK1Pxq"
      },
      "outputs": [],
      "source": [
        "np.savez('/content/drive/MyDrive/msc_uhasselt/experiments/classification/auc_metrics_uplus2.npz', **auc_metrics_uplus2)\n",
        "np.savez('/content/drive/MyDrive/msc_uhasselt/experiments/classification/auc_metrics_uplus2_oricath.npz', **auc_metrics_up2_oricath)\n",
        "np.savez('/content/drive/MyDrive/msc_uhasselt/experiments/classification/auc_metrics_uplus2_oriatr.npz', **auc_metrics_up2_ori_atrium)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ys05e2m72DpG"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dlyb6riTfdkb"
      },
      "outputs": [],
      "source": [
        "np.savez('/content/drive/MyDrive/msc_uhasselt/experiments/classification/auc_metrics_original.npz', **auc_metrics)\n",
        "# loaded_data = np.load('/content/drive/MyDrive/msc_uhasselt/experiments/classification/auc_metrics_original.npz', allow_pickle=True)\n",
        "# data_loaded = {key: loaded_data[key] for key in loaded_data.files}\n",
        "# data_loaded\n",
        "auc_metrics_ds = calculate_auc_metrics(fold_predictions_ds)\n",
        "np.savez('/content/drive/MyDrive/msc_uhasselt/experiments/classification/auc_metrics_ds.npz', **auc_metrics_ds)\n",
        "auc_metrics_base = calculate_auc_metrics(fold_predictions_base)\n",
        "np.savez('/content/drive/MyDrive/msc_uhasselt/experiments/classification/auc_metrics_base.npz', **auc_metrics_base)\n",
        "auc_metrics_ori_atrium = calculate_auc_metrics(fold_ori_atrium_pred_cath_perf[1])\n",
        "np.savez('/content/drive/MyDrive/msc_uhasselt/experiments/classification/auc_metrics_ori_atrium.npz', **auc_metrics_ori_atrium)\n",
        "auc_metrics_ori_cath = calculate_auc_metrics(fold_predictins_ori_cath_pred)\n",
        "np.savez('/content/drive/MyDrive/msc_uhasselt/experiments/classification/auc_metrics_ori_cath.npz', **auc_metrics_ori_cath)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GPyxatJf3Hdk"
      },
      "outputs": [],
      "source": [
        "free_gpu_memory()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mC-knkz0Xq0B"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score,\n",
        "    precision_score,\n",
        "    f1_score,\n",
        "    matthews_corrcoef,\n",
        "    confusion_matrix,\n",
        "    recall_score\n",
        ")\n",
        "\n",
        "def calculate_classification_metrics(fold_predictions, threshold=0.5):\n",
        "    \"\"\"\n",
        "    Calculate classification metrics (Accuracy, Precision, MCC, F1) from fold predictions.\n",
        "\n",
        "    Args:\n",
        "        fold_predictions (dict): Dictionary of fold predictions (probs, labels).\n",
        "        threshold (float): Decision threshold for binary classification (default=0.5).\n",
        "\n",
        "    Returns:\n",
        "        dict: Contains fold-wise and macro-averaged metrics.\n",
        "    \"\"\"\n",
        "    fold_metrics = {\n",
        "        'accuracy': [],\n",
        "        'precision': [],\n",
        "        'f1': [],\n",
        "        'mcc': []\n",
        "    }\n",
        "    all_probs = []\n",
        "    all_labels = []\n",
        "\n",
        "    for fold, (probs, labels) in fold_predictions.items():\n",
        "        # Binarize predictions\n",
        "        preds = (probs >= threshold).astype(int)\n",
        "\n",
        "        # Compute metrics for this fold\n",
        "        fold_metrics['accuracy'].append(accuracy_score(labels, preds))\n",
        "        fold_metrics['precision'].append(precision_score(labels, preds, zero_division=0))\n",
        "        fold_metrics['f1'].append(f1_score(labels, preds))\n",
        "        fold_metrics['mcc'].append(matthews_corrcoef(labels, preds))\n",
        "\n",
        "        # Store for macro-averaging\n",
        "        all_probs.extend(probs)\n",
        "        all_labels.extend(labels)\n",
        "\n",
        "    # Convert to arrays\n",
        "    all_probs = np.array(all_probs)\n",
        "    all_labels = np.array(all_labels)\n",
        "    all_preds = (all_probs >= threshold).astype(int)\n",
        "\n",
        "    # Macro-averaged metrics (computed on all data combined)\n",
        "    macro_metrics = {\n",
        "        'accuracy': accuracy_score(all_labels, all_preds),\n",
        "        'precision': precision_score(all_labels, all_preds, zero_division=0),\n",
        "        'f1': f1_score(all_labels, all_preds),\n",
        "        'mcc': matthews_corrcoef(all_labels, all_preds),\n",
        "        # 'recall': recall_score(all_labels, all_preds)\n",
        "    }\n",
        "\n",
        "    # Fold-wise averages (mean ± std)\n",
        "    avg_metrics = {\n",
        "        'avg_accuracy': np.mean(fold_metrics['accuracy']),\n",
        "        'std_accuracy': np.std(fold_metrics['accuracy']),\n",
        "        'avg_precision': np.mean(fold_metrics['precision']),\n",
        "        'std_precision': np.std(fold_metrics['precision']),\n",
        "        'avg_f1': np.mean(fold_metrics['f1']),\n",
        "        'std_f1': np.std(fold_metrics['f1']),\n",
        "        'avg_mcc': np.mean(fold_metrics['mcc']),\n",
        "        'std_mcc': np.std(fold_metrics['mcc'])\n",
        "        # 'avg_recall': np.mean(fold_metrics['recall']),\n",
        "        # 'std_recall': np.std(fold_metrics['recall'])\n",
        "    }\n",
        "\n",
        "    return {\n",
        "        'fold_metrics': fold_metrics,  # Metrics per fold\n",
        "        'avg_metrics': avg_metrics,   # Mean ± std across folds\n",
        "        'macro_metrics': macro_metrics  # Computed on all data\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lMClgSoxYWsv"
      },
      "outputs": [],
      "source": [
        "class_metrics_original = calculate_classification_metrics(fold_predictions)\n",
        "class_metrics_ds = calculate_classification_metrics(fold_predictions_ds)\n",
        "class_metrics_base = calculate_classification_metrics(fold_predictions_base)\n",
        "class_metrics_ori_atrium = calculate_classification_metrics(fold_ori_atrium_pred_cath_perf[1])\n",
        "class_metrics_ori_cath = calculate_classification_metrics(fold_predictins_ori_cath_pred)\n",
        "\n",
        "\n",
        "metrics = {\n",
        "    'Original masks': class_metrics_original,\n",
        "    'UNet +++ DS': class_metrics_ds,\n",
        "    'UNet +++': class_metrics_base,\n",
        "    'Cath DS + Original Atrium': class_metrics_ori_atrium,\n",
        "    'Atrium DS + Original Cath': class_metrics_ori_cath\n",
        "}\n",
        "\n",
        "with open('/content/drive/MyDrive/msc_uhasselt/experiments/classification/class_metrics.json', 'w') as f:\n",
        "    json.dump(metrics, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zCLc0ljzl9hD"
      },
      "outputs": [],
      "source": [
        "calculate_classification_metrics(fold_predictions, threshold=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "siDyxHeqYfUy"
      },
      "outputs": [],
      "source": [
        "calculate_classification_metrics(fold_predictions_ds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LtaTYgKOkIR4"
      },
      "source": [
        "### Try Convenext"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "glln4p-scQAF"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import models\n",
        "from torchvision.models import (\n",
        "    EfficientNet_B0_Weights,\n",
        "    EfficientNet_B7_Weights,\n",
        "    ConvNeXt_Tiny_Weights,\n",
        "    ConvNeXt_Base_Weights\n",
        ")\n",
        "\n",
        "\n",
        "def call_model(model_name='convnext_tiny', device=None, fine_tune=None, drop_out_prob=0.2):\n",
        "    \"\"\"\n",
        "    Initialize ConvNeXt or EfficientNet using torchvision models.\n",
        "\n",
        "    Args:\n",
        "        model_name: One of ['convnext_tiny', 'convnext_base', 'efficientnet_b0', 'efficientnet_b7']\n",
        "        device: torch.device\n",
        "        fine_tune: None (frozen), 'head_only' (final conv + classifier),\n",
        "                   'last_two' (last two blocks), or 'all' (entire model)\n",
        "    \"\"\"\n",
        "    # Device setup\n",
        "    device = device or torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    # Model initialization with pretrained weights\n",
        "    if model_name.startswith('convnext'):\n",
        "        if model_name == 'convnext_tiny':\n",
        "            weights = ConvNeXt_Tiny_Weights.IMAGENET1K_V1\n",
        "            model = models.convnext_tiny(weights=weights)\n",
        "        elif model_name == 'convnext_base':\n",
        "            weights = ConvNeXt_Base_Weights.IMAGENET1K_V1\n",
        "            model = models.convnext_base(weights=weights)\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported ConvNeXt variant: {model_name}\")\n",
        "\n",
        "        # For ConvNeXt, the final \"block\" is actually a Sequential of layers\n",
        "        final_conv = model.features[-1][-1]  # Get last layer of last block\n",
        "\n",
        "    elif model_name.startswith('efficientnet'):\n",
        "        if model_name == 'efficientnet_b0':\n",
        "            weights = EfficientNet_B0_Weights.IMAGENET1K_V1\n",
        "            model = models.efficientnet_b0(weights=weights)\n",
        "        elif model_name == 'efficientnet_b7':\n",
        "            weights = EfficientNet_B7_Weights.IMAGENET1K_V1\n",
        "            model = models.efficientnet_b7(weights=weights)\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported EfficientNet variant: {model_name}\")\n",
        "\n",
        "        # For EfficientNet, identify the final convolutional layer\n",
        "        final_conv = model.features[-1]\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown model: {model_name}\")\n",
        "\n",
        "    # Freezing parameters based on fine_tune option\n",
        "    if fine_tune is None:\n",
        "        # Freeze all parameters\n",
        "        for param in model.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "    elif fine_tune == 'head_only':\n",
        "        # Freeze all parameters first\n",
        "        for param in model.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "        # Unfreeze the final convolutional layer\n",
        "        for param in final_conv.parameters():\n",
        "            param.requires_grad = True\n",
        "\n",
        "    elif fine_tune == 'last_two':\n",
        "        # Unfreeze last two blocks\n",
        "        if model_name.startswith('convnext'):\n",
        "            for block in model.features[-2:]:\n",
        "                for param in block.parameters():\n",
        "                    param.requires_grad = True\n",
        "        else:  # EfficientNet\n",
        "            for layer in model.features[-2:]:\n",
        "                for param in layer.parameters():\n",
        "                    param.requires_grad = True\n",
        "\n",
        "    elif fine_tune == 'all':\n",
        "        # All parameters remain trainable\n",
        "        pass\n",
        "    else:\n",
        "        raise ValueError(\"fine_tune must be None, 'head_only', 'last_two', or 'all'\")\n",
        "\n",
        "    # Replace classifier head for binary classification\n",
        "    if model_name.startswith('convnext'):\n",
        "        in_features = model.classifier[-1].in_features\n",
        "        model.classifier = nn.Sequential(\n",
        "            model.classifier[0],  # Keep LayerNorm2d\n",
        "            model.classifier[1],  # Keep AdaptiveAvgPool2d\n",
        "            nn.Flatten(),\n",
        "            nn.Dropout(p=drop_out_prob, inplace=True),\n",
        "            nn.Linear(in_features, 1)\n",
        "        )\n",
        "    else:  # EfficientNet\n",
        "        in_features = model.classifier[-1].in_features\n",
        "        model.classifier = nn.Sequential(\n",
        "            nn.Dropout(p=drop_out_prob, inplace=True),\n",
        "            nn.Linear(in_features, 1)\n",
        "        )\n",
        "\n",
        "    return model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SHO1pIMYZDEg"
      },
      "outputs": [],
      "source": [
        "original_convnext_perf, original_convnext_predictions = train_kfold_model(catheter_tensor_original,\n",
        "                              atria_tensor_original,\n",
        "                              labels, all_ids,\n",
        "                              num_epochs=120, size=224,\n",
        "                              model_name='convnext_tiny',\n",
        "                              batch_size=16)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tWqPa82qmi6y"
      },
      "outputs": [],
      "source": [
        "merics_convnext_original = summarize_kfold_metrics(original_convnext_perf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0qLSlZxPmlgM"
      },
      "outputs": [],
      "source": [
        "plot_combined_roc_curves(original_convnext_predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j6dUyImtmoNS"
      },
      "outputs": [],
      "source": [
        "original_convnext_large_perf, original_convnext_large_predictions = train_kfold_model(catheter_tensor_original,\n",
        "                              atria_tensor_original,\n",
        "                              labels, all_ids,\n",
        "                              num_epochs=120, size=224,\n",
        "                              model_name='convnext_base',\n",
        "                              batch_size=16)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gjsOK5s8xo9G"
      },
      "outputs": [],
      "source": [
        "metrics_convnext_large = summarize_kfold_metrics(original_convnext_large_perf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hmAMK4e5x2X5"
      },
      "outputs": [],
      "source": [
        "plot_combined_roc_curves(original_convnext_large_predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uSliS9ztx5Fo"
      },
      "outputs": [],
      "source": [
        "convnext_ds_perf, convnext_ds_predictions = train_kfold_model(catheter_tensor_ds,\n",
        "                              atria_tensor_original,\n",
        "                              labels, all_ids,\n",
        "                              num_epochs=120, size=224, model_name='convnext_base',\n",
        "                              batch_size=16)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b8Q2VJdYNLiy"
      },
      "outputs": [],
      "source": [
        "metrics_convnext_ds = summarize_kfold_metrics(convnext_ds_perf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZaqnYFcmNVwK"
      },
      "outputs": [],
      "source": [
        "plot_combined_roc_curves(convnext_ds_predictions)\n",
        "#"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xqV0j5zRNwX_"
      },
      "outputs": [],
      "source": [
        "convnext_base_perf, convnext_base_predictions = train_kfold_model(catheter_tensor_base,\n",
        "                              atria_tensor_base,\n",
        "                              labels, all_ids,\n",
        "                              num_epochs=120, size=224, model_name='convnext_base',\n",
        "                              batch_size=16)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "26vlCPa1YxX9"
      },
      "outputs": [],
      "source": [
        "metrics_convnext_base = summarize_kfold_metrics(convnext_base_perf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ywcnS9ByYzYC"
      },
      "outputs": [],
      "source": [
        "convnext_ds_perf, convnext_ds_predictions = train_kfold_model(catheter_tensor_ds,\n",
        "                              atria_tensor_ds,\n",
        "                              labels, all_ids,\n",
        "                              num_epochs=120, size=224, model_name='convnext_base',\n",
        "                              batch_size=16)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LtnPhkbahecG"
      },
      "outputs": [],
      "source": [
        "# create an 80 20 % training and test data set\n",
        "metrics_convnext_ds = summarize_kfold_metrics(convnext_ds_perf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Lp5KP5Xl8Tt"
      },
      "outputs": [],
      "source": [
        "plot_combined_roc_curves(convnext_ds_predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sbT-pIbKormB"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BuEkTx44l_wZ"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "IMG_SIZE = 600\n",
        "train_transform = A.Compose([\n",
        "        A.Resize(IMG_SIZE, IMG_SIZE, interpolation=cv2.INTER_NEAREST),\n",
        "        A.HorizontalFlip(p=0.3),\n",
        "        A.Rotate(limit=15, p=0.2, border_mode=cv2.BORDER_CONSTANT),\n",
        "        A.GridElasticDeform(\n",
        "       num_grid_xy=(7, 7),\n",
        "           magnitude=3,\n",
        "         interpolation=cv2.INTER_NEAREST,\n",
        "                mask_interpolation=cv2.INTER_NEAREST,\n",
        "           p=0.2\n",
        "       )  ,\n",
        "        A.ToTensorV2()\n",
        "    ])\n",
        "\n",
        "\n",
        "val_transform = A.Compose([\n",
        "        A.Resize(IMG_SIZE, IMG_SIZE, interpolation=cv2.INTER_NEAREST),\n",
        "        A.ToTensorV2()\n",
        "    ])\n",
        "#\n",
        "\n",
        "# 2. Create train-test split (80-20) based on IDs\n",
        "train_ids, test_ids = train_test_split(\n",
        "    all_ids,\n",
        "    test_size=0.2,\n",
        "    stratify=labels,\n",
        "    random_state=42  # For reproducibility\n",
        ")\n",
        "\n",
        "# 3. Create boolean masks for indexing\n",
        "train_mask = np.isin(all_ids, train_ids)\n",
        "test_mask = np.isin(all_ids, test_ids)\n",
        "\n",
        "# 4. Create datasets with appropriate transforms\n",
        "train_dataset = ClassificationDataset(\n",
        "    catheter_predictions=catheter_tensor_u2plus[train_mask],\n",
        "    atria_predictions=atria_tensor_u2plus[train_mask],\n",
        "    labels=[labels[i] for i in np.where(train_mask)[0]],\n",
        "    # original_images=original_images[train_mask] if original_images is not None else None,\n",
        "    ids=train_ids,\n",
        "    transform=train_transform,\n",
        "    # normalize=True\n",
        ")\n",
        "\n",
        "test_dataset = ClassificationDataset(\n",
        "    catheter_predictions=catheter_tensor_u2plus[test_mask],\n",
        "    atria_predictions=atria_tensor_u2plus[test_mask],\n",
        "    labels=[labels[i] for i in np.where(test_mask)[0]],\n",
        "    # original_images=original_images[test_mask] if original_images is not None else None,\n",
        "    ids=test_ids,\n",
        "    transform=val_transform,\n",
        "    # normalize=True\n",
        ")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qdL7o4mTpoXN"
      },
      "outputs": [],
      "source": [
        "\n",
        "idx = 5\n",
        "\n",
        "img, lab, id = train_dataset[idx]\n",
        "\n",
        "plt.imshow(img.permute(1, 2, 0))\n",
        "plt.title(f\"Label: {lab}, ID: {id}\")\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-O2ZTNe_qSvX"
      },
      "outputs": [],
      "source": [
        "num_epochs = 120\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# Create DataLoaders\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
        "val_dataloader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n",
        "\n",
        "\n",
        "\n",
        "model = call_model(model_name='efficientnet_b7', device=device, fine_tune='last_two', drop_out_prob=0.5)\n",
        "model.to(device)\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "\n",
        "\n",
        "# Define loss function and optimizer\n",
        "optimizer = AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=0.0001, weight_decay=0.001)\n",
        "\n",
        "\n",
        "# LR scheduling\n",
        "warmup_epochs = 5  # Number of epochs for warmup\n",
        "warmup_scheduler = LinearLR(optimizer, start_factor=0.01, end_factor=1.0, total_iters=warmup_epochs)\n",
        "\n",
        "  # Step 2: Cosine decay scheduler (after warmup)\n",
        "cosine_scheduler = CosineAnnealingLR(optimizer, T_max=num_epochs - warmup_epochs, eta_min=1e-6)\n",
        "\n",
        "  # # Combined scheduler\n",
        "from torch.optim.lr_scheduler import SequentialLR\n",
        "scheduler = SequentialLR(\n",
        "      optimizer,\n",
        "      schedulers=[warmup_scheduler, cosine_scheduler],\n",
        "      milestones=[warmup_epochs]\n",
        "      )\n",
        "\n",
        "# Training loop\n",
        "epoch_losses = []\n",
        "epoch_accuracies = []\n",
        "val_accuracies = []\n",
        "val_loss = []\n",
        "for epoch in tqdm(range(num_epochs), desc=f'Epochs'):\n",
        "  free_gpu_memory()\n",
        "  train_loss, train_acc = train_step(model, train_dataloader, criterion, optimizer, scheduler, device)\n",
        "  val_metrics = test_step(model, val_dataloader, criterion, device)\n",
        "  epoch_losses.append(train_loss)\n",
        "  epoch_accuracies.append(train_acc)\n",
        "  val_loss.append(val_metrics[0])\n",
        "  val_accuracies.append(val_metrics[1])\n",
        "  if (epoch + 1) % 10 == 0 or epoch == 0 or (epoch + 1) == num_epochs:\n",
        "    print(f\"Epoch {epoch+1:03d} | \"\n",
        "          f\"Train Loss: {train_loss:.4f} | \"\n",
        "          f\"Train Acc: {train_acc * 100:.2f}% | \"\n",
        "          f\"Val Loss: {val_metrics[0]:.4f} | \"\n",
        "          f\"Val Acc: {val_metrics[1] * 100:.2f}%\")\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fwGu0Yi7Tsjh"
      },
      "outputs": [],
      "source": [
        "# plot loss and accuracies\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epoch_losses, label='Train Loss')\n",
        "plt.plot(val_loss, label='Val Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epoch_accuracies, label='Train Accuracy')\n",
        "plt.plot(val_accuracies, label='Val Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hO5VL9gPT86n"
      },
      "outputs": [],
      "source": [
        "# save model\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# model.to(device)\n",
        "# torch.save(model.state_dict(), '/content/drive/MyDrive/msc_uhasselt/experiments/classification/effnet_unetp2.pth')\n",
        "\n",
        "model = call_model(model_name='efficientnet_b7', device=device, fine_tune='last_two')\n",
        "# model.to(device)\n",
        "model.load_state_dict(torch.load('/content/drive/MyDrive/msc_uhasselt/experiments/classification/effnet_unetp2.pth'))\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OStAfjWzxSNG"
      },
      "outputs": [],
      "source": [
        "!pip install optuna\n",
        "import optuna\n",
        "from optuna.trial import TrialState\n",
        "\n",
        "IMG_SIZE = 224\n",
        "train_transform = A.Compose([\n",
        "        A.Resize(IMG_SIZE, IMG_SIZE, interpolation=cv2.INTER_NEAREST),\n",
        "        A.HorizontalFlip(p=0.3),\n",
        "        A.Rotate(limit=15, p=0.2, border_mode=cv2.BORDER_CONSTANT),\n",
        "        A.GridElasticDeform(\n",
        "       num_grid_xy=(7, 7),\n",
        "           magnitude=3,\n",
        "         interpolation=cv2.INTER_NEAREST,\n",
        "                mask_interpolation=cv2.INTER_NEAREST,\n",
        "           p=0.2\n",
        "       )  ,\n",
        "        A.ToTensorV2()\n",
        "    ])\n",
        "\n",
        "\n",
        "val_transform = A.Compose([\n",
        "        A.Resize(IMG_SIZE, IMG_SIZE, interpolation=cv2.INTER_NEAREST),\n",
        "        A.ToTensorV2()\n",
        "    ])\n",
        "\n",
        "train_dataset = ClassificationDataset(\n",
        "    catheter_predictions=catheter_tensor_original[train_mask],\n",
        "    atria_predictions=atria_tensor_original[train_mask],\n",
        "    labels=[labels[i] for i in np.where(train_mask)[0]],\n",
        "    # original_images=original_images[train_mask] if original_images is not None else None,\n",
        "    ids=train_ids,\n",
        "    transform=train_transform,\n",
        "\n",
        "    # normalize=True\n",
        ")\n",
        "\n",
        "test_dataset = ClassificationDataset(\n",
        "    catheter_predictions=catheter_tensor_original[test_mask],\n",
        "    atria_predictions=atria_tensor_original[test_mask],\n",
        "    labels=[labels[i] for i in np.where(test_mask)[0]],\n",
        "    # original_images=original_images[test_mask] if original_images is not None else None,\n",
        "    ids=test_ids,\n",
        "    transform=val_transform,\n",
        "    # normalize=True\n",
        ")\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "val_dataloader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
        "\n",
        "def objective(trial):\n",
        "    # 1. Suggest hyperparameters\n",
        "    params = {\n",
        "        'dropout_prob': trial.suggest_float('dropout_prob', 0.1, 0.5),\n",
        "        'weight_decay': trial.suggest_float('weight_decay', 1e-5, 1e-3, log=True),\n",
        "        'lr': trial.suggest_float('lr', 1e-5, 1e-3, log=True),\n",
        "    }\n",
        "\n",
        "    # 2. Initialize model with suggested dropout\n",
        "    model = call_model(model_name='convnext_base', device=device, fine_tune='last_two', drop_out_prob=params['dropout_prob'])\n",
        "    model.to(device)\n",
        "     # 3. Create optimizer with weight decay\n",
        "    optimizer = torch.optim.AdamW(\n",
        "        model.parameters(),\n",
        "        lr=params['lr'],\n",
        "        weight_decay=params['weight_decay']\n",
        "    )\n",
        "\n",
        "    # LR scheduling\n",
        "    warmup_epochs = 5  # Number of epochs for warmup\n",
        "    warmup_scheduler = LinearLR(optimizer, start_factor=0.01, end_factor=1.0, total_iters=warmup_epochs)\n",
        "\n",
        "   # Step 2: Cosine decay scheduler (after warmup)\n",
        "    cosine_scheduler = CosineAnnealingLR(optimizer, T_max=num_epochs - warmup_epochs, eta_min=1e-6)\n",
        "\n",
        "    # # Combined scheduler\n",
        "    from torch.optim.lr_scheduler import SequentialLR\n",
        "    scheduler = SequentialLR(\n",
        "          optimizer,\n",
        "          schedulers=[warmup_scheduler, cosine_scheduler],\n",
        "          milestones=[warmup_epochs]\n",
        "          )\n",
        "\n",
        "\n",
        "    # 4. Use your existing train/val steps\n",
        "    best_acc = 0\n",
        "    for epoch in range(50):\n",
        "        # Your existing training step\n",
        "        train_loss, train_acc = train_step(model, train_dataloader, criterion, optimizer, scheduler, device)\n",
        "        val_loss, val_acc, *rest  = test_step(model, val_dataloader, criterion, device)\n",
        "\n",
        "        # Report back to Optuna\n",
        "        trial.report(val_acc, epoch)\n",
        "\n",
        "        # Early stopping/pruning\n",
        "        if trial.should_prune():\n",
        "            raise optuna.exceptions.TrialPruned()\n",
        "\n",
        "        # Track best validation loss\n",
        "        if best_acc < val_acc:\n",
        "            best_acc = val_acc\n",
        "\n",
        "    return best_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WVAgLKg2taNq"
      },
      "outputs": [],
      "source": [
        "# Create study with pruning\n",
        "study = optuna.create_study(\n",
        "    direction='minimize',\n",
        "    pruner=optuna.pruners.MedianPruner(n_startup_trials=5, n_warmup_steps=10)\n",
        ")\n",
        "\n",
        "# Run optimization\n",
        "study.optimize(objective, n_trials=20)  # 30 trials or 1 hour\n",
        "\n",
        "# Best found parameters\n",
        "print(\"Best trial:\")\n",
        "trial = study.best_trial\n",
        "print(f\"  Dropout: {trial.params['dropout_prob']:.4f}\")\n",
        "print(f\"  Weight decay: {trial.params['weight_decay']:.2e}\")\n",
        "print(f\"  Learning rate: {trial.params['lr']:.2e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W4eBy3GGk1x8"
      },
      "outputs": [],
      "source": [
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Nk2A6l2qalb"
      },
      "outputs": [],
      "source": [
        "ind = 10\n",
        "img, lab, id = test_dataset[ind]\n",
        "\n",
        "input = img.unsqueeze(0)\n",
        "\n",
        "# Ensure the input tensor is on the same device as the model\n",
        "input = input.to(device) # <-- Added this line\n",
        "\n",
        "model.to(device)\n",
        "\n",
        "with torch.no_grad():\n",
        "\n",
        "  logit = model(input)\n",
        "  logit = torch.sigmoid(logit)\n",
        "  logit = logit.item()\n",
        "print(logit)\n",
        "\n",
        "predicted_lab = 1 if logit > 0.5 else 0\n",
        "\n",
        "title_color = \"green\" if predicted_lab == lab else \"red\"\n",
        "\n",
        "prob = logit if predicted_lab == 1 else 1 - logit\n",
        "\n",
        "\n",
        "plt.imshow(img.permute(1, 2, 0))\n",
        "plt.title(f\"actual: {int(lab)}, predicted: {int(logit > 0.5)}, prop: {prob:.4f}\", color=title_color)\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "\n",
        "input.requires_grad = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Toe-SjZTmPiR"
      },
      "outputs": [],
      "source": [
        "!pip install captum --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KqxyrS9zoli0"
      },
      "outputs": [],
      "source": [
        "from captum.attr import IntegratedGradients\n",
        "from captum.attr import Saliency\n",
        "from captum.attr import DeepLift\n",
        "from captum.attr import NoiseTunnel\n",
        "from captum.attr import visualization as viz\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# move model to cpu, to use local ram\n",
        "device = torch.device(\"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "# Ensure the input tensor is on the same device as the model\n",
        "input = input.to(device)\n",
        "\n",
        "\n",
        "saliency = Saliency(model)\n",
        "# Remove the target argument for single-output binary classification models\n",
        "grads = saliency.attribute(input) # Removed target=lab\n",
        "grads = np.transpose(grads.squeeze().cpu().detach().numpy(), (1, 2, 0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rrpddwl6bGSO"
      },
      "outputs": [],
      "source": [
        "# move model and input to cpu\n",
        "# device = torch.device(\"cpu\")\n",
        "# model.to(device)\n",
        "# input = input.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6y_l2owApULc"
      },
      "outputs": [],
      "source": [
        "# Convert the img tensor to a NumPy array before visualizing\n",
        "img_np = img.squeeze().cpu().numpy()\n",
        "\n",
        "\n",
        "\n",
        "_ = viz.visualize_image_attr(grads, img_np, method=\"heat_map\", sign=\"absolute_value\",\n",
        "                          show_colorbar=True, title=\"Overlayed Gradient Magnitudes\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xpd7wBHJv2MS"
      },
      "outputs": [],
      "source": [
        "# file ipython-input-139-8aa18f246882\n",
        "def attribute_image_features(algorithm, input, **kwargs):\n",
        "    model.zero_grad()\n",
        "    # For binary segmentation with a single output channel, do not specify target\n",
        "    tensor_attributions = algorithm.attribute(input,\n",
        "                                              # Removed target=labels[ind]\n",
        "                                              **kwargs\n",
        "                                             )\n",
        "\n",
        "    return tensor_attributions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JJ7IH0vtv3fM"
      },
      "outputs": [],
      "source": [
        "# file ipython-input-141-8aa18f246882\n",
        "dl = DeepLift(model)\n",
        "# Call attribute_image_features, which no longer passes the target argument\n",
        "attr_dl = attribute_image_features(dl, input, baselines=input * 0)\n",
        "attr_dl = np.transpose(attr_dl.squeeze(0).cpu().detach().numpy(), (1, 2, 0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nYQjIDf-wwWS"
      },
      "outputs": [],
      "source": [
        "\n",
        "_ = viz.visualize_image_attr(attr_dl, img_np, method=\"blended_heat_map\",sign=\"all\",show_colorbar=True,\n",
        "                          title=\"Overlayed DeepLift\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W5va5WK0yw3W"
      },
      "outputs": [],
      "source": [
        "met_df['tip'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "slKqy40N2rOl"
      },
      "outputs": [],
      "source": [
        "predicted_features_base_df['tip'].value_counts(normalize=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lMcy4tqE20Je"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "datasetId": 7476702,
          "sourceId": 11895780,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 31041,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}